<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Checking outliers with *performance* • performance</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<!-- katex math --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><script src="../katex-auto.js"></script><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Roboto-0.4.10/font.css" rel="stylesheet">
<link href="../deps/JetBrains_Mono-0.4.10/font.css" rel="stylesheet">
<link href="../deps/Roboto_Slab-0.4.10/font.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Checking outliers with *performance*">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">performance</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.15.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html" aria-label="Reference"><span class="fa fa-file-code"></span> Reference</a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html" aria-label="Articles"><span class="fa fa-book-reader"></span> Articles</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html" aria-label="News"><span class="fa fa-newspaper"></span> News</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-easystats" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="easystats"><span class="fa fab fa-r-project"></span> easystats</button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-easystats">
<li><a class="external-link dropdown-item" href="https://easystats.github.io/bayestestR/">bayestestR</a></li>
    <li><a class="external-link dropdown-item" href="https://easystats.github.io/correlation/">correlation</a></li>
    <li><a class="external-link dropdown-item" href="https://easystats.github.io/datawizard/">datawizard</a></li>
    <li><a class="external-link dropdown-item" href="https://easystats.github.io/easystats/">easystats</a></li>
    <li><a class="external-link dropdown-item" href="https://easystats.github.io/effectsize/">effectsize</a></li>
    <li><a class="external-link dropdown-item" href="https://easystats.github.io/insight/">insight</a></li>
    <li><a class="external-link dropdown-item" href="https://easystats.github.io/modelbased/">modelbased</a></li>
    <li><a class="dropdown-item" href="https://easystats.github.io/performance/">performance</a></li>
    <li><a class="external-link dropdown-item" href="https://easystats.github.io/parameters/">parameters</a></li>
    <li><a class="external-link dropdown-item" href="https://easystats.github.io/report/">report</a></li>
    <li><a class="external-link dropdown-item" href="https://easystats.github.io/see/">see</a></li>
  </ul>
</li>
<li class="nav-item"><a class="external-link nav-link" href="http://twitter.com/easystats4u" aria-label="Twitter"><span class="fa fa-twitter"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/easystats/performance/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">



<link href="check_outliers_files/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="check_outliers_files/tabwid-1.1.3/tabwid.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Checking outliers with *performance*</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/easystats/performance/blob/main/vignettes/check_outliers.Rmd" class="external-link"><code>vignettes/check_outliers.Rmd</code></a></small>
      <div class="d-none name"><code>check_outliers.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="reuse-of-this-material">Reuse of this Material<a class="anchor" aria-label="anchor" href="#reuse-of-this-material"></a>
</h2>
<blockquote>
<p>Note: This vignette is an extended write-up of the <a href="https://doi.org/10.3758/s13428-024-02356-w" class="external-link">Behavior Research
Methods paper</a>. This educational module can be freely reused for
teaching purposes as long as the original BRM paper is cited. The raw
code file, which can be adapted to other rmarkdown formats for teaching
purposes, can be accessed <a href="https://github.com/easystats/performance/blob/HEAD/vignettes/check_outliers.Rmd" class="external-link">here</a>.
To contribute to and improve this content directly, please submit a Pull
Request at the <em>{performance}</em> package GitHub repository by
following our usual contributing guidelines: <a href="https://easystats.github.io/performance/CONTRIBUTING.html" class="uri">https://easystats.github.io/performance/CONTRIBUTING.html</a>.
To report issues or problems, with this module, or seek support, please
open an issue: <a href="https://github.com/easystats/performance/issues" class="external-link uri">https://github.com/easystats/performance/issues</a>.</p>
</blockquote>
<p><strong>Reference:</strong></p>
<p>Thériault, R., Ben-Shachar, M. S., Patil, I., Lüdecke, D., Wiernik,
B. M., &amp; Makowski, D. (2024). Check your outliers﻿! An introduction
to identifying statistical outliers in R with easystats. <em>Behavior
Research Methods</em>, 1-11. <a href="https://doi.org/10.3758/s13428-024-02356-w" class="external-link uri">https://doi.org/10.3758/s13428-024-02356-w</a></p>
</div>
<div class="section level2">
<h2 id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<p>Beyond the challenge of keeping up-to-date with current best
practices regarding the diagnosis and treatment of outliers, an
additional difficulty arises concerning the mathematical implementation
of the recommended methods. In this vignette, we provide an overview of
current recommendations and best practices and demonstrate how they can
easily and conveniently be implemented in the R statistical computing
software, using the <em>{performance}</em> package of the
<em>easystats</em> ecosystem. We cover univariate, multivariate, and
model-based statistical outlier detection methods, their recommended
threshold, standard output, and plotting methods. We conclude with
recommendations on the handling of outliers: the different theoretical
types of outliers, whether to exclude or winsorize them, and the
importance of transparency.</p>
</div>
<div class="section level2">
<h2 id="statement-of-need">Statement of Need<a class="anchor" aria-label="anchor" href="#statement-of-need"></a>
</h2>
<p>Real-life data often contain observations that can be considered
<em>abnormal</em> when compared to the main population. The cause of
it—be it because they belong to a different distribution (originating
from a different generative process) or simply being extreme cases,
statistically rare but not impossible—can be hard to assess, and the
boundaries of “abnormal” difficult to define.</p>
<p>Nonetheless, the improper handling of these outliers can
substantially affect statistical model estimations, biasing effect
estimations and weakening the models’ predictive performance. It is thus
essential to address this problem in a thoughtful manner. Yet, despite
the existence of established recommendations and guidelines, many
researchers still do not treat outliers in a consistent manner, or do so
using inappropriate strategies <span class="citation">(Simmons et al.
2011; Leys et al. 2013)</span>.</p>
<p>One possible reason is that researchers are not aware of the existing
recommendations, or do not know how to implement them using their
analysis software. In this paper, we show how to follow current best
practices for automatic and reproducible statistical outlier detection
(SOD) using R and the <em>{performance}</em> package <span class="citation">(Lüdecke et al. 2021)</span>, which is part of the
<em>easystats</em> ecosystem of packages that build an R framework for
easy statistical modeling, visualization, and reporting <span class="citation">(Lüdecke et al. [2019] 2023)</span>. Installation
instructions can be found on <a href="https://github.com/easystats/performance" class="external-link">GitHub</a> or its <a href="https://easystats.github.io/performance/">website</a>, and its
list of dependencies on <a href="https://cran.r-project.org/package=performance" class="external-link">CRAN</a>.</p>
<p>The instructional materials that follow are aimed at an audience of
researchers who want to follow good practices, and are appropriate for
advanced undergraduate students, graduate students, professors, or
professionals having to deal with the nuances of outlier treatment.</p>
</div>
<div class="section level2">
<h2 id="identifying-outliers">Identifying Outliers<a class="anchor" aria-label="anchor" href="#identifying-outliers"></a>
</h2>
<p>Although many researchers attempt to identify outliers with measures
based on the mean (e.g., <em>z</em> scores), those methods are
problematic because the mean and standard deviation themselves are not
robust to the influence of outliers and those methods also assume
normally distributed data (i.e., a Gaussian distribution). Therefore,
current guidelines recommend using robust methods to identify outliers,
such as those relying on the median as opposed to the mean <span class="citation">(Leys et al. 2019, 2013, 2018)</span>.</p>
<p>Nonetheless, which exact outlier method to use depends on many
factors. In some cases, eye-gauging odd observations can be an
appropriate solution, though many researchers will favour algorithmic
solutions to detect potential outliers, for example, based on a
continuous value expressing the observation stands out from the
others.</p>
<p>One of the factors to consider when selecting an algorithmic outlier
detection method is the statistical test of interest. When using a
regression model, relevant information can be found by identifying
observations that do not fit well with the model. This approach, known
as model-based outliers detection (as outliers are extracted after the
statistical model has been fit), can be contrasted with
distribution-based outliers detection, which is based on the distance
between an observation and the “center” of its population. Various
quantification strategies of this distance exist for the latter, both
univariate (involving only one variable at a time) or multivariate
(involving multiple variables).</p>
<p>When no method is readily available to detect model-based outliers,
such as for structural equation modelling (SEM), looking for
multivariate outliers may be of relevance. For simple tests (<em>t</em>
tests or correlations) that compare values of the same variable, it can
be appropriate to check for univariate outliers. However, univariate
methods can give false positives since <em>t</em> tests and
correlations, ultimately, are also models/multivariable statistics. They
are in this sense more limited, but we show them nonetheless for
educational purposes.</p>
<p>Importantly, whatever approach researchers choose remains a
subjective decision, which usage (and rationale) must be transparently
documented and reproducible <span class="citation">(Leys et al.
2019)</span>. Researchers should commit (ideally in a preregistration)
to an outlier treatment method before collecting the data. They should
report in the paper their decisions and details of their methods, as
well as any deviation from their original plan. These transparency
practices can help reduce false positives due to excessive researchers’
degrees of freedom (i.e., choice flexibility throughout the analysis).
In the following section, we will go through each of the mentioned
methods and provide examples on how to implement them with R.</p>
<div class="section level3">
<h3 id="univariate-outliers">Univariate Outliers<a class="anchor" aria-label="anchor" href="#univariate-outliers"></a>
</h3>
<p>Researchers frequently attempt to identify outliers using measures of
deviation from the center of a variable’s distribution. One of the most
popular such procedure is the <em>z</em> score transformation, which
computes the distance in standard deviation (SD) from the mean. However,
as mentioned earlier, this popular method is not robust. Therefore, for
univariate outliers, it is recommended to use the median along with the
Median Absolute Deviation (MAD), which are more robust than the
interquartile range or the mean and its standard deviation <span class="citation">(Leys et al. 2019, 2013)</span>.</p>
<p>Researchers can identify outliers based on robust (i.e., MAD-based)
<em>z</em> scores using the <code><a href="../reference/check_outliers.html">check_outliers()</a></code> function of
the <em>{performance}</em> package, by specifying
<code>method = "zscore_robust"</code>.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;Note that &lt;code&gt;&lt;a href="../reference/check_outliers.html"&gt;check_outliers()&lt;/a&gt;&lt;/code&gt; only checks
numeric variables.&lt;/p&gt;'><sup>1</sup></a> Although <span class="citation">Leys et al. (2013)</span> suggest a default threshold
of 2.5 and <span class="citation">Leys et al. (2019)</span> a threshold
of 3, <em>{performance}</em> uses by default a less conservative
threshold of ~3.29.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;3.29 is an approximation of the two-tailed critical
value for &lt;em&gt;p&lt;/em&gt; &amp;lt; .001, obtained through
&lt;code&gt;qnorm(p = 1 - 0.001 / 2)&lt;/code&gt;. We chose this threshold for
consistency with the thresholds of all our other methods.&lt;/p&gt;"><sup>2</sup></a> That is, data points will be flagged as
outliers if they go beyond +/- ~3.29 MAD. Users can adjust this
threshold using the <code>threshold</code> argument.</p>
<p>Below we provide example code using the <code>mtcars</code> dataset,
which was extracted from the 1974 <em>Motor Trend</em> US magazine. The
dataset contains fuel consumption and 10 characteristics of automobile
design and performance for 32 different car models (see
<code><a href="https://rdrr.io/r/datasets/mtcars.html" class="external-link">?mtcars</a></code> for details). We chose this dataset because it is
accessible from base R and familiar to many R users. We might want to
conduct specific statistical analyses on this data set, say, <em>t</em>
tests or structural equation modelling, but first, we want to check for
outliers that may influence those test results.</p>
<p>Because the automobile names are stored as column names in
<code>mtcars</code>, we first have to convert them to an ID column to
benefit from the <code><a href="../reference/check_outliers.html">check_outliers()</a></code> ID argument. Furthermore,
we only really need a couple columns for this demonstration, so we
choose the first four (<code>mpg</code> = Miles/(US) gallon;
<code>cyl</code> = Number of cylinders; <code>disp</code> =
Displacement; <code>hp</code> = Gross horsepower). Finally, because
there are no outliers in this dataset, we add two artificial outliers
before running our function.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/performance/">performance</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create some artificial outliers and an ID column</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, <span class="fl">42</span>, <span class="fl">55</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span>car <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/row.names.html" class="external-link">row.names</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="va">outliers</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/check_outliers.html">check_outliers</a></span><span class="op">(</span><span class="va">data</span>, method <span class="op">=</span> <span class="st">"zscore_robust"</span>, ID <span class="op">=</span> <span class="st">"car"</span><span class="op">)</span></span>
<span><span class="va">outliers</span></span></code></pre></div>
<pre><code>&gt; 2 outliers detected: cases 33, 34.
&gt; - Based on the following method and threshold: zscore_robust (3.291).
&gt; - For variables: mpg, cyl, disp, hp.
&gt; 
&gt; -----------------------------------------------------------------------------
&gt;  
&gt; The following observations were considered outliers for two or more
&gt;   variables by at least one of the selected methods:
&gt; 
&gt;   Row car n_Zscore_robust
&gt; 1  33  33               2
&gt; 2  34  34               2
&gt; 
&gt; -----------------------------------------------------------------------------
&gt; Outliers per variable (zscore_robust): 
&gt; 
&gt; $mpg
&gt;    Row car Distance_Zscore_robust
&gt; 33  33  33                    3.7
&gt; 34  34  34                    5.8
&gt; 
&gt; $cyl
&gt;    Row car Distance_Zscore_robust
&gt; 33  33  33                     12
&gt; 34  34  34                     17</code></pre>
<p>What we see is that <code><a href="../reference/check_outliers.html">check_outliers()</a></code> with the robust
<em>z</em> score method detected two outliers: cases 33 and 34, which
were the observations we added ourselves. They were flagged for two
variables specifically: <code>mpg</code> (Miles/(US) gallon) and
<code>cyl</code> (Number of cylinders), and the output provides their
exact <em>z</em> score for those variables.</p>
<p>We describe how to deal with those cases in more details later in the
paper, but should we want to exclude these detected outliers from the
main dataset, we can extract row numbers using <code><a href="https://rdrr.io/r/base/which.html" class="external-link">which()</a></code> on
the output object, which can then be used for indexing:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span></span></code></pre></div>
<pre><code>&gt; [1] 33 34</code></pre>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data_clean</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span>, <span class="op">]</span></span></code></pre></div>
<p>All <code><a href="../reference/check_outliers.html">check_outliers()</a></code> output objects possess a
<code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> method, meaning it is also possible to visualize the
outliers using the generic <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> function on the resulting
outlier object after loading the {see} package.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/see/" class="external-link">see</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span></span></code></pre></div>
<pre><code>&gt; $threshold_outliers
&gt; [1] 33 34
&gt; 
&gt; $threshold
&gt; [1] 3.3
&gt; 
&gt; $elbow_outliers
&gt; [1] 33 34
&gt; 
&gt; $elbow_threshold
&gt; [1] 9.5</code></pre>
<div class="figure">
<img src="check_outliers_files/figure-html/univariate_implicit-1.png" alt="Visual depiction of outliers using the robust z-score method. The distance represents an aggregate score for variables mpg, cyl, disp, and hp." width="100%"><p class="caption">
Visual depiction of outliers using the robust z-score method. The
distance represents an aggregate score for variables mpg, cyl, disp, and
hp.
</p>
</div>
<p>Other univariate methods are available, such as using the
interquartile range (IQR), or based on different intervals, such as the
Highest Density Interval (HDI) or the Bias Corrected and Accelerated
Interval (BCI). These methods are documented and described in the
function’s <a href="https://easystats.github.io/performance/reference/check_outliers.html">help
page</a>.</p>
</div>
<div class="section level3">
<h3 id="multivariate-outliers">Multivariate Outliers<a class="anchor" aria-label="anchor" href="#multivariate-outliers"></a>
</h3>
<p>Univariate outliers can be useful when the focus is on a particular
variable, for instance the reaction time, as extreme values might be
indicative of inattention or non-task-related behavior<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt; Note that they might not be the optimal way of treating
reaction time outliers &lt;span class="citation"&gt;(Ratcliff 1993; Van Zandt
and Ratcliff 1995)&lt;/span&gt;&lt;/p&gt;'><sup>3</sup></a>.</p>
<p>However, in many scenarios, variables of a data set are not
independent, and an abnormal observation will impact multiple
dimensions. For instance, a participant giving random answers to a
questionnaire. In this case, computing the <em>z</em> score for each of
the questions might not lead to satisfactory results. Instead, one might
want to look at these variables together.</p>
<p>One common approach for this is to compute multivariate distance
metrics such as the Mahalanobis distance. Although the Mahalanobis
distance is very popular, just like the regular <em>z</em> scores
method, it is not robust and is heavily influenced by the outliers
themselves. Therefore, for multivariate outliers, it is recommended to
use the Minimum Covariance Determinant, a robust version of the
Mahalanobis distance <span class="citation">(MCD, Leys et al. 2018,
2019)</span>.</p>
<p>In <em>{performance}</em>’s <code><a href="../reference/check_outliers.html">check_outliers()</a></code>, one can
use this approach with <code>method = "mcd"</code>.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;Our default threshold for the MCD method is defined by
&lt;code&gt;stats::qchisq(p = 1 - 0.001, df = ncol(x))&lt;/code&gt;, which again is
an approximation of the critical value for &lt;em&gt;p&lt;/em&gt; &amp;lt; .001
consistent with the thresholds of our other methods.&lt;/p&gt;"><sup>4</sup></a></p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">outliers</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/check_outliers.html">check_outliers</a></span><span class="op">(</span><span class="va">data</span>, method <span class="op">=</span> <span class="st">"mcd"</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">outliers</span></span></code></pre></div>
<pre><code>&gt; 2 outliers detected: cases 33, 34.
&gt; - Based on the following method and threshold: mcd (20).
&gt; - For variables: mpg, cyl, disp, hp.</code></pre>
<p>Here, we detected 9 multivariate outliers (i.e,. when looking at all
variables of our dataset together).</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span></span></code></pre></div>
<pre><code>&gt; $threshold_outliers
&gt; [1] 33 34
&gt; 
&gt; $threshold
&gt; [1] 18
&gt; 
&gt; $elbow_outliers
&gt; [1] 33 34
&gt; 
&gt; $elbow_threshold
&gt; [1] 3547</code></pre>
<div class="figure">
<img src="check_outliers_files/figure-html/multivariate_implicit-1.png" alt="Visual depiction of outliers using the Minimum Covariance Determinant (MCD) method, a robust version of the Mahalanobis distance. The distance represents the MCD scores for variables mpg, cyl, disp, and hp." width="100%"><p class="caption">
Visual depiction of outliers using the Minimum Covariance Determinant
(MCD) method, a robust version of the Mahalanobis distance. The distance
represents the MCD scores for variables mpg, cyl, disp, and hp.
</p>
</div>
<p>Other multivariate methods are available, such as another type of
robust Mahalanobis distance that in this case relies on an
orthogonalized Gnanadesikan-Kettenring pairwise estimator <span class="citation">(Gnanadesikan and Kettenring 1972)</span>. These
methods are documented and described in the function’s <a href="https://easystats.github.io/performance/reference/check_outliers.html">help
page</a>.</p>
</div>
<div class="section level3">
<h3 id="model-based-outliers">Model-Based Outliers<a class="anchor" aria-label="anchor" href="#model-based-outliers"></a>
</h3>
<p>Working with regression models creates the possibility of using
model-based SOD methods. These methods rely on the concept of
<em>leverage</em>, that is, how much influence a given observation can
have on the model estimates. If few observations have a relatively
strong leverage/influence on the model, one can suspect that the model’s
estimates are biased by these observations, in which case flagging them
as outliers could prove helpful (see next section, “Handling
Outliers”).</p>
<p>In {performance}, two such model-based SOD methods are currently
available: Cook’s distance, for regular regression models, and Pareto,
for Bayesian models. As such, <code><a href="../reference/check_outliers.html">check_outliers()</a></code> can be
applied directly on regression model objects, by simply specifying
<code>method = "cook"</code> (or <code>method = "pareto"</code> for
Bayesian models).<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;Our default threshold for the Cook method is defined by
&lt;code&gt;stats::qf(0.5, ncol(x), nrow(x) - ncol(x))&lt;/code&gt;, which again is
an approximation of the critical value for &lt;em&gt;p&lt;/em&gt; &amp;lt; .001
consistent with the thresholds of our other methods.&lt;/p&gt;"><sup>5</sup></a></p>
<p>Currently, most lm models are supported (with the exception of
<code>glmmTMB</code>, <code>lmrob</code>, and <code>glmrob</code>
models), as long as they are supported by the underlying functions
<code><a href="https://rdrr.io/r/stats/influence.measures.html" class="external-link">stats::cooks.distance()</a></code> (or
<code><a href="https://mc-stan.org/loo/reference/pareto-k-diagnostic.html" class="external-link">loo::pareto_k_values()</a></code>) and
<code><a href="https://easystats.github.io/insight/reference/get_data.html" class="external-link">insight::get_data()</a></code> (for a full list of the 225 models
currently supported by the <code>insight</code> package, see <a href="https://easystats.github.io/insight/#list-of-supported-models-by-class" class="external-link uri">https://easystats.github.io/insight/#list-of-supported-models-by-class</a>).
Also note that although <code><a href="../reference/check_outliers.html">check_outliers()</a></code> supports the pipe
operators (<code>|&gt;</code> or <code>%&gt;%</code>), it does not
support <code>tidymodels</code> at this time. We show a demo below.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">disp</span> <span class="op">~</span> <span class="va">mpg</span> <span class="op">*</span> <span class="va">hp</span>, data <span class="op">=</span> <span class="va">data</span><span class="op">)</span></span>
<span><span class="va">outliers</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/check_outliers.html">check_outliers</a></span><span class="op">(</span><span class="va">model</span>, method <span class="op">=</span> <span class="st">"cook"</span><span class="op">)</span></span>
<span><span class="va">outliers</span></span></code></pre></div>
<pre><code>&gt; 2 outliers detected: cases 31, 34.
&gt; - Based on the following method and threshold: cook (0.806).
&gt; - For variable: (Whole model).</code></pre>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="check_outliers_files/figure-html/model-1.png" alt="Visual depiction of outliers based on Cook's distance (leverage and standardized residuals), based on the fitted model." width="100%"><p class="caption">
Visual depiction of outliers based on Cook’s distance (leverage and
standardized residuals), based on the fitted model.
</p>
</div>
<p>Using the model-based outlier detection method, we identified two
outliers.</p>
<p>Table 1 below summarizes which methods to use in which cases, and
with what threshold. The recommended thresholds are the default
thresholds.</p>
<div class="section level4">
<h4 id="table-1">Table 1<a class="anchor" aria-label="anchor" href="#table-1"></a>
</h4>
<p><em>Summary of Statistical Outlier Detection Methods
Recommendations</em></p>
<div class="tabwid">
<style>.cl-2040bf30{}.cl-203a5cda{font-family:'Latin Modern Roman';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-203a5cee{font-family:'Latin Modern Roman';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-203a5cf8{font-family:'Latin Modern Roman';font-size:11pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-203d2b5e{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-203d46fc{width:2.25in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-203d4706{width:2.25in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-203d4710{width:2.25in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style>
<table data-quarto-disable-processing="true" class="table cl-2040bf30">
<thead><tr style="overflow-wrap:break-word;">
<th class="cl-203d46fc"><p class="cl-203d2b5e"><span class="cl-203a5cda">Statistical Test</span></p></th>
<th class="cl-203d46fc"><p class="cl-203d2b5e"><span class="cl-203a5cda">Diagnosis Method</span></p></th>
<th class="cl-203d46fc"><p class="cl-203d2b5e"><span class="cl-203a5cda">Recommended Threshold</span></p></th>
<th class="cl-203d46fc"><p class="cl-203d2b5e"><span class="cl-203a5cda">Function Usage</span></p></th>
</tr></thead>
<tbody>
<tr style="overflow-wrap:break-word;">
<td class="cl-203d4706"><p class="cl-203d2b5e"><span class="cl-203a5cda">Supported</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">regression</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">model</span></p></td>
<td class="cl-203d4706"><p class="cl-203d2b5e"><span class="cl-203a5cee">Model-based</span><span class="cl-203a5cda">:</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">Cook</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">(or</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">Pareto</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">for</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">Bayesian</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">models)</span></p></td>
<td class="cl-203d4706"><p class="cl-203d2b5e"><span class="cl-203a5cf8">qf(0.5,</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">ncol(x),</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">nrow(x)</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">-</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">ncol(x))</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">(or</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">0.7</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">for</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">Pareto)</span></p></td>
<td class="cl-203d4706"><p class="cl-203d2b5e"><span class="cl-203a5cf8">check_outliers(model,</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">method</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">=</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">“</span><span class="cl-203a5cf8">cook</span><span class="cl-203a5cf8">”</span><span class="cl-203a5cf8">)</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-203d4706"><p class="cl-203d2b5e"><span class="cl-203a5cda">Structural</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">Equation</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">Modeling</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">(or</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">other</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">unsupported</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">model)</span></p></td>
<td class="cl-203d4706"><p class="cl-203d2b5e"><span class="cl-203a5cee">Multivariate</span><span class="cl-203a5cda">:</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">Minimum</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">Covariance</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">Determinant</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">(MCD)</span></p></td>
<td class="cl-203d4706"><p class="cl-203d2b5e"><span class="cl-203a5cf8">qchisq(p</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">=</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">1</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">-</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">0.001,</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">df</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">=</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">ncol(x))</span></p></td>
<td class="cl-203d4706"><p class="cl-203d2b5e"><span class="cl-203a5cf8">check_outliers(data,</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">method</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">=</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">“</span><span class="cl-203a5cf8">mcd</span><span class="cl-203a5cf8">”</span><span class="cl-203a5cf8">)</span></p></td>
</tr>
<tr style="overflow-wrap:break-word;">
<td class="cl-203d4710"><p class="cl-203d2b5e"><span class="cl-203a5cda">Simple</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">test</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">with</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">few</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">variables</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">(</span><span class="cl-203a5cf8">t</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">test,</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">correlation,</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">etc.)</span></p></td>
<td class="cl-203d4710"><p class="cl-203d2b5e"><span class="cl-203a5cee">Univariate</span><span class="cl-203a5cda">:</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">robust</span><span class="cl-203a5cda"> </span><span class="cl-203a5cf8">z</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">scores</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">(MAD)</span></p></td>
<td class="cl-203d4710"><p class="cl-203d2b5e"><span class="cl-203a5cf8">qnorm(p</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">=</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">1</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">-</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">0.001</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">/</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">2)</span><span class="cl-203a5cda">,</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">~</span><span class="cl-203a5cda"> </span><span class="cl-203a5cda">3.29</span></p></td>
<td class="cl-203d4710"><p class="cl-203d2b5e"><span class="cl-203a5cf8">check_outliers(data,</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">method</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">=</span><span class="cl-203a5cf8"> </span><span class="cl-203a5cf8">“</span><span class="cl-203a5cf8">zscore_robust</span><span class="cl-203a5cf8">”</span><span class="cl-203a5cf8">)</span></p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="section level3">
<h3 id="cooks-distance-vs--mcd">Cook’s Distance vs. MCD<a class="anchor" aria-label="anchor" href="#cooks-distance-vs--mcd"></a>
</h3>
<p><span class="citation">Leys et al. (2018)</span> report a preference
for the MCD method over Cook’s distance. This is because Cook’s distance
removes one observation at a time and checks its corresponding influence
on the model each time <span class="citation">(Cook 1977)</span>, and
flags any observation that has a large influence. In the view of these
authors, when there are several outliers, the process of removing a
single outlier at a time is problematic as the model remains
“contaminated” or influenced by other possible outliers in the model,
rendering this method suboptimal in the presence of multiple
outliers.</p>
<p>However, distribution-based approaches are not a silver bullet
either, and there are cases where the usage of methods agnostic to
theoretical and statistical models of interest might be problematic. For
example, a very tall person would be expected to also be much heavier
than average, but that would still fit with the expected association
between height and weight (i.e., it would be in line with a model such
as <code>weight ~ height</code>). In contrast, using multivariate
outlier detection methods there may flag this person as being an
outlier—being unusual on two variables, height and weight—even though
the pattern fits perfectly with our predictions.</p>
<p>In the example below, we plot the raw data and see two possible
outliers. The first one falls along the regression line, and is
therefore “in line” with our hypothesis. The second one clearly diverges
from the regression line, and therefore we can conclude that this
outlier may have a disproportionate influence on our model.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">women</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_len</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">women</span><span class="op">)</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">data</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">258</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">200</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">weight</span> <span class="op">~</span> <span class="va">height</span>, <span class="va">data</span><span class="op">)</span></span>
<span><span class="fu">rempsyc</span><span class="fu">::</span><span class="fu"><a href="https://rempsyc.remi-theriault.com/reference/nice_scatter.html" class="external-link">nice_scatter</a></span><span class="op">(</span><span class="va">data</span>, <span class="st">"height"</span>, <span class="st">"weight"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="check_outliers_files/figure-html/scatter-1.png" alt="Scatter plot of height and weight, with two extreme observations: one model-consistent (top-right) and the other, model-inconsistent (i.e., an outlier; bottom-right)." width="100%"><p class="caption">
Scatter plot of height and weight, with two extreme observations: one
model-consistent (top-right) and the other, model-inconsistent (i.e., an
outlier; bottom-right).
</p>
</div>
<p>Using either the <em>z</em>-score or MCD methods, our
model-consistent observation will be incorrectly flagged as an outlier
or influential observation.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">outliers</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/check_outliers.html">check_outliers</a></span><span class="op">(</span><span class="va">model</span>, method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"zscore_robust"</span>, <span class="st">"mcd"</span><span class="op">)</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span></span></code></pre></div>
<pre><code>&gt; [1] 1501 1502</code></pre>
<p>In contrast, the model-based detection method displays the desired
behaviour: it correctly flags the person who is very tall but very
light, without flagging the person who is both tall and heavy.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">outliers</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/check_outliers.html">check_outliers</a></span><span class="op">(</span><span class="va">model</span>, method <span class="op">=</span> <span class="st">"cook"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span></span></code></pre></div>
<pre><code>&gt; [1] 1502</code></pre>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="check_outliers_files/figure-html/model2-1.png" alt="The leverage method (Cook's distance) correctly distinguishes the true outlier from the model-consistent extreme observation), based on the fitted model." width="100%"><p class="caption">
The leverage method (Cook’s distance) correctly distinguishes the true
outlier from the model-consistent extreme observation), based on the
fitted model.
</p>
</div>
<p>Finally, unusual observations happen naturally: extreme observations
are expected even when taken from a normal distribution. While
statistical models can integrate this “expectation”, multivariate
outlier methods might be too conservative, flagging too many
observations despite belonging to the right generative process. For
these reasons, we believe that model-based methods are still preferable
to the MCD when using supported regression models. Additionally, if the
presence of multiple outliers is a significant concern, regression
methods that are more robust to outliers should be considered—like
<em>t</em> regression or quantile regression—as they render their
precise identification less critical <span class="citation">(McElreath
2020)</span>.</p>
</div>
<div class="section level3">
<h3 id="composite-outlier-score">Composite Outlier Score<a class="anchor" aria-label="anchor" href="#composite-outlier-score"></a>
</h3>
<p>The <em>{performance}</em> package also offers an alternative,
consensus-based approach that combines several methods, based on the
assumption that different methods provide different angles of looking at
a given problem. By applying a variety of methods, one can hope to
“triangulate” the true outliers (those consistently flagged by multiple
methods) and thus attempt to minimize false positives.</p>
<p>In practice, this approach computes a composite outlier score, formed
of the average of the binary (0 or 1) classification results of each
method. It represents the probability that each observation is
classified as an outlier by at least one method. The default decision
rule classifies rows with composite outlier scores superior or equal to
0.5 as outlier observations (i.e., that were classified as outliers by
at least half of the methods). In <em>{performance}</em>’s
<code><a href="../reference/check_outliers.html">check_outliers()</a></code>, one can use this approach by including
all desired methods in the corresponding argument.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">outliers</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/check_outliers.html">check_outliers</a></span><span class="op">(</span><span class="va">model</span>, method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"zscore_robust"</span>, <span class="st">"mcd"</span>, <span class="st">"cook"</span><span class="op">)</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span></span></code></pre></div>
<pre><code>&gt; [1] 1501 1502</code></pre>
<p>Outliers (counts or per variables) for individual methods can then be
obtained through attributes. For example:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/attributes.html" class="external-link">attributes</a></span><span class="op">(</span><span class="va">outliers</span><span class="op">)</span><span class="op">$</span><span class="va">outlier_var</span><span class="op">$</span><span class="va">zscore_robust</span></span></code></pre></div>
<pre><code>&gt; $weight
&gt;       Row Distance_Zscore_robust
&gt; 1501 1501                    6.9
&gt; 1502 1502                    3.7
&gt; 
&gt; $height
&gt;       Row Distance_Zscore_robust
&gt; 1501 1501                    5.9
&gt; 1502 1502                    5.9</code></pre>
<p>An example sentence for reporting the usage of the composite method
could be:</p>
<blockquote>
<p>Based on a composite outlier score <span class="citation">(see the
‘check_outliers()’ function in the ‘performance’ R package, Lüdecke et
al. 2021)</span> obtained via the joint application of multiple outliers
detection algorithms <span class="citation">((a) median absolute
deviation (MAD)-based robust <em>z</em> scores, Leys et al. 2013; (b)
Mahalanobis minimum covariance determinant (MCD), Leys et al. 2019; and
(c) Cook’s distance, Cook 1977)</span>, we excluded two participants
that were classified as outliers by at least half of the methods
used.</p>
</blockquote>
</div>
</div>
<div class="section level2">
<h2 id="handling-outliers">Handling Outliers<a class="anchor" aria-label="anchor" href="#handling-outliers"></a>
</h2>
<p>The above section demonstrated how to identify outliers using the
<code><a href="../reference/check_outliers.html">check_outliers()</a></code> function in the <em>{performance}</em>
package. But what should we do with these outliers once identified?
Although it is common to automatically discard any observation that has
been marked as “an outlier” as if it might infect the rest of the data
with its statistical ailment, we believe that the use of SOD methods is
but one step in the get-to-know-your-data pipeline; a researcher or
analyst’s <em>domain knowledge</em> must be involved in the decision of
how to deal with observations marked as outliers by means of SOD.
Indeed, automatic tools can help detect outliers, but they are nowhere
near perfect. Although they can be useful to flag suspect data, they can
have misses and false alarms, and they cannot replace human eyes and
proper vigilance from the researcher. If you do end up manually
inspecting your data for outliers, it can be helpful to think of
outliers as belonging to different types of outliers, or categories,
which can help decide what to do with a given outlier.</p>
<div class="section level3">
<h3 id="error-interesting-and-random-outliers">Error, Interesting, and Random Outliers<a class="anchor" aria-label="anchor" href="#error-interesting-and-random-outliers"></a>
</h3>
<p><span class="citation">Leys et al. (2019)</span> distinguish between
error outliers, interesting outliers, and random outliers. <em>Error
outliers</em> are likely due to human error and should be corrected
before data analysis or outright removed since they are invalid
observations. <em>Interesting outliers</em> are not due to technical
error and may be of theoretical interest; it might thus be relevant to
investigate them further even though they should be removed from the
current analysis of interest. <em>Random outliers</em> are assumed to be
due to chance alone and to belong to the correct distribution and,
therefore, should be retained.</p>
<p>It is recommended to <em>keep</em> observations which are expected to
be part of the distribution of interest, even if they are outliers <span class="citation">(Leys et al. 2019)</span>. However, if it is suspected
that the outliers belong to an alternative distribution, then those
observations could have a large impact on the results and call into
question their robustness, especially if significance is conditional on
their inclusion, so should be removed.</p>
<p>We should also keep in mind that there might be error outliers that
are not detected by statistical tools, but should nonetheless be found
and removed. For example, if we are studying the effects of X on Y among
teenagers and we have one observation from a 20-year-old, this
observation might not be a <em>statistical outlier</em>, but it is an
outlier in the <em>context</em> of our research, and should be
discarded. We could call these observations <em>undetected</em> error
outliers, in the sense that although they do not statistically stand
out, they do not belong to the theoretical or empirical distribution of
interest (e.g., teenagers). In this way, we should not blindly rely on
statistical outlier detection methods; doing our due diligence to
investigate undetected error outliers relative to our specific research
question is also essential for valid inferences.</p>
</div>
<div class="section level3">
<h3 id="winsorization">Winsorization<a class="anchor" aria-label="anchor" href="#winsorization"></a>
</h3>
<p><em>Removing</em> outliers can in this case be a valid strategy, and
ideally one would report results with and without outliers to see the
extent of their impact on results. This approach however can reduce
statistical power. Therefore, some propose a <em>recoding</em> approach,
namely, winsorization: bringing outliers back within acceptable limits
<span class="citation">(e.g., 3 MADs, Tukey and McLaughlin 1963)</span>.
However, if possible, it is recommended to collect enough data so that
even after removing outliers, there is still sufficient statistical
power without having to resort to winsorization <span class="citation">(Leys et al. 2019)</span>.</p>
<p>The <em>easystats</em> ecosystem makes it easy to incorporate this
step into your workflow through the <code><a href="https://easystats.github.io/datawizard/reference/winsorize.html" class="external-link">winsorize()</a></code> function of
<em>{datawizard}</em>, a lightweight R package to facilitate data
wrangling and statistical transformations <span class="citation">(Patil
et al. 2022)</span>. This procedure will bring back univariate outliers
within the limits of ‘acceptable’ values, based either on the
percentile, the <em>z</em> score, or its robust alternative based on the
MAD.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span><span class="op">[</span><span class="fl">1501</span><span class="op">:</span><span class="fl">1502</span>, <span class="op">]</span> <span class="co"># See outliers rows</span></span></code></pre></div>
<pre><code>&gt;      height weight
&gt; 1501    100    258
&gt; 1502    100    200</code></pre>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Winsorizing using the MAD</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/datawizard/" class="external-link">datawizard</a></span><span class="op">)</span></span>
<span><span class="va">winsorized_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://easystats.github.io/datawizard/reference/winsorize.html" class="external-link">winsorize</a></span><span class="op">(</span><span class="va">data</span>, method <span class="op">=</span> <span class="st">"zscore"</span>, robust <span class="op">=</span> <span class="cn">TRUE</span>, threshold <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co"># Values &gt; +/- MAD have been winsorized</span></span>
<span><span class="va">winsorized_data</span><span class="op">[</span><span class="fl">1501</span><span class="op">:</span><span class="fl">1502</span>, <span class="op">]</span></span></code></pre></div>
<pre><code>&gt;      height weight
&gt; 1501     83    188
&gt; 1502     83    188</code></pre>
</div>
<div class="section level3">
<h3 id="the-importance-of-transparency">The Importance of Transparency<a class="anchor" aria-label="anchor" href="#the-importance-of-transparency"></a>
</h3>
<p>Once again, it is a critical part of a sound outlier treatment that
regardless of which SOD method used, it should be reported in a
reproducible manner. Ideally, the handling of outliers should be
specified <em>a priori</em> with as much detail as possible, and
preregistered, to limit researchers’ degrees of freedom and therefore
risks of false positives <span class="citation">(Leys et al.
2019)</span>. This is especially true given that interesting outliers
and random outliers are often times hard to distinguish in practice.
Thus, researchers should always prioritize transparency and report all
of the following information: (a) how many outliers were identified
(including percentage); (b) according to which method and criteria, (c)
using which function of which R package (if applicable), and (d) how
they were handled (excluded or winsorized, if the latter, using what
threshold). If at all possible, (e) the corresponding code script along
with the data should be shared on a public repository like the Open
Science Framework (OSF), so that the exclusion criteria can be
reproduced precisely.</p>
</div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>In this vignette, we have showed how to investigate outliers using
the <code><a href="../reference/check_outliers.html">check_outliers()</a></code> function of the <em>{performance}</em>
package while following current good practices. However, best practice
for outlier treatment does not stop at using appropriate statistical
algorithms, but entails respecting existing recommendations, such as
preregistration, reproducibility, consistency, transparency, and
justification. Ideally, one would additionally also report the package,
function, and threshold used (linking to the full code when possible).
We hope that this paper and the accompanying
<code>check_outlier()</code> function of <em>easystats</em> will help
researchers engage in good research practices while providing a smooth
outlier detection experience.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-cook1977detection" class="csl-entry">
Cook, R. Dennis. 1977. <span>“Detection of Influential Observation in
Linear Regression.”</span> <em>Technometrics</em> 19 (1): 15–18. <a href="https://doi.org/10.1080/00401706.1977.10489493" class="external-link">https://doi.org/10.1080/00401706.1977.10489493</a>.
</div>
<div id="ref-gnanadesikan1972robust" class="csl-entry">
Gnanadesikan, R., and J. R Kettenring. 1972. <span>“Robust Estimates,
Residuals, and Outlier Detection with Multiresponse Data.”</span>
<em>Biometrics</em>, 81–124.
</div>
<div id="ref-leys2019outliers" class="csl-entry">
Leys, Christophe, Marie Delacre, Youri L. Mora, Daniël Lakens, and
Christophe Ley. 2019. <span>“How to Classify, Detect, and Manage
Univariate and Multivariate Outliers, with Emphasis on
Pre-Registration.”</span> <em>International Review of Social
Psychology</em>, ahead of print. <a href="https://doi.org/10.5334/irsp.289" class="external-link">https://doi.org/10.5334/irsp.289</a>.
</div>
<div id="ref-leys2018outliers" class="csl-entry">
Leys, Christophe, Olivier Klein, Yves Dominicy, and Christophe Ley.
2018. <span>“Detecting Multivariate Outliers: Use a Robust Variant of
the Mahalanobis Distance.”</span> <em>Journal of Experimental Social
Psychology</em> 74: 150–56. <a href="https://doi.org/10.1016/j.jesp.2017.09.011" class="external-link">https://doi.org/10.1016/j.jesp.2017.09.011</a>.
</div>
<div id="ref-leys2013outliers" class="csl-entry">
Leys, Christophe, Christophe Ley, Olivier Klein, Philippe Bernard, and
Laurent Licata. 2013. <span>“Detecting Outliers: Do Not Use Standard
Deviation Around the Mean, Use Absolute Deviation Around the
Median.”</span> <em>Journal of Experimental Social Psychology</em> 49
(4): 764–66. <a href="https://doi.org/10.1016/j.jesp.2013.03.013" class="external-link">https://doi.org/10.1016/j.jesp.2013.03.013</a>.
</div>
<div id="ref-ludecke2021performance" class="csl-entry">
Lüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Philip
Waggoner, and Dominique Makowski. 2021. <span>“<span class="nocase">performance</span>: An <span>R</span> Package for
Assessment, Comparison and Testing of Statistical Models.”</span>
<em>Journal of Open Source Software</em> 6 (60): 3139. <a href="https://doi.org/10.21105/joss.03139" class="external-link">https://doi.org/10.21105/joss.03139</a>.
</div>
<div id="ref-easystatspackage" class="csl-entry">
Lüdecke, Daniel, Dominique Makowski, Mattan S. Ben-Shachar, et al.
(2019) 2023. <em><span class="nocase">easystats</span>: Streamline Model
Interpretation, Visualization, and Reporting</em>. January 28, released
February 4. <a href="https://easystats.github.io/easystats/" class="external-link">https://easystats.github.io/easystats/</a>.
</div>
<div id="ref-mcelreath2020statistical" class="csl-entry">
McElreath, Richard. 2020. <em>Statistical Rethinking: A Bayesian Course
with Examples in <span>R</span> and Stan</em>. CRC press.
</div>
<div id="ref-patil2022datawizard" class="csl-entry">
Patil, Indrajeet, Dominique Makowski, Mattan S. Ben-Shachar, Brenton M.
Wiernik, Etienne Bacher, and Daniel Lüdecke. 2022. <span>“<span class="nocase">datawizard</span>: An <span>R</span> Package for Easy
Data Preparation and Statistical Transformations.”</span> <em>Journal of
Open Source Software</em> 7 (78): 4684. <a href="https://doi.org/10.21105/joss.04684" class="external-link">https://doi.org/10.21105/joss.04684</a>.
</div>
<div id="ref-ratcliff1993methods" class="csl-entry">
Ratcliff, Roger. 1993. <span>“Methods for Dealing with Reaction Time
Outliers.”</span> <em>Psychological Bulletin</em> 114 (3): 510. <a href="https://doi.org/10.1037/0033-2909.114.3.510" class="external-link">https://doi.org/10.1037/0033-2909.114.3.510</a>.
</div>
<div id="ref-simmons2011false" class="csl-entry">
Simmons, Joseph P., Leif D. Nelson, and Uri Simonsohn. 2011.
<span>“False-Positive Psychology: Undisclosed Flexibility in Data
Collection and Analysis Allows Presenting Anything as
Significant.”</span> <em>Psychological Science</em> 22 (11): 1359–66. <a href="https://doi.org/10.1177/0956797611417632" class="external-link">https://doi.org/10.1177/0956797611417632</a>.
</div>
<div id="ref-tukey1963less" class="csl-entry">
Tukey, John W, and Donald H McLaughlin. 1963. <span>“Less Vulnerable
Confidence and Significance Procedures for Location Based on a Single
Sample: Trimming/Winsorization 1.”</span> <em>Sankhy<span>ā</span>: The
Indian Journal of Statistics, Series A</em>, 331–52.
</div>
<div id="ref-van1995statistical" class="csl-entry">
Van Zandt, Trisha, and Roger Ratcliff. 1995. <span>“Statistical
Mimicking of Reaction Time Data: Single-Process Models, Parameter
Variability, and Mixtures.”</span> <em>Psychonomic Bulletin &amp;
Review</em> 2 (1): 20–54. <a href="https://doi.org/10.3758/BF03214411" class="external-link">https://doi.org/10.3758/BF03214411</a>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://github.com/strengejacke" class="external-link">Daniel Lüdecke</a>, <a href="https://dominiquemakowski.github.io/" class="external-link">Dominique Makowski</a>, <a href="https://home.msbstats.info/" class="external-link">Mattan S. Ben-Shachar</a>, <a href="https://sites.google.com/site/indrajeetspatilmorality/" class="external-link">Indrajeet Patil</a>, Philip Waggoner, <a href="https://wiernik.org/" class="external-link">Brenton M. Wiernik</a>, <a href="https://remi-theriault.com/" class="external-link">Rémi Thériault</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.9000.</p>
</div>

    </footer>
</div>





  </body>
</html>
