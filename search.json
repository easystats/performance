[{"path":[]},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement d.luedecke@uke.de. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://easystats.github.io/performance/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://easystats.github.io/performance/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to performance","title":"Contributing to performance","text":"outlines propose change performance.","code":""},{"path":"https://easystats.github.io/performance/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to performance","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. want fix typos documentation, please edit related .R file R/ folder. edit .Rd file man/.","code":""},{"path":"https://easystats.github.io/performance/CONTRIBUTING.html","id":"filing-an-issue","dir":"","previous_headings":"","what":"Filing an issue","title":"Contributing to performance","text":"easiest way propose change new feature file issue. ’ve found bug, may also create associated issue. possible, try illustrate proposal bug minimal reproducible example.","code":""},{"path":"https://easystats.github.io/performance/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull requests","title":"Contributing to performance","text":"Please create Git branch pull request (PR). contributed code roughly follow R style guide, particular easystats convention code-style. performance uses roxygen2, Markdown syntax, documentation. performance uses testthat. Adding tests PR makes easier merge PR code base. PR user-visible change, may add bullet top NEWS.md describing changes made. may optionally add GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"https://easystats.github.io/performance/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to performance","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://easystats.github.io/performance/articles/compare.html","id":"comparing-vs--testing","dir":"Articles","previous_headings":"","what":"Comparing vs. Testing","title":"Compare, Test, and Select Models","text":"Let’s imagine interested explaining variability Sepal.Length using 3 different predictors. , can build 3 linear models.","code":"model1 <- lm(Sepal.Length ~ Petal.Length, data = iris) model2 <- lm(Sepal.Length ~ Petal.Width, data = iris) model3 <- lm(Sepal.Length ~ Sepal.Width, data = iris)"},{"path":"https://easystats.github.io/performance/articles/compare.html","id":"comparing-indices-of-model-performance","dir":"Articles","previous_headings":"Comparing vs. Testing","what":"Comparing Indices of Model Performance","title":"Compare, Test, and Select Models","text":"eponymous function package, performance(), can used compute different indices performance (umbrella term indices fit). Indices model performance multiple models, one can obtain useful table compare indices glance using compare_performance() function. Comparison Model Performance Indices remember stats lessons, comparing different model fits, like choose model high \\(R^2\\) value (measure much variance explained predictors), low AIC BIC values, low root mean squared error (RMSE). Based criteria, can immediately see model1 best fit. don’t like looking tables, can also plot using plotting method supported see package:  , see: https://easystats.github.io/see/articles/performance.html","code":"library(performance) library(insight) library(magrittr) # for pipe operator  # we will use `print_md` function to display a well-formatted table performance(model1) %>%   print_md() compare_performance(model1, model2, model3) %>%   print_md() library(see)  plot(compare_performance(model1, model2, model3))"},{"path":"https://easystats.github.io/performance/articles/compare.html","id":"testing-models","dir":"Articles","previous_headings":"Comparing vs. Testing","what":"Testing Models","title":"Compare, Test, and Select Models","text":"comparing indices often useful, making decision (instance, model keep drop) can often hard, indices can give conflicting suggestions. Additionally, sometimes unclear index favour given context. one reason tests useful, facilitate decisions via (infamous) “significance” indices, like p-values (frequentist framework) Bayes Factors (Bayesian framework). model compared model1. However, tests also strong limitations shortcomings, used one criterion rule ! can find information tests .","code":"test_performance(model1, model2, model3) %>%   print_md()"},{"path":"https://easystats.github.io/performance/articles/compare.html","id":"experimenting","dir":"Articles","previous_headings":"Comparing vs. Testing","what":"Experimenting","title":"Compare, Test, and Select Models","text":"Although shown examples simple linear models, highly encourage try functions models choosing. example, functions work mixed-effects regression models, Bayesian regression models, etc. demonstrate , run Bayesian versions linear regression models just compared: Comparison Model Performance Indices Note , since Bayesian regression models, function automatically picked appropriate indices compare! unfamiliar , explore . Now ’s turn play! :)","code":"library(rstanarm)  model1 <- stan_glm(Sepal.Length ~ Petal.Length, data = iris, refresh = 0) model2 <- stan_glm(Sepal.Length ~ Petal.Width, data = iris, refresh = 0) model3 <- stan_glm(Sepal.Length ~ Sepal.Width, data = iris, refresh = 0)  compare_performance(model1, model2, model3) %>%   print_md()"},{"path":"https://easystats.github.io/performance/articles/r2.html","id":"what-is-the-r2","dir":"Articles","previous_headings":"","what":"What is the R2?","title":"R-squared (R2)","text":"coefficient determination, denoted \\(R^2\\) pronounced “R squared”, typically corresponds proportion variance dependent variable (response) explained (.e., predicted) independent variables (predictors). “absolute” index goodness--fit, ranging 0 1 (often expressed percentage), can used model performance assessment models comparison.","code":""},{"path":"https://easystats.github.io/performance/articles/r2.html","id":"different-types-of-r2","dir":"Articles","previous_headings":"","what":"Different types of R2","title":"R-squared (R2)","text":"models become complex, computation \\(R^2\\) becomes increasingly less straightforward. Currently, depending context regression model object, one can choose following measures supported performance: Bayesian \\(R^2\\) Cox & Snell’s \\(R^2\\) Efron’s \\(R^2\\) Kullback-Leibler \\(R^2\\) LOO-adjusted \\(R^2\\) McFadden’s \\(R^2\\) McKelvey & Zavoinas \\(R^2\\) Nagelkerke’s \\(R^2\\) Nakagawa’s \\(R^2\\) mixed models Somers’ \\(D_{xy}\\) rank correlation binary outcomes Tjur’s \\(R^2\\) - coefficient determination (D) Xu’ \\(R^2\\) (Omega-squared) \\(R^2\\) models zero-inflation COMPLETED. begin, let’s first load package.","code":"library(performance)"},{"path":"https://easystats.github.io/performance/articles/r2.html","id":"r2-for-lm","dir":"Articles","previous_headings":"","what":"R2 for lm","title":"R-squared (R2)","text":"","code":"m_lm <- lm(wt ~ am * cyl, data = mtcars)  r2(m_lm) > # R2 for Linear Regression >        R2: 0.724 >   adj. R2: 0.694"},{"path":"https://easystats.github.io/performance/articles/r2.html","id":"r2-for-glm","dir":"Articles","previous_headings":"","what":"R2 for glm","title":"R-squared (R2)","text":"context generalized linear model (e.g., logistic model outcome binary), \\(R^2\\) doesn’t measure percentage “explained variance”, concept doesn’t apply. However, \\(R^2\\)s adapted GLMs retained name “R2”, mostly similar properties (range, sensitivity, interpretation amount explanatory power).","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/articles/r2.html","id":"marginal-vs--conditional-r2","dir":"Articles","previous_headings":"R2 for Mixed Models","what":"Marginal vs. Conditional R2","title":"R-squared (R2)","text":"mixed models, performance return two different \\(R^2\\)s: conditional \\(R^2\\) marginal \\(R^2\\) marginal \\(R^2\\) considers variance fixed effects (without random effects), conditional \\(R^2\\) takes fixed random effects account (.e., total model). Note r2 functions return \\(R^2\\) values. encourage users instead always use model_performance function get comprehensive set indices model fit. , current vignette, like exclusively focus family functions talk measure.","code":"library(lme4)  # defining a linear mixed-effects model model <- lmer(Petal.Length ~ Petal.Width + (1 | Species), data = iris)  r2(model) > # R2 for Mixed Models >  >   Conditional R2: 0.933 >      Marginal R2: 0.303 model_performance(model) > # Indices of model performance >  > AIC     |    AICc |     BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma > ----------------------------------------------------------------------------- > 159.036 | 159.312 | 171.079 |      0.933 |      0.303 | 0.904 | 0.373 | 0.378"},{"path":"https://easystats.github.io/performance/articles/r2.html","id":"r2-for-bayesian-models","dir":"Articles","previous_headings":"","what":"R2 for Bayesian Models","title":"R-squared (R2)","text":"discussed , mixed-effects models, two components associated \\(R^2\\). Let’s look another regression analysis carried BayesFactor package.","code":"library(rstanarm)  model <- stan_glm(mpg ~ wt + cyl, data = mtcars, refresh = 0) r2(model) > # Bayesian R2 with Compatibility Interval >  >   Conditional R2: 0.816 (95% CI [0.704, 0.897]) # defining a Bayesian mixed-effects model model <- stan_lmer(Petal.Length ~ Petal.Width + (1 | Species), data = iris, refresh = 0)  r2(model) > # Bayesian R2 with Compatibility Interval >  >   Conditional R2: 0.953 (95% CI [0.942, 0.963]) >      Marginal R2: 0.825 (95% CI [0.720, 0.901]) library(BayesFactor) data(puzzles)  m1 <- anovaBF(extra ~ group + ID,   data = sleep,   whichRandom = \"ID\", progress = FALSE )  r2(m1) > # Bayesian R2 with Compatibility Interval >  >   Conditional R2: 0.773 (95% CI [0.439, 0.900]) >      Marginal R2: 0.124 (95% CI [2.468e-08, 0.252])  m2 <- generalTestBF(RT ~ shape * color + ID,   data = puzzles, whichRandom = \"ID\",   neverExclude = \"ID\", progress = FALSE )  r2(m2) > # Bayesian R2 with Compatibility Interval >  >   Conditional R2: 0.693 (95% CI [0.550, 0.782]) >      Marginal R2: 0.029 (95% CI [8.085e-08, 0.088])"},{"path":"https://easystats.github.io/performance/articles/r2.html","id":"comparing-change-in-r2-using-cohens-f","dir":"Articles","previous_headings":"","what":"Comparing change in R2 using Cohen’s f","title":"R-squared (R2)","text":"Cohen’s \\(f\\) (ANOVA fame) can used measure effect size context sequential multiple regression (.e., nested models). , comparing two models, can examine ratio increase \\(R^2\\) unexplained variance: \\[ f^{2}={R_{AB}^{2}-R_{}^{2} \\1-R_{AB}^{2}} \\] want know indices, can check details references functions compute .","code":"library(effectsize) data(hardlyworking) m1 <- lm(salary ~ xtra_hours, data = hardlyworking) m2 <- lm(salary ~ xtra_hours + n_comps + seniority, data = hardlyworking)  cohens_f_squared(m1, model2 = m2) > Cohen's f2 (partial) |      95% CI | R2_delta > --------------------------------------------- > 1.19                 | [0.99, Inf] |     0.17 >  > - One-sided CIs: upper bound fixed at [Inf]."},{"path":"https://easystats.github.io/performance/articles/r2.html","id":"interpretation","dir":"Articles","previous_headings":"","what":"Interpretation","title":"R-squared (R2)","text":"want know interpret \\(R^2\\) values, see interpretation guidelines.","code":""},{"path":"https://easystats.github.io/performance/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Lüdecke. Author, maintainer.            @strengejacke Dominique Makowski. Author, contributor.            @Dom_Makowski Mattan S. Ben-Shachar. Author, contributor.            @mattansb Indrajeet Patil. Author, contributor.            @patilindrajeets Philip Waggoner. Author, contributor. Brenton M. Wiernik. Author, contributor.            @bmwiernik Vincent Arel-Bundock. Contributor. Rémi Thériault. Contributor.            @rempsyc Martin Jullum. Reviewer. gjo11. Reviewer.","code":""},{"path":"https://easystats.github.io/performance/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lüdecke et al., (2021). performance: R Package Assessment, Comparison Testing Statistical Models. Journal Open Source Software, 6(60), 3139. https://doi.org/10.21105/joss.03139","code":"@Article{,   title = {{performance}: An {R} Package for Assessment, Comparison and Testing of Statistical Models},   author = {Daniel Lüdecke and Mattan S. Ben-Shachar and Indrajeet Patil and Philip Waggoner and Dominique Makowski},   year = {2021},   journal = {Journal of Open Source Software},   volume = {6},   number = {60},   pages = {3139},   doi = {10.21105/joss.03139}, }"},{"path":"https://easystats.github.io/performance/index.html","id":"performance-","dir":"","previous_headings":"","what":"Assessment of Regression Models Performance","title":"Assessment of Regression Models Performance","text":"Test model good model! crucial aspect building regression models evaluate quality modelfit. important investigate well models fit data fit indices report. Functions create diagnostic plots compute fit measures exist, however, mostly spread different packages. unique consistent approach assess model quality different kind models. primary goal performance package fill gap provide utilities computing indices model quality goodness fit. include measures like r-squared (R2), root mean squared error (RMSE) intraclass correlation coefficient (ICC) , also functions check (mixed) models overdispersion, zero-inflation, convergence singularity.","code":""},{"path":"https://easystats.github.io/performance/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Assessment of Regression Models Performance","text":"performance package available CRAN, latest development version available R-universe (rOpenSci). downloaded package, can load using: Tip Instead library(performance), use library(easystats). make features easystats-ecosystem available. stay updated, use easystats::install_latest().","code":"library(\"performance\")"},{"path":"https://easystats.github.io/performance/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Assessment of Regression Models Performance","text":"cite performance publications use:","code":"citation(\"performance\") #>  #> To cite package 'performance' in publications use: #>  #>   Lüdecke et al., (2021). performance: An R Package for Assessment, Comparison and #>   Testing of Statistical Models. Journal of Open Source Software, 6(60), 3139. #>   https://doi.org/10.21105/joss.03139 #>  #> A BibTeX entry for LaTeX users is #>  #>   @Article{, #>     title = {{performance}: An {R} Package for Assessment, Comparison and Testing of Statistical Models}, #>     author = {Daniel Lüdecke and Mattan S. Ben-Shachar and Indrajeet Patil and Philip Waggoner and Dominique Makowski}, #>     year = {2021}, #>     journal = {Journal of Open Source Software}, #>     volume = {6}, #>     number = {60}, #>     pages = {3139}, #>     doi = {10.21105/joss.03139}, #>   }"},{"path":"https://easystats.github.io/performance/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Assessment of Regression Models Performance","text":"nice introduction package youtube.","code":""},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/performance/index.html","id":"r-squared","dir":"","previous_headings":"The performance workflow > Assessing model quality","what":"R-squared","title":"Assessment of Regression Models Performance","text":"performance generic r2() function, computes r-squared many different models, including mixed effects Bayesian regression models. r2() returns list containing values related “appropriate” r-squared given model. different R-squared measures can also accessed directly via functions like r2_bayes(), r2_coxsnell() r2_nagelkerke() (see full list functions ). mixed models, conditional marginal R-squared returned. marginal R-squared considers variance fixed effects indicates much model’s variance explained fixed effects part . conditional R-squared takes fixed random effects account indicates much model’s variance explained “complete” model. frequentist mixed models, r2() (resp. r2_nakagawa()) computes mean random effect variances, thus r2() also appropriate mixed models complex random effects structures, like random slopes nested random effects (Johnson 2014; Nakagawa, Johnson, Schielzeth 2017).","code":"model <- lm(mpg ~ wt + cyl, data = mtcars) r2(model) #> # R2 for Linear Regression #>        R2: 0.830 #>   adj. R2: 0.819  model <- glm(am ~ wt + cyl, data = mtcars, family = binomial) r2(model) #> # R2 for Logistic Regression #>   Tjur's R2: 0.705  library(MASS) data(housing) model <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing) r2(model) #>   Nagelkerke's R2: 0.108 set.seed(123) library(rstanarm)  model <- stan_glmer(Petal.Length ~ Petal.Width + (1 | Species), data = iris, cores = 4)  r2(model) #> # Bayesian R2 with Compatibility Interval #>  #>   Conditional R2: 0.953 (95% CI [0.941, 0.963]) #>      Marginal R2: 0.824 (95% CI [0.713, 0.896])  library(lme4) model <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy) r2(model) #> # R2 for Mixed Models #>  #>   Conditional R2: 0.799 #>      Marginal R2: 0.279"},{"path":"https://easystats.github.io/performance/index.html","id":"intraclass-correlation-coefficient-icc","dir":"","previous_headings":"The performance workflow > Assessing model quality","what":"Intraclass Correlation Coefficient (ICC)","title":"Assessment of Regression Models Performance","text":"Similar R-squared, ICC provides information explained variance can interpreted “proportion variance explained grouping structure population” (Hox 2010). icc() calculates ICC various mixed model objects, including stanreg models. …models class brmsfit.","code":"library(lme4) model <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy) icc(model) #> # Intraclass Correlation Coefficient #>  #>     Adjusted ICC: 0.722 #>   Unadjusted ICC: 0.521 library(brms) set.seed(123) model <- brm(mpg ~ wt + (1 | cyl) + (1 + wt | gear), data = mtcars) icc(model) #> # Intraclass Correlation Coefficient #>  #>     Adjusted ICC: 0.930 #>   Unadjusted ICC: 0.771"},{"path":[]},{"path":"https://easystats.github.io/performance/index.html","id":"check-for-overdispersion","dir":"","previous_headings":"The performance workflow > Model diagnostics","what":"Check for overdispersion","title":"Assessment of Regression Models Performance","text":"Overdispersion occurs observed variance data higher expected variance model assumption (Poisson, variance roughly equals mean outcome). check_overdispersion() checks count model (including mixed models) overdispersed . Overdispersion can fixed either modelling dispersion parameter (possible packages), choosing different distributional family (like Quasi-Poisson, negative binomial, see (Gelman Hill 2007)).","code":"library(glmmTMB) data(Salamanders) model <- glm(count ~ spp + mined, family = poisson, data = Salamanders) check_overdispersion(model) #> # Overdispersion test #>  #>        dispersion ratio =    2.946 #>   Pearson's Chi-Squared = 1873.710 #>                 p-value =  < 0.001"},{"path":"https://easystats.github.io/performance/index.html","id":"check-for-zero-inflation","dir":"","previous_headings":"The performance workflow > Model diagnostics","what":"Check for zero-inflation","title":"Assessment of Regression Models Performance","text":"Zero-inflation ((Quasi-)Poisson models) indicated amount observed zeros larger amount predicted zeros, model underfitting zeros. cases, recommended use negative binomial zero-inflated models. Use check_zeroinflation() check zero-inflation present fitted model.","code":"model <- glm(count ~ spp + mined, family = poisson, data = Salamanders) check_zeroinflation(model) #> # Check for zero-inflation #>  #>    Observed zeros: 387 #>   Predicted zeros: 298 #>             Ratio: 0.77"},{"path":"https://easystats.github.io/performance/index.html","id":"check-for-singular-model-fits","dir":"","previous_headings":"The performance workflow > Model diagnostics","what":"Check for singular model fits","title":"Assessment of Regression Models Performance","text":"“singular” model fit means dimensions variance-covariance matrix estimated exactly zero. often occurs mixed models overly complex random effects structures. check_singularity() checks mixed models (class lme, merMod, glmmTMB MixMod) singularity, returns TRUE model fit singular. Remedies cure issues singular fits can found .","code":"library(lme4) data(sleepstudy)  # prepare data set.seed(123) sleepstudy$mygrp <- sample(1:5, size = 180, replace = TRUE) sleepstudy$mysubgrp <- NA for (i in 1:5) {     filter_group <- sleepstudy$mygrp == i     sleepstudy$mysubgrp[filter_group] <- sample(1:30, size = sum(filter_group), replace = TRUE) }  # fit strange model model <- lmer(Reaction ~ Days + (1 | mygrp/mysubgrp) + (1 | Subject), data = sleepstudy)  check_singularity(model) #> [1] TRUE"},{"path":"https://easystats.github.io/performance/index.html","id":"check-for-heteroskedasticity","dir":"","previous_headings":"The performance workflow > Model diagnostics","what":"Check for heteroskedasticity","title":"Assessment of Regression Models Performance","text":"Linear models assume constant error variance (homoskedasticity). check_heteroscedasticity() functions assess assumption violated:","code":"data(cars) model <- lm(dist ~ speed, data = cars)  check_heteroscedasticity(model) #> Warning: Heteroscedasticity (non-constant error variance) detected (p = 0.031)."},{"path":"https://easystats.github.io/performance/index.html","id":"comprehensive-visualization-of-model-checks","dir":"","previous_headings":"The performance workflow > Model diagnostics","what":"Comprehensive visualization of model checks","title":"Assessment of Regression Models Performance","text":"performance provides many functions check model assumptions, like check_collinearity(), check_normality() check_heteroscedasticity(). get comprehensive check, use check_model().","code":"# defining a model model <- lm(mpg ~ wt + am + gear + vs * cyl, data = mtcars)  # checking model assumptions check_model(model)"},{"path":"https://easystats.github.io/performance/index.html","id":"model-performance-summaries","dir":"","previous_headings":"The performance workflow","what":"Model performance summaries","title":"Assessment of Regression Models Performance","text":"model_performance() computes indices model performance regression models. Depending model object, typical indices might r-squared, AIC, BIC, RMSE, ICC LOOIC.","code":""},{"path":"https://easystats.github.io/performance/index.html","id":"linear-model","dir":"","previous_headings":"The performance workflow > Model performance summaries","what":"Linear model","title":"Assessment of Regression Models Performance","text":"","code":"m1 <- lm(mpg ~ wt + cyl, data = mtcars) model_performance(m1) #> # Indices of model performance #>  #> AIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma #> ----------------------------------------------------- #> 156.010 | 161.873 | 0.830 |     0.819 | 2.444 | 2.568"},{"path":"https://easystats.github.io/performance/index.html","id":"logistic-regression","dir":"","previous_headings":"The performance workflow > Model performance summaries","what":"Logistic regression","title":"Assessment of Regression Models Performance","text":"","code":"m2 <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") model_performance(m2) #> # Indices of model performance #>  #> AIC    |    BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP #> -------------------------------------------------------------------------------------------- #> 31.298 | 35.695 |     0.478 | 0.359 | 0.934 |    0.395 |   -14.903 |           0.095 | 0.743"},{"path":"https://easystats.github.io/performance/index.html","id":"linear-mixed-model","dir":"","previous_headings":"The performance workflow > Model performance summaries","what":"Linear mixed model","title":"Assessment of Regression Models Performance","text":"","code":"library(lme4) m3 <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy) model_performance(m3) #> # Indices of model performance #>  #> AIC      |     AICc |      BIC | R2 (cond.) | R2 (marg.) |   ICC |   RMSE |  Sigma #> ---------------------------------------------------------------------------------- #> 1755.628 | 1756.114 | 1774.786 |      0.799 |      0.279 | 0.722 | 23.438 | 25.592"},{"path":"https://easystats.github.io/performance/index.html","id":"models-comparison","dir":"","previous_headings":"The performance workflow","what":"Models comparison","title":"Assessment of Regression Models Performance","text":"compare_performance() function can used compare performance quality several models (including models different types).","code":"counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) outcome <- gl(3, 1, 9) treatment <- gl(3, 3) m4 <- glm(counts ~ outcome + treatment, family = poisson())  compare_performance(m1, m2, m3, m4) #> # Comparison of Model Performance Indices #>  #> Name |   Model |  AIC (weights) |  BIC (weights) |   RMSE |  Sigma | Score_log | Score_spherical |    R2 | R2 (adj.) | Tjur's R2 | Log_loss |   PCP | AICc (weights) | R2 (cond.) | R2 (marg.) |   ICC | Nagelkerke's R2 #> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ #> m1   |      lm |  156.0 (<.001) |  161.9 (<.001) |  2.444 |  2.568 |           |                 | 0.830 |     0.819 |           |          |       |        (>.999) |            |            |       |                 #> m2   |     glm |   31.3 (>.999) |   35.7 (>.999) |  0.359 |  0.934 |   -14.903 |           0.095 |       |           |     0.478 |    0.395 | 0.743 |        (>.999) |            |            |       |                 #> m3   | lmerMod | 1764.0 (<.001) | 1783.1 (<.001) | 23.438 | 25.592 |           |                 |       |           |           |          |       | 1764.5 (>.999) |      0.799 |      0.279 | 0.722 |                 #> m4   |     glm |   56.8 (<.001) |   57.7 (<.001) |  3.043 |  1.132 |    -2.598 |           0.324 |       |           |           |          |       |        (>.999) |            |            |       |           0.657"},{"path":"https://easystats.github.io/performance/index.html","id":"general-index-of-model-performance","dir":"","previous_headings":"The performance workflow > Models comparison","what":"General index of model performance","title":"Assessment of Regression Models Performance","text":"One can also easily compute composite index model performance sort models best one worse.","code":"compare_performance(m1, m2, m3, m4, rank = TRUE) #> # Comparison of Model Performance Indices #>  #> Name |   Model |   RMSE |  Sigma | AIC weights | BIC weights | Performance-Score #> -------------------------------------------------------------------------------- #> m2   |     glm |  0.359 |  0.934 |       1.000 |       1.000 |           100.00% #> m4   |     glm |  3.043 |  1.132 |    2.96e-06 |    1.63e-05 |            46.89% #> m1   |      lm |  2.444 |  2.568 |    8.30e-28 |    3.99e-28 |            46.09% #> m3   | lmerMod | 23.438 | 25.592 |    0.00e+00 |    0.00e+00 |             0.00%"},{"path":"https://easystats.github.io/performance/index.html","id":"visualisation-of-indices-of-models-performance","dir":"","previous_headings":"The performance workflow > Models comparison","what":"Visualisation of indices of models’ performance","title":"Assessment of Regression Models Performance","text":"Finally, provide convenient visualisation (see package must installed).","code":"plot(compare_performance(m1, m2, m4, rank = TRUE))"},{"path":"https://easystats.github.io/performance/index.html","id":"testing-models","dir":"","previous_headings":"The performance workflow","what":"Testing models","title":"Assessment of Regression Models Performance","text":"test_performance() (test_bf, Bayesian sister) carries relevant appropriate tests based input (instance, whether models nested ).","code":"set.seed(123) data(iris)  lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) lm3 <- lm(Sepal.Length ~ Species * Sepal.Width, data = iris) lm4 <- lm(Sepal.Length ~ Species * Sepal.Width + Petal.Length + Petal.Width, data = iris)  test_performance(lm1, lm2, lm3, lm4) #> Name | Model |       BF | Omega2 | p (Omega2) |    LR | p (LR) #> -------------------------------------------------------------- #> lm1  |    lm |          |        |            |       |        #> lm2  |    lm | 3.45e+26 |   0.69 |     < .001 | -6.25 | < .001 #> lm3  |    lm | 4.69e+07 |   0.36 |     < .001 | -3.44 | < .001 #> lm4  |    lm | 7.58e+29 |   0.73 |     < .001 | -7.77 | < .001 #> Each model is compared to lm1.  test_bf(lm1, lm2, lm3, lm4) #> Bayes Factors for Model Comparison #>  #>       Model                                                    BF #> [lm2] Species + Petal.Length                             3.45e+26 #> [lm3] Species * Sepal.Width                              4.69e+07 #> [lm4] Species * Sepal.Width + Petal.Length + Petal.Width 7.58e+29 #>  #> * Against Denominator: [lm1] Species #> *   Bayes Factor Type: BIC approximation"},{"path":"https://easystats.github.io/performance/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Assessment of Regression Models Performance","text":"Please note performance project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://easystats.github.io/performance/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Assessment of Regression Models Performance","text":"happy receive bug reports, suggestions, questions, () contributions fix problems add features. Please follow contributing guidelines mentioned : https://easystats.github.io/performance/CONTRIBUTING.html","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/binned_residuals.html","id":null,"dir":"Reference","previous_headings":"","what":"Binned residuals for binomial logistic regression — binned_residuals","title":"Binned residuals for binomial logistic regression — binned_residuals","text":"Check model quality binomial logistic regression models.","code":""},{"path":"https://easystats.github.io/performance/reference/binned_residuals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binned residuals for binomial logistic regression — binned_residuals","text":"","code":"binned_residuals(model, term = NULL, n_bins = NULL, ...)"},{"path":"https://easystats.github.io/performance/reference/binned_residuals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binned residuals for binomial logistic regression — binned_residuals","text":"model glm-object binomial-family. term Name independent variable x. NULL, average residuals categories term plotted; else, average residuals estimated probabilities response plotted. n_bins Numeric, number bins divide data. n_bins = NULL, square root number observations taken. ... Currently used.","code":""},{"path":"https://easystats.github.io/performance/reference/binned_residuals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binned residuals for binomial logistic regression — binned_residuals","text":"data frame representing data mapped accompanying plot. case residuals inside error bounds, points black. residuals outside error bounds (indicated grey-shaded area), blue points indicate residuals OK, red points indicate model - -fitting relevant range estimated probabilities.","code":""},{"path":"https://easystats.github.io/performance/reference/binned_residuals.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binned residuals for binomial logistic regression — binned_residuals","text":"Binned residual plots achieved “dividing data categories (bins) based fitted values, plotting average residual versus average fitted value bin.” (Gelman, Hill 2007: 97). model true, one expect 95% residuals fall inside error bounds.  term NULL, one can compare residuals relation specific model predictor. may helpful check term fit better transformed, e.g. rising falling pattern residuals along x-axis signal consider taking logarithm predictor (cf. Gelman Hill 2007, pp. 97-98).","code":""},{"path":"https://easystats.github.io/performance/reference/binned_residuals.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Binned residuals for binomial logistic regression — binned_residuals","text":"binned_residuals() returns data frame, however, print() method returns short summary result. data frame used plotting. plot() method, turn, creates ggplot-object.","code":""},{"path":"https://easystats.github.io/performance/reference/binned_residuals.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binned residuals for binomial logistic regression — binned_residuals","text":"Gelman, ., Hill, J. (2007). Data analysis using regression multilevel/hierarchical models. Cambridge; New York: Cambridge University Press.","code":""},{"path":"https://easystats.github.io/performance/reference/binned_residuals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binned residuals for binomial logistic regression — binned_residuals","text":"","code":"model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") result <- binned_residuals(model) result #> Warning: Probably bad model fit. Only about 50% of the residuals are inside the error bounds. #>   # look at the data frame as.data.frame(result) #>         xbar        ybar n       x.lo       x.hi         se   ci_range #> 1 0.03786483 -0.03786483 5 0.01744776 0.06917366 0.01899089 0.00968941 #> 2 0.09514191 -0.09514191 5 0.07087498 0.15160143 0.02816391 0.01436960 #> 3 0.25910531  0.07422802 6 0.17159955 0.35374001 0.42499664 0.21683901 #> 4 0.47954643 -0.07954643 5 0.38363314 0.54063600 0.49728294 0.25372045 #> 5 0.71108931  0.28891069 5 0.57299903 0.89141359 0.10975381 0.05599787 #> 6 0.97119262 -0.13785929 6 0.91147360 0.99815623 0.30361062 0.15490623 #>        CI_low     CI_high group #> 1 -0.05685572 -0.01887394    no #> 2 -0.12330581 -0.06697800    no #> 3 -0.35076862  0.49922466   yes #> 4 -0.57682937  0.41773650   yes #> 5  0.17915688  0.39866451    no #> 6 -0.44146992  0.16575133   yes  # plot if (require(\"see\")) {   plot(result) } #> Loading required package: see #> Warning: Computation failed in `stat_smooth()` #> Caused by error in `smooth.construct.tp.smooth.spec()`: #> ! A term has fewer unique covariate combinations than specified maximum degrees of freedom"},{"path":"https://easystats.github.io/performance/reference/check_autocorrelation.html","id":null,"dir":"Reference","previous_headings":"","what":"Check model for independence of residuals. — check_autocorrelation","title":"Check model for independence of residuals. — check_autocorrelation","text":"Check model independence residuals, .e. autocorrelation error terms.","code":""},{"path":"https://easystats.github.io/performance/reference/check_autocorrelation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check model for independence of residuals. — check_autocorrelation","text":"","code":"check_autocorrelation(x, ...)  # S3 method for default check_autocorrelation(x, nsim = 1000, ...)"},{"path":"https://easystats.github.io/performance/reference/check_autocorrelation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check model for independence of residuals. — check_autocorrelation","text":"x model object. ... Currently used. nsim Number simulations Durbin-Watson-Test.","code":""},{"path":"https://easystats.github.io/performance/reference/check_autocorrelation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check model for independence of residuals. — check_autocorrelation","text":"Invisibly returns p-value test statistics. p-value < 0.05 indicates autocorrelated residuals.","code":""},{"path":"https://easystats.github.io/performance/reference/check_autocorrelation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check model for independence of residuals. — check_autocorrelation","text":"Performs Durbin-Watson-Test check autocorrelated residuals. case autocorrelation, robust standard errors return accurate results estimates, maybe mixed model error term cluster groups used.","code":""},{"path":"https://easystats.github.io/performance/reference/check_autocorrelation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check model for independence of residuals. — check_autocorrelation","text":"","code":"m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars) check_autocorrelation(m) #> OK: Residuals appear to be independent and not autocorrelated (p = 0.282)."},{"path":"https://easystats.github.io/performance/reference/check_clusterstructure.html","id":null,"dir":"Reference","previous_headings":"","what":"Check suitability of data for clustering — check_clusterstructure","title":"Check suitability of data for clustering — check_clusterstructure","text":"checks whether data appropriate clustering using Hopkins' H statistic given data. value Hopkins statistic close 0 (0.5), can reject null hypothesis conclude dataset significantly clusterable. value H lower 0.25 indicates clustering tendency 90% confidence level. visual assessment cluster tendency (VAT) approach (Bezdek Hathaway, 2002) consists investigating heatmap ordered dissimilarity matrix. Following , one can potentially detect clustering tendency counting number square shaped blocks along diagonal.","code":""},{"path":"https://easystats.github.io/performance/reference/check_clusterstructure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check suitability of data for clustering — check_clusterstructure","text":"","code":"check_clusterstructure(x, standardize = TRUE, distance = \"euclidean\", ...)"},{"path":"https://easystats.github.io/performance/reference/check_clusterstructure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check suitability of data for clustering — check_clusterstructure","text":"x data frame. standardize Standardize dataframe clustering (default). distance Distance method used. methods \"euclidean\" (default) exploratory context clustering tendency. See stats::dist() list available methods. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/check_clusterstructure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check suitability of data for clustering — check_clusterstructure","text":"H statistic (numeric)","code":""},{"path":"https://easystats.github.io/performance/reference/check_clusterstructure.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check suitability of data for clustering — check_clusterstructure","text":"Lawson, R. G., & Jurs, P. C. (1990). New index clustering tendency application chemical problems. Journal chemical information computer sciences, 30(1), 36-41. Bezdek, J. C., & Hathaway, R. J. (2002, May). VAT: tool visual assessment (cluster) tendency. Proceedings 2002 International Joint Conference Neural Networks. IJCNN02 (3), 2225-2230. IEEE.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/check_clusterstructure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check suitability of data for clustering — check_clusterstructure","text":"","code":"# \\donttest{ library(performance) check_clusterstructure(iris[, 1:4]) #> # Clustering tendency #>  #> The dataset is suitable for clustering (Hopkins' H = 0.18). #>  plot(check_clusterstructure(iris[, 1:4]))  # }"},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for multicollinearity of model terms — check_collinearity","title":"Check for multicollinearity of model terms — check_collinearity","text":"check_collinearity() checks regression models multicollinearity calculating variance inflation factor (VIF). multicollinearity() alias check_collinearity(). check_concurvity() wrapper around mgcv::concurvity(), can considered collinearity check smooth terms GAMs. Confidence intervals VIF tolerance based Marcoulides et al. (2019, Appendix B).","code":""},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for multicollinearity of model terms — check_collinearity","text":"","code":"check_collinearity(x, ...)  multicollinearity(x, ...)  # S3 method for default check_collinearity(x, ci = 0.95, verbose = TRUE, ...)  # S3 method for glmmTMB check_collinearity(   x,   component = c(\"all\", \"conditional\", \"count\", \"zi\", \"zero_inflated\"),   ci = 0.95,   verbose = TRUE,   ... )  check_concurvity(x, ...)"},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for multicollinearity of model terms — check_collinearity","text":"x model object (least respond vcov(), possible, also model.matrix() - however, also work without model.matrix()). ... Currently used. ci Confidence Interval (CI) level VIF tolerance values. verbose Toggle warnings messages. component models zero-inflation component, multicollinearity can checked conditional model (count component, component = \"conditional\" component = \"count\"), zero-inflation component (component = \"zero_inflated\" component = \"zi\") components (component = \"\"). Following model-classes currently supported: hurdle, zeroinfl, zerocount, MixMod glmmTMB.","code":""},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for multicollinearity of model terms — check_collinearity","text":"data frame information name model term, variance inflation factor associated confidence intervals, factor standard error increased due possible correlation terms, tolerance values (including confidence intervals), tolerance = 1/vif.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"multicollinearity","dir":"Reference","previous_headings":"","what":"Multicollinearity","title":"Check for multicollinearity of model terms — check_collinearity","text":"Multicollinearity confused raw strong correlation predictors. matters association one predictor variables, conditional variables model. nutshell, multicollinearity means know effect one predictor, value knowing predictor rather low. Thus, one predictors help much terms better understanding model predicting outcome. consequence, multicollinearity problem, model seems suggest predictors question seems reliably associated outcome (low estimates, high standard errors), although predictors actually strongly associated outcome, .e. indeed might strong effect (McElreath 2020, chapter 6.1).  Multicollinearity might arise third, unobserved variable causal effect two predictors associated outcome. cases, actual relationship matters association unobserved variable outcome.  Remember: “Pairwise correlations problem. conditional associations - correlations - matter.” (McElreath 2020, p. 169)","code":""},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"interpretation-of-the-variance-inflation-factor","dir":"Reference","previous_headings":"","what":"Interpretation of the Variance Inflation Factor","title":"Check for multicollinearity of model terms — check_collinearity","text":"variance inflation factor measure analyze magnitude multicollinearity model terms. VIF less 5 indicates low correlation predictor predictors. value 5 10 indicates moderate correlation, VIF values larger 10 sign high, tolerable correlation model predictors (James et al. 2013). Increased SE column output indicates much larger standard error due association predictors conditional remaining variables model.","code":""},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"multicollinearity-and-interaction-terms","dir":"Reference","previous_headings":"","what":"Multicollinearity and Interaction Terms","title":"Check for multicollinearity of model terms — check_collinearity","text":"interaction terms included model, high VIF values expected. portion multicollinearity among component terms interaction also called \"inessential ill-conditioning\", leads inflated VIF values typically seen models interaction terms (Francoeur 2013).","code":""},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"concurvity-for-smooth-terms-in-generalized-additive-models","dir":"Reference","previous_headings":"","what":"Concurvity for Smooth Terms in Generalized Additive Models","title":"Check for multicollinearity of model terms — check_collinearity","text":"check_concurvity() wrapper around mgcv::concurvity(), can considered collinearity check smooth terms GAMs. “Concurvity occurs smooth term model approximated one smooth terms model.” (see ?mgcv::concurvity). check_concurvity() returns column named VIF, \"worst\" measure. mgcv::concurvity() range 0 1, VIF value 1 / (1 - worst), make interpretation comparable classical VIF values, .e. 1 indicates problems, higher values indicate increasing lack identifiability. VIF proportion column equals \"estimate\" column mgcv::concurvity(), ranging 0 (problem) 1 (total lack identifiability).","code":""},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Check for multicollinearity of model terms — check_collinearity","text":"code compute confidence intervals VIF tolerance values adapted Appendix B Marcoulides et al. paper. Thus, credits go authors original algorithm. also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check for multicollinearity of model terms — check_collinearity","text":"Francoeur, R. B. (2013). Sequential Residual Centering Resolve Low Sensitivity Moderated Regression? Simulations Cancer Symptom Clusters. Open Journal Statistics, 03(06), 24-44. James, G., Witten, D., Hastie, T., Tibshirani, R. (eds.). (2013). introduction statistical learning: applications R. New York: Springer. Marcoulides, K. M., Raykov, T. (2019). Evaluation Variance Inflation Factors Regression Models Using Latent Variable Modeling Methods. Educational Psychological Measurement, 79(5), 874–882. McElreath, R. (2020). Statistical rethinking: Bayesian course examples R Stan. 2nd edition. Chapman Hall/CRC. Vanhove, J. (2019). Collinearity disease needs curing. webpage","code":""},{"path":"https://easystats.github.io/performance/reference/check_collinearity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for multicollinearity of model terms — check_collinearity","text":"","code":"m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars) check_collinearity(m) #> # Check for Multicollinearity #>  #> Low Correlation #>  #>  Term  VIF    VIF 95% CI Increased SE Tolerance Tolerance 95% CI #>   cyl 5.41 [3.42,  9.04]         2.33      0.18     [0.11, 0.29] #>  #> Moderate Correlation #>  #>  Term  VIF    VIF 95% CI Increased SE Tolerance Tolerance 95% CI #>  gear 1.53  [1.19, 2.51]         1.24      0.65     [0.40, 0.84] #>    wt 5.05 [3.21,  8.41]         2.25      0.20     [0.12, 0.31] #>  disp 9.97 [6.08, 16.85]         3.16      0.10     [0.06, 0.16]  # plot results if (require(\"see\")) {   x <- check_collinearity(m)   plot(x) }"},{"path":"https://easystats.github.io/performance/reference/check_convergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Convergence test for mixed effects models — check_convergence","title":"Convergence test for mixed effects models — check_convergence","text":"check_convergence() provides alternative convergence test merMod-objects.","code":""},{"path":"https://easystats.github.io/performance/reference/check_convergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convergence test for mixed effects models — check_convergence","text":"","code":"check_convergence(x, tolerance = 0.001, ...)"},{"path":"https://easystats.github.io/performance/reference/check_convergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convergence test for mixed effects models — check_convergence","text":"x merMod glmmTMB-object. tolerance Indicates value convergence result accepted. smaller tolerance , stricter test . ... Currently used.","code":""},{"path":"https://easystats.github.io/performance/reference/check_convergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convergence test for mixed effects models — check_convergence","text":"TRUE convergence fine FALSE convergence suspicious. Additionally, convergence value returned attribute.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/check_convergence.html","id":"convergence-and-log-likelihood","dir":"Reference","previous_headings":"","what":"Convergence and log-likelihood","title":"Convergence test for mixed effects models — check_convergence","text":"Convergence problems typically arise model converged solution log-likelihood true maximum. may result unreliable overly complex (non-estimable) estimates standard errors.","code":""},{"path":"https://easystats.github.io/performance/reference/check_convergence.html","id":"inspect-model-convergence","dir":"Reference","previous_headings":"","what":"Inspect model convergence","title":"Convergence test for mixed effects models — check_convergence","text":"lme4 performs convergence-check (see ?lme4::convergence), however, discussed suggested one lme4-authors comment, check can strict. check_convergence() thus provides alternative convergence test merMod-objects.","code":""},{"path":"https://easystats.github.io/performance/reference/check_convergence.html","id":"resolving-convergence-issues","dir":"Reference","previous_headings":"","what":"Resolving convergence issues","title":"Convergence test for mixed effects models — check_convergence","text":"Convergence issues easy diagnose. help page ?lme4::convergence provides current advice resolve convergence issues. Another clue might large parameter values, e.g. estimates (scale linear predictor) larger 10 (non-identity link) generalized linear model might indicate complete separation. Complete separation can addressed regularization, e.g. penalized regression Bayesian regression appropriate priors fixed effects.","code":""},{"path":"https://easystats.github.io/performance/reference/check_convergence.html","id":"convergence-versus-singularity","dir":"Reference","previous_headings":"","what":"Convergence versus Singularity","title":"Convergence test for mixed effects models — check_convergence","text":"Note different meaning singularity convergence: singularity indicates issue \"true\" best estimate, .e. whether maximum likelihood estimation variance-covariance matrix random effects positive definite semi-definite. Convergence question whether can assume numerical optimization worked correctly .","code":""},{"path":"https://easystats.github.io/performance/reference/check_convergence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convergence test for mixed effects models — check_convergence","text":"","code":"if (require(\"lme4\")) {   data(cbpp)   set.seed(1)   cbpp$x <- rnorm(nrow(cbpp))   cbpp$x2 <- runif(nrow(cbpp))    model <- glmer(     cbind(incidence, size - incidence) ~ period + x + x2 + (1 + x | herd),     data = cbpp,     family = binomial()   )    check_convergence(model) } #> Loading required package: lme4 #> Loading required package: Matrix #> boundary (singular) fit: see help('isSingular') #> [1] TRUE #> attr(,\"gradient\") #> [1] 8.444972e-05  if (FALSE) { if (require(\"glmmTMB\")) {   model <- glmmTMB(     Sepal.Length ~ poly(Petal.Width, 4) * poly(Petal.Length, 4) +       (1 + poly(Petal.Width, 4) | Species),     data = iris   )   check_convergence(model) } }"},{"path":"https://easystats.github.io/performance/reference/check_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify the distribution of a model-family using machine learning — check_distribution","title":"Classify the distribution of a model-family using machine learning — check_distribution","text":"Choosing right distributional family regression models essential get accurate estimates standard errors. function may help check models' distributional family see model-family probably reconsidered. Since difficult exactly predict correct model family, consider function somewhat experimental.","code":""},{"path":"https://easystats.github.io/performance/reference/check_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify the distribution of a model-family using machine learning — check_distribution","text":"","code":"check_distribution(model)"},{"path":"https://easystats.github.io/performance/reference/check_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify the distribution of a model-family using machine learning — check_distribution","text":"model Typically, model (response residuals()). May also numeric vector.","code":""},{"path":"https://easystats.github.io/performance/reference/check_distribution.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Classify the distribution of a model-family using machine learning — check_distribution","text":"function uses internal random forest model classify distribution model-family. Currently, following distributions trained (.e. results check_distribution() may one following): \"bernoulli\", \"beta\", \"beta-binomial\", \"binomial\", \"chi\", \"exponential\", \"F\", \"gamma\", \"lognormal\", \"normal\", \"negative binomial\", \"negative binomial (zero-inflated)\", \"pareto\", \"poisson\", \"poisson (zero-inflated)\", \"uniform\" \"weibull\".  Note similarity certain distributions according shape, skewness, etc. Thus, predicted distribution may perfectly representing distributional family underlying fitted model, response value.  plot() method, shows probabilities predicted distributions, however, probability greater zero.","code":""},{"path":"https://easystats.github.io/performance/reference/check_distribution.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Classify the distribution of a model-family using machine learning — check_distribution","text":"function somewhat experimental might improved future releases. final decision model-family also based theoretical aspects information data model.  also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/performance/reference/check_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classify the distribution of a model-family using machine learning — check_distribution","text":"","code":"if (require(\"lme4\") && require(\"parameters\") &&   require(\"see\") && require(\"patchwork\") && require(\"randomForest\")) {   data(sleepstudy)    model <<- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)   check_distribution(model)   plot(check_distribution(model)) } #> Loading required package: parameters #> Loading required package: patchwork #> Loading required package: randomForest #> randomForest 4.7-1.1 #> Type rfNews() to see new features/changes/bug fixes. #> Warning: Removed 6 rows containing missing values (`geom_segment()`). #> Warning: Removed 6 rows containing missing values (`geom_point()`)."},{"path":"https://easystats.github.io/performance/reference/check_factorstructure.html","id":null,"dir":"Reference","previous_headings":"","what":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"checks whether data appropriate Factor Analysis (FA) running Bartlett's Test Sphericity Kaiser, Meyer, Olkin (KMO) Measure Sampling Adequacy (MSA).","code":""},{"path":"https://easystats.github.io/performance/reference/check_factorstructure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"","code":"check_factorstructure(x, ...)"},{"path":"https://easystats.github.io/performance/reference/check_factorstructure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"x dataframe. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/check_factorstructure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"list lists indices related sphericity KMO.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/check_factorstructure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check suitability of data for Factor Analysis (FA) — check_factorstructure","text":"","code":"library(performance) check_factorstructure(mtcars) #> # Is the data suitable for Factor Analysis? #>  #>   - KMO: The Kaiser, Meyer, Olkin (KMO) measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83). #>   - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001)."},{"path":"https://easystats.github.io/performance/reference/check_heterogeneity_bias.html","id":null,"dir":"Reference","previous_headings":"","what":"Check model predictor for heterogeneity bias — check_heterogeneity_bias","title":"Check model predictor for heterogeneity bias — check_heterogeneity_bias","text":"check_heterogeneity_bias() checks model predictors variables may cause heterogeneity bias, .e. variables within- /-effect.","code":""},{"path":"https://easystats.github.io/performance/reference/check_heterogeneity_bias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check model predictor for heterogeneity bias — check_heterogeneity_bias","text":"","code":"check_heterogeneity_bias(x, select = NULL, group = NULL)"},{"path":"https://easystats.github.io/performance/reference/check_heterogeneity_bias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check model predictor for heterogeneity bias — check_heterogeneity_bias","text":"x data frame mixed model object. select Character vector (formula) names variables select checked. x mixed model object, argument ignored. group Character vector (formula) name variable indicates group- cluster-ID. x model object, argument ignored.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/check_heterogeneity_bias.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check model predictor for heterogeneity bias — check_heterogeneity_bias","text":"","code":"data(iris) iris$ID <- sample(1:4, nrow(iris), replace = TRUE) # fake-ID check_heterogeneity_bias(iris, select = c(\"Sepal.Length\", \"Petal.Length\"), group = \"ID\") #> Possible heterogeneity bias due to following predictors: Sepal.Length, Petal.Length"},{"path":"https://easystats.github.io/performance/reference/check_heteroscedasticity.html","id":null,"dir":"Reference","previous_headings":"","what":"Check model for (non-)constant error variance — check_heteroscedasticity","title":"Check model for (non-)constant error variance — check_heteroscedasticity","text":"Significance testing linear regression models assumes model errors (residuals) constant variance. assumption violated p-values model longer reliable.","code":""},{"path":"https://easystats.github.io/performance/reference/check_heteroscedasticity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check model for (non-)constant error variance — check_heteroscedasticity","text":"","code":"check_heteroscedasticity(x, ...)  check_heteroskedasticity(x, ...)"},{"path":"https://easystats.github.io/performance/reference/check_heteroscedasticity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check model for (non-)constant error variance — check_heteroscedasticity","text":"x model object. ... Currently used.","code":""},{"path":"https://easystats.github.io/performance/reference/check_heteroscedasticity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check model for (non-)constant error variance — check_heteroscedasticity","text":"p-value test statistics. p-value < 0.05 indicates non-constant variance (heteroskedasticity).","code":""},{"path":"https://easystats.github.io/performance/reference/check_heteroscedasticity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check model for (non-)constant error variance — check_heteroscedasticity","text":"test hypothesis (non-)constant error also called Breusch-Pagan test (1979).","code":""},{"path":"https://easystats.github.io/performance/reference/check_heteroscedasticity.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Check model for (non-)constant error variance — check_heteroscedasticity","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/performance/reference/check_heteroscedasticity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check model for (non-)constant error variance — check_heteroscedasticity","text":"Breusch, T. S., Pagan, . R. (1979) simple test heteroscedasticity random coefficient variation. Econometrica 47, 1287-1294.","code":""},{"path":"https://easystats.github.io/performance/reference/check_heteroscedasticity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check model for (non-)constant error variance — check_heteroscedasticity","text":"","code":"m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars) check_heteroscedasticity(m) #> Warning: Heteroscedasticity (non-constant error variance) detected (p = 0.042). #>   # plot results if (require(\"see\")) {   x <- check_heteroscedasticity(m)   plot(x) }"},{"path":"https://easystats.github.io/performance/reference/check_homogeneity.html","id":null,"dir":"Reference","previous_headings":"","what":"Check model for homogeneity of variances — check_homogeneity","title":"Check model for homogeneity of variances — check_homogeneity","text":"Check model homogeneity variances groups described independent variables model.","code":""},{"path":"https://easystats.github.io/performance/reference/check_homogeneity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check model for homogeneity of variances — check_homogeneity","text":"","code":"check_homogeneity(x, method = c(\"bartlett\", \"fligner\", \"levene\", \"auto\"), ...)  # S3 method for afex_aov check_homogeneity(x, method = \"levene\", ...)"},{"path":"https://easystats.github.io/performance/reference/check_homogeneity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check model for homogeneity of variances — check_homogeneity","text":"x linear model ANOVA object. method Name method (underlying test) performed check homogeneity variances. May either \"levene\" Levene's Test Homogeneity Variance, \"bartlett\" Bartlett test (assuming normal distributed samples groups), \"fligner\" Fligner-Killeen test (rank-based, non-parametric test), \"auto\". latter case, Bartlett test used model response normal distributed, else Fligner-Killeen test used. ... Arguments passed car::leveneTest().","code":""},{"path":"https://easystats.github.io/performance/reference/check_homogeneity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check model for homogeneity of variances — check_homogeneity","text":"Invisibly returns p-value test statistics. p-value < 0.05 indicates significant difference variance groups.","code":""},{"path":"https://easystats.github.io/performance/reference/check_homogeneity.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Check model for homogeneity of variances — check_homogeneity","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/performance/reference/check_homogeneity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check model for homogeneity of variances — check_homogeneity","text":"","code":"model <<- lm(len ~ supp + dose, data = ToothGrowth) check_homogeneity(model) #> OK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.226). #>   # plot results if (require(\"see\")) {   result <- check_homogeneity(model)   plot(result) }"},{"path":"https://easystats.github.io/performance/reference/check_itemscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe Properties of Item Scales — check_itemscale","title":"Describe Properties of Item Scales — check_itemscale","text":"Compute various measures internal consistencies applied (sub)scales, items extracted using parameters::principal_components().","code":""},{"path":"https://easystats.github.io/performance/reference/check_itemscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe Properties of Item Scales — check_itemscale","text":"","code":"check_itemscale(x)"},{"path":"https://easystats.github.io/performance/reference/check_itemscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe Properties of Item Scales — check_itemscale","text":"x object class parameters_pca, returned parameters::principal_components().","code":""},{"path":"https://easystats.github.io/performance/reference/check_itemscale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe Properties of Item Scales — check_itemscale","text":"list data frames, related measures internal consistencies subscale.","code":""},{"path":"https://easystats.github.io/performance/reference/check_itemscale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Describe Properties of Item Scales — check_itemscale","text":"check_itemscale() calculates various measures internal consistencies, Cronbach's alpha, item difficulty discrimination etc. subscales built several items. Subscales retrieved results parameters::principal_components(), .e. based many components extracted PCA, check_itemscale() retrieves variables belong component calculates mentioned measures.","code":""},{"path":"https://easystats.github.io/performance/reference/check_itemscale.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Describe Properties of Item Scales — check_itemscale","text":"Item difficulty range 0.2 0.8. Ideal value p+(1-p)/2 (mostly 0.5 0.8). See item_difficulty() details. item discrimination, acceptable values 0.20 higher; closer 1.00 better. See item_reliability() details. case total Cronbach's alpha value acceptable cut-0.7 (mostly index items), mean inter-item-correlation alternative measure indicate acceptability. Satisfactory range lies 0.2 0.4. See also item_intercor().","code":""},{"path":"https://easystats.github.io/performance/reference/check_itemscale.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Describe Properties of Item Scales — check_itemscale","text":"Briggs SR, Cheek JM (1986) role factor analysis development evaluation personality scales. Journal Personality, 54(1), 106-148. doi: 10.1111/j.1467-6494.1986.tb00391.x Trochim WMK (2008) Types Reliability. (web)","code":""},{"path":"https://easystats.github.io/performance/reference/check_itemscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Describe Properties of Item Scales — check_itemscale","text":"","code":"# data generation from '?prcomp', slightly modified C <- chol(S <- toeplitz(0.9^(0:15))) set.seed(17) X <- matrix(rnorm(1600), 100, 16) Z <- X %*% C if (require(\"parameters\") && require(\"psych\")) {   pca <- principal_components(as.data.frame(Z), rotation = \"varimax\", n = 3)   pca   check_itemscale(pca) } #> Loading required package: psych #>  #> Attaching package: ‘psych’ #> The following object is masked from ‘package:randomForest’: #>  #>     outlier #> # Description of (Sub-)Scales #> Component 1 #>  #> Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted #> ------------------------------------------------------------------------------------------ #> V1   |        0 | -0.02 | 1.06 |    -0.49 |      -0.01 |           0.80 |             0.96 #> V2   |        0 | -0.05 | 1.05 |    -0.29 |      -0.02 |           0.90 |             0.95 #> V3   |        0 |  0.00 | 1.10 |    -0.77 |       0.00 |           0.94 |             0.95 #> V4   |        0 |  0.00 | 1.10 |    -0.82 |       0.00 |           0.92 |             0.95 #> V5   |        0 | -0.07 | 1.09 |    -0.29 |      -0.03 |           0.90 |             0.95 #> V6   |        0 | -0.04 | 1.13 |    -0.27 |      -0.01 |           0.83 |             0.96 #>  #> Mean inter-item-correlation = 0.813  Cronbach's alpha = 0.963 #>  #> Component 2 #>  #> Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted #> ------------------------------------------------------------------------------------------ #> V7   |        0 | -0.01 | 1.07 |     0.01 |       0.00 |           0.87 |             0.97 #> V8   |        0 |  0.02 | 0.96 |     0.23 |       0.01 |           0.89 |             0.96 #> V9   |        0 |  0.04 | 0.98 |     0.37 |       0.01 |           0.93 |             0.96 #> V10  |        0 |  0.08 | 1.00 |     0.18 |       0.03 |           0.93 |             0.96 #> V11  |        0 |  0.02 | 1.03 |     0.18 |       0.01 |           0.92 |             0.96 #> V12  |        0 |  0.00 | 1.04 |     0.27 |       0.00 |           0.84 |             0.97 #>  #> Mean inter-item-correlation = 0.840  Cronbach's alpha = 0.969 #>  #> Component 3 #>  #> Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted #> ------------------------------------------------------------------------------------------ #> V13  |        0 |  0.04 | 0.95 |     0.10 |       0.02 |           0.81 |             0.95 #> V14  |        0 | -0.02 | 0.96 |     0.24 |      -0.01 |           0.93 |             0.91 #> V15  |        0 | -0.03 | 0.94 |     0.41 |      -0.01 |           0.92 |             0.91 #> V16  |        0 |  0.03 | 0.96 |     0.28 |       0.01 |           0.82 |             0.94 #>  #> Mean inter-item-correlation = 0.811  Cronbach's alpha = 0.945"},{"path":"https://easystats.github.io/performance/reference/check_kmo.html","id":null,"dir":"Reference","previous_headings":"","what":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"Kaiser (1970) introduced Measure Sampling Adequacy (MSA), later modified Kaiser Rice (1974). Kaiser-Meyer-Olkin (KMO) statistic, can vary 0 1, indicates degree variable set predicted without error variables.","code":""},{"path":"https://easystats.github.io/performance/reference/check_kmo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"","code":"check_kmo(x, ...)"},{"path":"https://easystats.github.io/performance/reference/check_kmo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"x dataframe. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/check_kmo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"list indices related KMO.","code":""},{"path":"https://easystats.github.io/performance/reference/check_kmo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"value 0 indicates sum partial correlations large relative sum correlations, indicating factor analysis likely inappropriate. KMO value close 1 indicates sum partial correlations large relative sum correlations factor analysis yield distinct reliable factors. Kaiser (1974) suggested KMO > .9 marvelous, .80s, meritorious, .70s, middling, .60s, mediocre, .50s, miserable, less .5, unacceptable. Hair et al. (2006) suggest accepting value > 0.5. Values 0.5 0.7 mediocre, values 0.7 0.8 good. function strongly inspired KMO function psych package (Revelle, 2016). credits goes author.","code":""},{"path":"https://easystats.github.io/performance/reference/check_kmo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"Revelle, W. (2016). : Use psych package Factor Analysis data reduction. Kaiser, H. F. (1970). second generation little jiffy. Psychometrika, 35(4), 401-415. Kaiser, H. F., & Rice, J. (1974). Little jiffy, mark IV. Educational psychological measurement, 34(1), 111-117. Kaiser, H. F. (1974). index factorial simplicity. Psychometrika, 39(1), 31-36.","code":""},{"path":"https://easystats.github.io/performance/reference/check_kmo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kaiser, Meyer, Olkin (KMO) Measure of Sampling Adequacy (MSA) for Factor Analysis — check_kmo","text":"","code":"library(performance) check_kmo(mtcars) #> # KMO Measure of Sampling Adequacy #>  #> The Kaiser, Meyer, Olkin (KMO) measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83)."},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Visual check of model assumptions — check_model","title":"Visual check of model assumptions — check_model","text":"Visual check model various assumptions (normality residuals, normality random effects, linear relationship, homogeneity variance, multicollinearity).","code":""},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visual check of model assumptions — check_model","text":"","code":"check_model(x, ...)  # S3 method for default check_model(   x,   dot_size = 2,   line_size = 0.8,   panel = TRUE,   check = \"all\",   alpha = 0.2,   dot_alpha = 0.8,   colors = c(\"#3aaf85\", \"#1b6ca8\", \"#cd201f\"),   theme = \"see::theme_lucid\",   detrend = FALSE,   show_dots = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visual check of model assumptions — check_model","text":"x model object. ... Currently used. dot_size, line_size Size line dot-geoms. panel Logical, TRUE, plots arranged panels; else, single plots diagnostic returned. check Character vector, indicating checks performed plotted. May one \"\", \"vif\", \"qq\", \"normality\", \"linearity\", \"ncv\", \"homogeneity\", \"outliers\", \"reqq\", \"pp_check\", \"binned_residuals\" \"overdispersion\", check apply type models (see 'Details'). \"reqq\" QQ-plot random effects available mixed models. \"ncv\" alias \"linearity\", checks non-constant variance, .e. heteroscedasticity, well linear relationship. default, possible checks performed plotted. alpha, dot_alpha alpha level confidence bands dot-geoms. Scalar 0 1. colors Character vector color codes (hex-format). Must length 3. First color usually used reference lines, second color dots, third color outliers extreme values. theme String, indicating name plot-theme. Must format \"package::theme_name\" (e.g. \"ggplot2::theme_minimal\"). detrend QQ/PP plots detrended? show_dots Logical, TRUE, show data points plot. Set FALSE models many observations, generating plot time-consuming. default, show_dots = NULL. case check_model() tries guess whether performance poor due large model thus automatically shows hides dots. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visual check of model assumptions — check_model","text":"data frame used plotting.","code":""},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Visual check of model assumptions — check_model","text":"Bayesian models packages rstanarm brms, models \"converted\" frequentist counterpart, using bayestestR::bayesian_as_frequentist. advanced model-check Bayesian models implemented later stage.","code":""},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Visual check of model assumptions — check_model","text":"function just prepares data plotting. create plots, see needs installed. Furthermore, function suppresses possible warnings. case observe suspicious plots, please refer dedicated functions (like check_collinearity(), check_normality() etc.) get informative messages warnings.","code":""},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":"linearity-assumption","dir":"Reference","previous_headings":"","what":"Linearity Assumption","title":"Visual check of model assumptions — check_model","text":"plot Linearity checks assumption linear relationship. However, spread dots also indicate possible heteroscedasticity (.e. non-constant variance); hence, alias \"ncv\" plot. caution needed interpreting plots. Although plots helpful check model assumptions, necessarily indicate -called \"lack fit\", e.g. missed non-linear relationships interactions. Thus, always recommended also look effect plots, including partial residuals.","code":""},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":"residuals-for-generalized-linear-models","dir":"Reference","previous_headings":"","what":"Residuals for (Generalized) Linear Models","title":"Visual check of model assumptions — check_model","text":"Plots check normality residuals (QQ-plot) homogeneity variance use standardized Pearson's residuals generalized linear models, standardized residuals linear models. plots normality residuals (overlayed normal curve) linearity assumption use default residuals lm glm (deviance residuals glm).","code":""},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":"troubleshooting","dir":"Reference","previous_headings":"","what":"Troubleshooting","title":"Visual check of model assumptions — check_model","text":"models many observations, complex models general, generating plot might become slow. One reason might underlying graphic engine becomes slow plotting many data points. cases, setting argument show_dots = FALSE might help. Furthermore, look check argument see model checks skipped, also increases performance.","code":""},{"path":"https://easystats.github.io/performance/reference/check_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visual check of model assumptions — check_model","text":"","code":"if (FALSE) { m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars) check_model(m)  if (require(\"lme4\")) {   m <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)   check_model(m, panel = FALSE) }  if (require(\"rstanarm\")) {   m <- stan_glm(mpg ~ wt + gear, data = mtcars, chains = 2, iter = 200)   check_model(m) } }"},{"path":"https://easystats.github.io/performance/reference/check_multimodal.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if a distribution is unimodal or multimodal — check_multimodal","title":"Check if a distribution is unimodal or multimodal — check_multimodal","text":"univariate distributions (one-dimensional vectors), functions performs Ameijeiras-Alonso et al. (2018) excess mass test. multivariate distributions (dataframes), uses mixture modelling. However, seems always returns significant result (suggesting distribution multimodal). better method might needed .","code":""},{"path":"https://easystats.github.io/performance/reference/check_multimodal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if a distribution is unimodal or multimodal — check_multimodal","text":"","code":"check_multimodal(x, ...)"},{"path":"https://easystats.github.io/performance/reference/check_multimodal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if a distribution is unimodal or multimodal — check_multimodal","text":"x numeric vector data frame. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/check_multimodal.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check if a distribution is unimodal or multimodal — check_multimodal","text":"Ameijeiras-Alonso, J., Crujeiras, R. M., Rodríguez-Casal, . (2019). Mode testing, critical bandwidth excess mass. Test, 28(3), 900-919.","code":""},{"path":"https://easystats.github.io/performance/reference/check_multimodal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if a distribution is unimodal or multimodal — check_multimodal","text":"","code":"if (FALSE) { if (require(\"multimode\")) {   # Univariate   x <- rnorm(1000)   check_multimodal(x) }  if (require(\"multimode\") && require(\"mclust\")) {   x <- c(rnorm(1000), rnorm(1000, 2))   check_multimodal(x)    # Multivariate   m <- data.frame(     x = rnorm(200),     y = rbeta(200, 2, 1)   )   plot(m$x, m$y)   check_multimodal(m)    m <- data.frame(     x = c(rnorm(100), rnorm(100, 4)),     y = c(rbeta(100, 2, 1), rbeta(100, 1, 4))   )   plot(m$x, m$y)   check_multimodal(m) } }"},{"path":"https://easystats.github.io/performance/reference/check_normality.html","id":null,"dir":"Reference","previous_headings":"","what":"Check model for (non-)normality of residuals. — check_normality","title":"Check model for (non-)normality of residuals. — check_normality","text":"Check model (non-)normality residuals.","code":""},{"path":"https://easystats.github.io/performance/reference/check_normality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check model for (non-)normality of residuals. — check_normality","text":"","code":"check_normality(x, ...)  # S3 method for merMod check_normality(x, effects = c(\"fixed\", \"random\"), ...)"},{"path":"https://easystats.github.io/performance/reference/check_normality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check model for (non-)normality of residuals. — check_normality","text":"x model object. ... Currently used. effects normality residuals (\"fixed\") random effects (\"random\") tested? applies mixed-effects models. May abbreviated.","code":""},{"path":"https://easystats.github.io/performance/reference/check_normality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check model for (non-)normality of residuals. — check_normality","text":"p-value test statistics. p-value < 0.05 indicates significant deviation normal distribution.","code":""},{"path":"https://easystats.github.io/performance/reference/check_normality.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check model for (non-)normality of residuals. — check_normality","text":"check_normality() calls stats::shapiro.test checks standardized residuals (Studentized residuals mixed models) normal distribution. Note formal test almost always yields significant results distribution residuals visual inspection (e.g. Q-Q plots) preferable.","code":""},{"path":"https://easystats.github.io/performance/reference/check_normality.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Check model for (non-)normality of residuals. — check_normality","text":"mixed-effects models, studentized residuals, standardized residuals, used test. also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/performance/reference/check_normality.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check model for (non-)normality of residuals. — check_normality","text":"","code":"m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars) check_normality(m) #> OK: residuals appear as normally distributed (p = 0.230). #>   # plot results if (require(\"see\")) {   x <- check_normality(m)   plot(x) }  if (FALSE) { # QQ-plot plot(check_normality(m), type = \"qq\")  # PP-plot plot(check_normality(m), type = \"pp\") }"},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Outliers detection (check for influential observations) — check_outliers","title":"Outliers detection (check for influential observations) — check_outliers","text":"Checks locates influential observations (.e., \"outliers\") via several distance /clustering methods. several methods selected, returned \"Outlier\" vector composite outlier score, made average binary (0 1) results method. represents probability observation classified outlier least one method. decision rule used default classify outliers observations composite outlier score superior equal 0.5 (.e., classified outliers least half methods). See Details section description methods.","code":""},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outliers detection (check for influential observations) — check_outliers","text":"","code":"check_outliers(x, ...)  # S3 method for default check_outliers(   x,   method = c(\"cook\", \"pareto\"),   threshold = NULL,   ID = NULL,   ... )  # S3 method for numeric check_outliers(x, method = \"zscore_robust\", threshold = NULL, ...)  # S3 method for data.frame check_outliers(x, method = \"mahalanobis\", threshold = NULL, ID = NULL, ...)"},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outliers detection (check for influential observations) — check_outliers","text":"x model data.frame object. ... method = \"ics\", arguments ... passed ICSOutlier::ics.outlier(). method = \"mahalanobis\",  passed stats::mahalanobis(). method outlier detection method(s). Can \"\" \"cook\", \"pareto\", \"zscore\", \"zscore_robust\", \"iqr\", \"ci\", \"eti\", \"hdi\", \"bci\", \"mahalanobis\", \"mahalanobis_robust\", \"mcd\", \"ics\", \"optics\" \"lof\". threshold list containing threshold values method (e.g. list('mahalanobis' = 7, 'cook' = 1)), observation considered outlier. NULL, default values used (see 'Details'). numeric value given, used threshold method run. ID Optional, report ID column along row number.","code":""},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outliers detection (check for influential observations) — check_outliers","text":"logical vector detected outliers nice printing method: check (message) whether outliers detected . information distance measure whether observation considered outlier can recovered .data.frame function.","code":""},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Outliers detection (check for influential observations) — check_outliers","text":"Outliers can defined particularly influential observations. methods rely computation distance metric, observations greater certain threshold considered outliers. Importantly, outliers detection methods meant provide information consider researcher, rather automatized procedure mindless application substitute thinking. example sentence reporting usage composite method : \"Based composite outlier score (see 'check_outliers' function 'performance' R package; Lüdecke et al., 2021) obtained via joint application multiple outliers detection algorithms (Z-scores, Iglewicz, 1993; Interquartile range (IQR); Mahalanobis distance, Cabana, 2019; Robust Mahalanobis distance, Gnanadesikan Kettenring, 1972; Minimum Covariance Determinant, Leys et al., 2018; Invariant Coordinate Selection, Archimbaud et al., 2018; OPTICS, Ankerst et al., 1999; Isolation Forest, Liu et al. 2008; Local Outlier Factor, Breunig et al., 2000), excluded n participants classified outliers least half methods used.\"","code":""},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Outliers detection (check for influential observations) — check_outliers","text":"also plot()-method implemented see-package. Please note range distance-values along y-axis re-scaled range 0 1.","code":""},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"model-specific-methods","dir":"Reference","previous_headings":"","what":"Model-specific methods","title":"Outliers detection (check for influential observations) — check_outliers","text":"Cook's Distance: Among outlier detection methods, Cook's distance leverage less common basic Mahalanobis distance, still used. Cook's distance estimates variations regression coefficients removing observation, one one (Cook, 1977). Since Cook's distance metric F distribution p n-p degrees freedom, median point quantile distribution can used cut-(Bollen, 1985). common approximation heuristic use 4 divided numbers observations, usually corresponds lower threshold (.e., outliers detected). works Frequentist models. Bayesian models, see pareto. Pareto: reliability approximate convergence Bayesian models can assessed using estimates shape parameter k generalized Pareto distribution. estimated tail shape parameter k exceeds 0.5, user warned, although practice authors loo package observed good performance values k 0.7 (default threshold used performance).","code":""},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"univariate-methods","dir":"Reference","previous_headings":"","what":"Univariate methods","title":"Outliers detection (check for influential observations) — check_outliers","text":"Z-scores (\"zscore\", \"zscore_robust\"): Z-score, standard score, way describing data point deviance central value, terms standard deviations mean (\"zscore\") , case (\"zscore_robust\") default (Iglewicz, 1993), terms Median Absolute Deviation (MAD) median (robust measures dispersion centrality). default threshold classify outliers 1.959 (threshold = list(\"zscore\" = 1.959)), corresponding 2.5\\ (assuming data normally distributed). Importantly, Z-score method univariate: computed column column. dataframe passed, Z-score calculated variable separately, maximum (absolute) Z-score kept observations. Thus, observations extreme least one variable might detected outliers. Thus, method suited high dimensional data (many columns), returning liberal results (detecting many outliers). IQR (\"iqr\"): Using IQR (interquartile range) robust method developed John Tukey, often appears box--whisker plots (e.g., geom_boxplot). interquartile range range first third quartiles. Tukey considered outliers data point fell outside either 1.5 times (default threshold 1.7) IQR first third quartile. Similar Z-score method, univariate method outliers detection, returning outliers detected least one column, might thus suited high dimensional data. distance score IQR absolute deviation median upper lower IQR thresholds. , value divided IQR threshold, “standardize” facilitate interpretation. CI (\"ci\", \"eti\", \"hdi\", \"bci\"): Another univariate method compute, variable, sort \"confidence\" interval consider outliers values lying beyond edges interval. default, \"ci\" computes Equal-Tailed Interval (\"eti\"), types intervals available, Highest Density Interval (\"hdi\") Bias Corrected Accelerated Interval (\"bci\"). default threshold 0.95, considering outliers observations outside 95% CI variable. See bayestestR::ci() details intervals. distance score CI methods absolute deviation median upper lower CI thresholds. , value divided difference upper lower CI bounds divided two, “standardize” facilitate interpretation.","code":""},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"multivariate-methods","dir":"Reference","previous_headings":"","what":"Multivariate methods","title":"Outliers detection (check for influential observations) — check_outliers","text":"Mahalanobis Distance: Mahalanobis distance (Mahalanobis, 1930) often used multivariate outliers detection distance takes account shape observations. default threshold often arbitrarily set deviation (terms SD MAD) mean (median) Mahalanobis distance. However, Mahalanobis distance can approximated Chi squared distribution (Rousseeuw Van Zomeren, 1990), can use alpha quantile chi-square distribution k degrees freedom (k number columns). default, alpha threshold set 0.025 (corresponding 2.5\\ Cabana, 2019). criterion natural extension median plus minus coefficient times MAD method (Leys et al., 2013). Robust Mahalanobis Distance: robust version Mahalanobis distance using Orthogonalized Gnanadesikan-Kettenring pairwise estimator (Gnanadesikan Kettenring, 1972). Requires bigutilsr package. See bigutilsr::dist_ogk() function. Minimum Covariance Determinant (MCD): Another robust version Mahalanobis. Leys et al. (2018) argue Mahalanobis Distance robust way determine outliers, uses means covariances data - including outliers - determine individual difference scores. Minimum Covariance Determinant calculates mean covariance matrix based central subset data (default, 66\\ deemed robust method identifying removing outliers regular Mahalanobis distance. Invariant Coordinate Selection (ICS): outlier detected using ICS, default uses alpha threshold 0.025 (corresponding 2.5\\ value outliers classification. Refer help-file ICSOutlier::ics.outlier() get details procedure. Note method = \"ics\" requires ICS ICSOutlier installed, takes time compute results. OPTICS: Ordering Points Identify Clustering Structure (OPTICS) algorithm (Ankerst et al., 1999) using similar concepts DBSCAN (unsupervised clustering technique can used outliers detection). threshold argument passed minPts, corresponds minimum size cluster. default, size set 2 times number columns (Sander et al., 1998). Compared techniques, always detect several outliers (usually defined percentage extreme values), algorithm functions different manner always detect outliers. Note method = \"optics\" requires dbscan package installed, takes time compute results.","code":""},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"threshold-specification","dir":"Reference","previous_headings":"","what":"Threshold specification","title":"Outliers detection (check for influential observations) — check_outliers","text":"Default thresholds currently specified follows:","code":"list(   zscore = stats::qnorm(p = 1 - 0.001),   zscore_robust = stats::qnorm(p = 1 - 0.001),   iqr = 1.7,   ci = 0.999,   eti = 0.999,   hdi = 0.999,   bci = 0.999,   cook = stats::qf(0.5, ncol(x), nrow(x) - ncol(x)),   pareto = 0.7,   mahalanobis = stats::qchisq(p = 1 - 0.001, df = ncol(x)),   mahalanobis_robust = stats::qchisq(p = 1 - 0.001, df = ncol(x)),   mcd = stats::qchisq(p = 1 - 0.001, df = ncol(x)),   ics = 0.001,   optics = 2 * ncol(x),   lof = 0.001 )"},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Outliers detection (check for influential observations) — check_outliers","text":"Archimbaud, ., Nordhausen, K., Ruiz-Gazen, . (2018). ICS multivariate outlier detection application quality control. Computational Statistics Data Analysis, 128, 184-199. doi:10.1016/j.csda.2018.06.011 Gnanadesikan, R., Kettenring, J. R. (1972). Robust estimates, residuals, outlier detection multiresponse data. Biometrics, 81-124. Bollen, K. ., Jackman, R. W. (1985). Regression diagnostics: expository treatment outliers influential cases. Sociological Methods Research, 13(4), 510-542. Cabana, E., Lillo, R. E., Laniado, H. (2019). Multivariate outlier detection based robust Mahalanobis distance shrinkage estimators. arXiv preprint arXiv:1904.02596. Cook, R. D. (1977). Detection influential observation linear regression. Technometrics, 19(1), 15-18. Iglewicz, B., Hoaglin, D. C. (1993). detect handle outliers (Vol. 16). Asq Press. Leys, C., Klein, O., Dominicy, Y., Ley, C. (2018). Detecting multivariate outliers: Use robust variant Mahalanobis distance. Journal Experimental Social Psychology, 74, 150-156. Liu, F. T., Ting, K. M., Zhou, Z. H. (2008, December). Isolation forest. 2008 Eighth IEEE International Conference Data Mining (pp. 413-422). IEEE. Lüdecke, D., Ben-Shachar, M. S., Patil, ., Waggoner, P., Makowski, D. (2021). performance: R package assessment, comparison testing statistical models. Journal Open Source Software, 6(60), 3139. doi:10.21105/joss.03139 Rousseeuw, P. J., Van Zomeren, B. C. (1990). Unmasking multivariate outliers leverage points. Journal American Statistical association, 85(411), 633-639.","code":""},{"path":"https://easystats.github.io/performance/reference/check_outliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outliers detection (check for influential observations) — check_outliers","text":"","code":"data <- mtcars # Size nrow(data) = 32  # For single variables ------------------------------------------------------ outliers_list <- check_outliers(data$mpg) # Find outliers outliers_list # Show the row index of the outliers #> OK: No outliers detected. #> - Based on the following method and threshold: zscore_robust (3.09). #> - For variable: data$mpg #>  #>  as.numeric(outliers_list) # The object is a binary vector... #>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 filtered_data <- data[!outliers_list, ] # And can be used to filter a dataframe nrow(filtered_data) # New size, 28 (4 outliers removed) #> [1] 32  # Find all observations beyond +/- 2 SD check_outliers(data$mpg, method = \"zscore\", threshold = 2) #> 2 outliers detected: cases 18, 20. #> - Based on the following method and threshold: zscore (2). #> - For variable: data$mpg. #>  #> ----------------------------------------------------------------------------- #> Outliers per variable (zscore):  #>  #> $`data$mpg` #>    Row Distance_Zscore #> 18  18        2.042389 #> 20  20        2.291272 #>   # For dataframes ------------------------------------------------------ check_outliers(data) # It works the same way on dataframes #> OK: No outliers detected. #> - Based on the following method and threshold: mahalanobis (31.26). #> - For variables: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb #>  #>   # You can also use multiple methods at once outliers_list <- check_outliers(data, method = c(   \"mahalanobis\",   \"iqr\",   \"zscore\" )) outliers_list #> 1 outlier detected: case 31. #> - Based on the following methods and thresholds: mahalanobis (3.09), iqr #>   (1.7), zscore (31.26). #> - For variables: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb. #> Note: Outliers were classified as such by at least half of the selected methods.  #>  #> ----------------------------------------------------------------------------- #> The following observations were considered outliers for two or more variables  #> by at least one of the selected methods:  #>  #>   Row n_Zscore n_IQR #> 1  31        1     2  # Using `as.data.frame()`, we can access more details! outliers_info <- as.data.frame(outliers_list) head(outliers_info) #>   Row Distance_Zscore Outlier_Zscore Distance_IQR Outlier_IQR #> 1   1        1.189901              0    0.4208483           0 #> 2   2        1.189901              0    0.2941176           0 #> 3   3        1.224858              0    0.5882353           0 #> 4   4        1.122152              0    0.5882353           0 #> 5   5        1.043081              0    0.3915954           0 #> 6   6        1.564608              0    0.6809025           0 #>   Distance_Mahalanobis Outlier_Mahalanobis Outlier #> 1             8.946673                   0       0 #> 2             8.287933                   0       0 #> 3             8.937150                   0       0 #> 4             6.096726                   0       0 #> 5             5.429061                   0       0 #> 6             8.877558                   0       0 outliers_info$Outlier # Including the probability of being an outlier #>  [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #>  [8] 0.0000000 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #> [15] 0.0000000 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #> [22] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #> [29] 0.0000000 0.0000000 0.6666667 0.0000000  # And we can be more stringent in our outliers removal process filtered_data <- data[outliers_info$Outlier < 0.1, ]  # We can run the function stratified by groups using `{dplyr}` package: if (require(\"poorman\")) {   iris %>%     group_by(Species) %>%     check_outliers() } #> Loading required package: poorman #>  #>   I'd seen my father. He was a poor man, and I watched him do astonishing things. #>     - Sidney Poitier #>  #> Attaching package: ‘poorman’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> OK: No outliers detected. #> - Based on the following method and threshold: mahalanobis (18.47). #> - For variables: Sepal.Length, Sepal.Width, Petal.Length, Petal.Width #>  #>  if (FALSE) { # You can also run all the methods check_outliers(data, method = \"all\")  # For statistical models --------------------------------------------- # select only mpg and disp (continuous) mt1 <- mtcars[, c(1, 3, 4)] # create some fake outliers and attach outliers to main df mt2 <- rbind(mt1, data.frame(   mpg = c(37, 40), disp = c(300, 400),   hp = c(110, 120) )) # fit model with outliers model <- lm(disp ~ mpg + hp, data = mt2)  outliers_list <- check_outliers(model)  if (require(\"see\")) {   plot(outliers_list) }  insight::get_data(model)[outliers_list, ] # Show outliers data  if (require(\"MASS\")) {   check_outliers(model, method = c(\"mahalanobis\", \"mcd\")) } if (require(\"ICS\")) {   # This one takes some seconds to finish...   check_outliers(model, method = \"ics\") } }"},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Check overdispersion of GL(M)M's — check_overdispersion","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"check_overdispersion() checks generalized linear (mixed) models overdispersion.","code":""},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"","code":"check_overdispersion(x, ...)"},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"x Fitted model class merMod, glmmTMB, glm, glm.nb (package MASS). ... Currently used.","code":""},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"list results overdispersion test, like chi-squared statistics, p-value dispersion ratio.","code":""},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"Overdispersion occurs observed variance higher variance theoretical model. Poisson models, variance increases mean , therefore, variance usually (roughly) equals mean value. variance much higher, data \"overdispersed\".","code":""},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"interpretation-of-the-dispersion-ratio","dir":"Reference","previous_headings":"","what":"Interpretation of the Dispersion Ratio","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"dispersion ratio close one, Poisson model fits well data. Dispersion ratios larger one indicate overdispersion, thus negative binomial model similar might fit better data. p-value < .05 indicates overdispersion.","code":""},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"overdispersion-in-poisson-models","dir":"Reference","previous_headings":"","what":"Overdispersion in Poisson Models","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"Poisson models, overdispersion test based code Gelman Hill (2007), page 115.","code":""},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"overdispersion-in-mixed-models","dir":"Reference","previous_headings":"","what":"Overdispersion in Mixed Models","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"merMod- glmmTMB-objects, check_overdispersion() based code GLMM FAQ, section can deal overdispersion GLMMs?. Note function returns approximate estimate overdispersion parameter, probably inaccurate zero-inflated mixed models (fitted glmmTMB).","code":""},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"how-to-fix-overdispersion","dir":"Reference","previous_headings":"","what":"How to fix Overdispersion","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"Overdispersion can fixed either modeling dispersion parameter, choosing different distributional family (like Quasi-Poisson, negative binomial, see Gelman Hill (2007), pages 115-116).","code":""},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"Bolker B et al. (2017): GLMM FAQ. Gelman, ., Hill, J. (2007). Data analysis using regression multilevel/hierarchical models. Cambridge; New York: Cambridge University Press.","code":""},{"path":"https://easystats.github.io/performance/reference/check_overdispersion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check overdispersion of GL(M)M's — check_overdispersion","text":"","code":"if (require(\"glmmTMB\")) {   data(Salamanders)   m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)   check_overdispersion(m)    m <- glmmTMB(     count ~ mined + spp + (1 | site),     family = poisson,     data = Salamanders   )   check_overdispersion(m) } #> Loading required package: glmmTMB #> # Overdispersion test #>  #>        dispersion ratio =    2.324 #>   Pearson's Chi-Squared = 1475.875 #>                 p-value =  < 0.001 #>  #> Overdispersion detected."},{"path":"https://easystats.github.io/performance/reference/check_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior predictive checks — check_predictions","title":"Posterior predictive checks — check_predictions","text":"Posterior predictive checks mean \"simulating replicated data fitted model comparing observed data\" (Gelman Hill, 2007, p. 158). Posterior predictive checks can used \"look systematic discrepancies real simulated data\" (Gelman et al. 2014, p. 169). performance provides posterior predictive check methods variety frequentist models (e.g., lm, merMod, glmmTMB, ...). Bayesian models, model passed bayesplot::pp_check().","code":""},{"path":"https://easystats.github.io/performance/reference/check_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior predictive checks — check_predictions","text":"","code":"check_predictions(   object,   iterations = 50,   check_range = FALSE,   re_formula = NULL,   ... )  posterior_predictive_check(   object,   iterations = 50,   check_range = FALSE,   re_formula = NULL,   ... )  check_posterior_predictions(   object,   iterations = 50,   check_range = FALSE,   re_formula = NULL,   ... )"},{"path":"https://easystats.github.io/performance/reference/check_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior predictive checks — check_predictions","text":"object statistical model. iterations number draws simulate/bootstrap. check_range Logical, TRUE, includes plot minimum value original response minimum values replicated responses, maximum value. plot helps judging whether variation original data captured model (Gelman et al. 2020, pp.163). minimum maximum values y inside range related minimum maximum values yrep. re_formula Formula containing group-level effects (random effects) considered simulated data. NULL (default), condition random effects. NA ~0, condition random effects. See simulate() lme4. ... Passed simulate().","code":""},{"path":"https://easystats.github.io/performance/reference/check_predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior predictive checks — check_predictions","text":"data frame simulated responses original response vector.","code":""},{"path":"https://easystats.github.io/performance/reference/check_predictions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior predictive checks — check_predictions","text":"example posterior predictive checks can also used model comparison Figure 6 Gabry et al. 2019, Figure 6. model shown right panel (b) can simulate new data similar observed outcome model left panel (). Thus, model (b) likely preferred model ().","code":""},{"path":"https://easystats.github.io/performance/reference/check_predictions.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Posterior predictive checks — check_predictions","text":"Every model object simulate()-method work check_predictions(). R 3.6.0 higher, bayesplot (package imports bayesplot rstanarm brms) loaded, pp_check() also available alias check_predictions().","code":""},{"path":"https://easystats.github.io/performance/reference/check_predictions.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Posterior predictive checks — check_predictions","text":"Gabry, J., Simpson, D., Vehtari, ., Betancourt, M., Gelman, . (2019). Visualization Bayesian workflow. Journal Royal Statistical Society: Series (Statistics Society), 182(2), 389–402. https://doi.org/10.1111/rssa.12378 Gelman, ., Hill, J. (2007). Data analysis using regression multilevel/hierarchical models. Cambridge; New York: Cambridge University Press. Gelman, ., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, ., Rubin, D. B. (2014). Bayesian data analysis. (Third edition). CRC Press. Gelman, ., Hill, J., Vehtari, . (2020). Regression Stories. Cambridge University Press.","code":""},{"path":"https://easystats.github.io/performance/reference/check_predictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior predictive checks — check_predictions","text":"","code":"library(performance) model <- lm(mpg ~ disp, data = mtcars) if (require(\"see\")) {   check_predictions(model) }"},{"path":"https://easystats.github.io/performance/reference/check_singularity.html","id":null,"dir":"Reference","previous_headings":"","what":"Check mixed models for boundary fits — check_singularity","title":"Check mixed models for boundary fits — check_singularity","text":"Check mixed models boundary fits.","code":""},{"path":"https://easystats.github.io/performance/reference/check_singularity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check mixed models for boundary fits — check_singularity","text":"","code":"check_singularity(x, tolerance = 1e-05, ...)"},{"path":"https://easystats.github.io/performance/reference/check_singularity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check mixed models for boundary fits — check_singularity","text":"x mixed model. tolerance Indicates value convergence result accepted. larger tolerance , stricter test . ... Currently used.","code":""},{"path":"https://easystats.github.io/performance/reference/check_singularity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check mixed models for boundary fits — check_singularity","text":"TRUE model fit singular.","code":""},{"path":"https://easystats.github.io/performance/reference/check_singularity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check mixed models for boundary fits — check_singularity","text":"model \"singular\", means dimensions variance-covariance matrix estimated exactly zero. often occurs mixed models complex random effects structures.  “singular models statistically well defined (theoretically sensible true maximum likelihood estimate correspond singular fit), real concerns (1) singular fits correspond overfitted models may poor power; (2) chances numerical problems mis-convergence higher singular models (e.g. may computationally difficult compute profile confidence intervals models); (3) standard inferential procedures Wald statistics likelihood ratio tests may inappropriate.” (lme4 Reference Manual)  gold-standard deal singularity random-effects specification choose. Beside using fully Bayesian methods (informative priors), proposals frequentist framework : avoid fitting overly complex models, variance-covariance matrices can estimated precisely enough (Matuschek et al. 2017) use form model selection choose model balances predictive accuracy overfitting/type error (Bates et al. 2015, Matuschek et al. 2017) “keep maximal”, .e. fit complex model consistent experimental design, removing terms required allow non-singular fit (Barr et al. 2013) Note different meaning singularity convergence: singularity indicates issue \"true\" best estimate, .e. whether maximum likelihood estimation variance-covariance matrix random effects positive definite semi-definite. Convergence question whether can assume numerical optimization worked correctly .","code":""},{"path":"https://easystats.github.io/performance/reference/check_singularity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check mixed models for boundary fits — check_singularity","text":"Bates D, Kliegl R, Vasishth S, Baayen H. Parsimonious Mixed Models. arXiv:1506.04967, June 2015. Barr DJ, Levy R, Scheepers C, Tily HJ. Random effects structure confirmatory hypothesis testing: Keep maximal. Journal Memory Language, 68(3):255-278, April 2013. Matuschek H, Kliegl R, Vasishth S, Baayen H, Bates D. Balancing type error power linear mixed models. Journal Memory Language, 94:305-315, 2017. lme4 Reference Manual, https://cran.r-project.org/package=lme4","code":""},{"path":"https://easystats.github.io/performance/reference/check_singularity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check mixed models for boundary fits — check_singularity","text":"","code":"if (require(\"lme4\")) {   data(sleepstudy)   set.seed(123)   sleepstudy$mygrp <- sample(1:5, size = 180, replace = TRUE)   sleepstudy$mysubgrp <- NA   for (i in 1:5) {     filter_group <- sleepstudy$mygrp == i     sleepstudy$mysubgrp[filter_group] <-       sample(1:30, size = sum(filter_group), replace = TRUE)   }    model <- lmer(     Reaction ~ Days + (1 | mygrp / mysubgrp) + (1 | Subject),     data = sleepstudy   )    check_singularity(model) } #> boundary (singular) fit: see help('isSingular') #> [1] TRUE"},{"path":"https://easystats.github.io/performance/reference/check_sphericity.html","id":null,"dir":"Reference","previous_headings":"","what":"Check model for violation of sphericity — check_sphericity","title":"Check model for violation of sphericity — check_sphericity","text":"Check model violation sphericity","code":""},{"path":"https://easystats.github.io/performance/reference/check_sphericity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check model for violation of sphericity — check_sphericity","text":"","code":"check_sphericity(x, ...)"},{"path":"https://easystats.github.io/performance/reference/check_sphericity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check model for violation of sphericity — check_sphericity","text":"x model object. ... Arguments passed car::Anova.","code":""},{"path":"https://easystats.github.io/performance/reference/check_sphericity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check model for violation of sphericity — check_sphericity","text":"Invisibly returns p-values test statistics. p-value < 0.05 indicates violation sphericity.","code":""},{"path":"https://easystats.github.io/performance/reference/check_sphericity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check model for violation of sphericity — check_sphericity","text":"","code":"if (require(\"car\")) {   soils.mod <- lm(     cbind(pH, N, Dens, P, Ca, Mg, K, Na, Conduc) ~ Block + Contour * Depth,     data = Soils   )    check_sphericity(Manova(soils.mod)) } #> Loading required package: car #> Loading required package: carData #>  #> Attaching package: ‘car’ #> The following object is masked from ‘package:poorman’: #>  #>     recode #> The following object is masked from ‘package:psych’: #>  #>     logit #> OK: Data seems to be spherical (p > .999). #>"},{"path":"https://easystats.github.io/performance/reference/check_sphericity_bartlett.html","id":null,"dir":"Reference","previous_headings":"","what":"Bartlett's Test of Sphericity — check_sphericity_bartlett","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"Bartlett's (1951) test sphericity tests whether matrix (correlations) significantly different identity matrix. test provides probability correlation matrix significant correlations among least variables dataset, prerequisite factor analysis work. words, starting factor analysis, one needs check whether Bartlett’s test sphericity significant.","code":""},{"path":"https://easystats.github.io/performance/reference/check_sphericity_bartlett.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"","code":"check_sphericity_bartlett(x, ...)"},{"path":"https://easystats.github.io/performance/reference/check_sphericity_bartlett.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"x dataframe. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/check_sphericity_bartlett.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"list indices related sphericity.","code":""},{"path":"https://easystats.github.io/performance/reference/check_sphericity_bartlett.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"function strongly inspired cortest.bartlett() function psych package (Revelle, 2016). credit goes author.","code":""},{"path":"https://easystats.github.io/performance/reference/check_sphericity_bartlett.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"Revelle, W. (2016). : Use psych package Factor Analysis data reduction. Bartlett, M. S. (1951). effect standardization Chi-square approximation factor analysis. Biometrika, 38(3/4), 337-344.","code":""},{"path":"https://easystats.github.io/performance/reference/check_sphericity_bartlett.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bartlett's Test of Sphericity — check_sphericity_bartlett","text":"","code":"library(performance) check_sphericity_bartlett(mtcars) #> # Test of Sphericity #>  #> Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001)."},{"path":"https://easystats.github.io/performance/reference/check_symmetry.html","id":null,"dir":"Reference","previous_headings":"","what":"Check distribution symmetry — check_symmetry","title":"Check distribution symmetry — check_symmetry","text":"Uses Hotelling Solomons test symmetry testing standardized nonparametric skew (\\(\\frac{(Mean - Median)}{SD}\\)) different 0.  underlying assumption Wilcoxon signed-rank test.","code":""},{"path":"https://easystats.github.io/performance/reference/check_symmetry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check distribution symmetry — check_symmetry","text":"","code":"check_symmetry(x, ...)"},{"path":"https://easystats.github.io/performance/reference/check_symmetry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check distribution symmetry — check_symmetry","text":"x Model numeric vector ... used.","code":""},{"path":"https://easystats.github.io/performance/reference/check_symmetry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check distribution symmetry — check_symmetry","text":"","code":"V <- wilcox.test(mtcars$mpg) #> Warning: cannot compute exact p-value with ties check_symmetry(V) #> OK: Data appears symmetrical (p = 0.119). #>"},{"path":"https://easystats.github.io/performance/reference/check_zeroinflation.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for zero-inflation in count models — check_zeroinflation","title":"Check for zero-inflation in count models — check_zeroinflation","text":"check_zeroinflation() checks whether count models - underfitting zeros outcome.","code":""},{"path":"https://easystats.github.io/performance/reference/check_zeroinflation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for zero-inflation in count models — check_zeroinflation","text":"","code":"check_zeroinflation(x, tolerance = 0.05)"},{"path":"https://easystats.github.io/performance/reference/check_zeroinflation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for zero-inflation in count models — check_zeroinflation","text":"x Fitted model class merMod, glmmTMB, glm, glm.nb (package MASS). tolerance tolerance ratio observed predicted zeros considered - underfitting zeros. ratio 1 +/- tolerance considered OK, ratio beyond threshold indicate - underfitting.","code":""},{"path":"https://easystats.github.io/performance/reference/check_zeroinflation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for zero-inflation in count models — check_zeroinflation","text":"list information amount predicted observed zeros outcome, well ratio two values.","code":""},{"path":"https://easystats.github.io/performance/reference/check_zeroinflation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for zero-inflation in count models — check_zeroinflation","text":"amount observed zeros larger amount predicted zeros, model underfitting zeros, indicates zero-inflation data. cases, recommended use negative binomial zero-inflated models.","code":""},{"path":"https://easystats.github.io/performance/reference/check_zeroinflation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for zero-inflation in count models — check_zeroinflation","text":"","code":"if (require(\"glmmTMB\")) {   data(Salamanders)   m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)   check_zeroinflation(m) } #> # Check for zero-inflation #>  #>    Observed zeros: 387 #>   Predicted zeros: 298 #>             Ratio: 0.77 #>  #> Model is underfitting zeros (probable zero-inflation)."},{"path":"https://easystats.github.io/performance/reference/classify_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify the distribution of a model-family using machine learning — classify_distribution","title":"Classify the distribution of a model-family using machine learning — classify_distribution","text":"Classify distribution model-family using machine learning","code":""},{"path":"https://easystats.github.io/performance/reference/classify_distribution.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Classify the distribution of a model-family using machine learning — classify_distribution","text":"trained model classify distributions, used check_distribution() function.","code":""},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare performance of different models — compare_performance","title":"Compare performance of different models — compare_performance","text":"compare_performance() computes indices model performance different models hence allows comparison indices across models.","code":""},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare performance of different models — compare_performance","text":"","code":"compare_performance(   ...,   metrics = \"all\",   rank = FALSE,   estimator = \"ML\",   verbose = TRUE )"},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare performance of different models — compare_performance","text":"... Multiple model objects (also different classes). metrics Can \"\", \"common\" character vector metrics computed. See related documentation() object's class details. rank Logical, TRUE, models ranked according 'best' overall model performance. See 'Details'. estimator linear models. Corresponds different estimators standard deviation errors. estimator = \"ML\" (default), scaling done n (biased ML estimator), equivalent using AIC(logLik()). Setting \"REML\" give results AIC(logLik(..., REML = TRUE)). verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare performance of different models — compare_performance","text":"data frame one row per model one column per \"index\" (see metrics).","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":"model-weights","dir":"Reference","previous_headings":"","what":"Model Weights","title":"Compare performance of different models — compare_performance","text":"information criteria (IC) requested metrics (.e., \"\", \"common\", \"AIC\", \"AICc\", \"BIC\", \"WAIC\", \"LOOIC\"), model weights based criteria also computed. IC except LOOIC, weights computed w = exp(-0.5 * delta_ic) / sum(exp(-0.5 * delta_ic)), delta_ic difference model's IC value smallest IC value model set (Burnham Anderson, 2002). LOOIC, weights computed \"stacking weights\" using loo::stacking_weights().","code":""},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":"ranking-models","dir":"Reference","previous_headings":"","what":"Ranking Models","title":"Compare performance of different models — compare_performance","text":"rank = TRUE, new column Performance_Score returned. score ranges 0\\ performance. Note score value necessarily sum 100\\ Rather, calculation based normalizing indices (.e. rescaling range 0 1), taking mean value indices model. rather quick heuristic, might helpful exploratory index.  particular models different types (e.g. mixed models, classical linear models, logistic regression, ...), indices computed model. case index calculated specific model type, model gets NA value. indices NAs excluded calculating performance score.  plot()-method compare_performance(), creates \"spiderweb\" plot, different indices normalized larger values indicate better model performance. Hence, points closer center indicate worse fit indices (see online-documentation details).","code":""},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":"reml-versus-ml-estimator","dir":"Reference","previous_headings":"","what":"REML versus ML estimator","title":"Compare performance of different models — compare_performance","text":"default, estimator = \"ML\", means values information criteria (AIC, AICc, BIC) specific model classes (like models lme4) based ML-estimator, default behaviour AIC() classes setting REML = TRUE. default intentional, comparing information criteria based REML fits usually valid (might useful, though, models share fixed effects - however, usually case nested models, prerequisite LRT). Set estimator = \"REML\" explicitly return (AIC/...) values defaults AIC.merMod().","code":""},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compare performance of different models — compare_performance","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compare performance of different models — compare_performance","text":"Burnham, K. P., Anderson, D. R. (2002). Model selection multimodel inference: practical information-theoretic approach (2nd ed.). Springer-Verlag. doi:10.1007/b97636","code":""},{"path":"https://easystats.github.io/performance/reference/compare_performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare performance of different models — compare_performance","text":"","code":"data(iris) lm1 <- lm(Sepal.Length ~ Species, data = iris) lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris) lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris) compare_performance(lm1, lm2, lm3) #> # Comparison of Model Performance Indices #>  #> Name | Model | AIC (weights) | AICc (weights) | BIC (weights) |    R2 | R2 (adj.) |  RMSE | Sigma #> ------------------------------------------------------------------------------------------------- #> lm1  |    lm | 231.5 (<.001) |  231.7 (<.001) | 243.5 (<.001) | 0.619 |     0.614 | 0.510 | 0.515 #> lm2  |    lm | 106.2 (0.566) |  106.6 (0.611) | 121.3 (0.964) | 0.837 |     0.833 | 0.333 | 0.338 #> lm3  |    lm | 106.8 (0.434) |  107.6 (0.389) | 127.8 (0.036) | 0.840 |     0.835 | 0.330 | 0.336 compare_performance(lm1, lm2, lm3, rank = TRUE) #> # Comparison of Model Performance Indices #>  #> Name | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | AICc weights | BIC weights | Performance-Score #> --------------------------------------------------------------------------------------------------------------- #> lm2  |    lm | 0.837 |     0.833 | 0.333 | 0.338 |       0.566 |        0.611 |       0.964 |            99.23% #> lm3  |    lm | 0.840 |     0.835 | 0.330 | 0.336 |       0.434 |        0.389 |       0.036 |            77.70% #> lm1  |    lm | 0.619 |     0.614 | 0.510 | 0.515 |    3.65e-28 |     4.23e-28 |    2.80e-27 |             0.00%  if (require(\"lme4\")) {   m1 <- lm(mpg ~ wt + cyl, data = mtcars)   m2 <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\")   m3 <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)   compare_performance(m1, m2, m3) } #> Warning: When comparing models, please note that probably not all models were fit #>   from same data. #> # Comparison of Model Performance Indices #>  #> Name |   Model | AIC (weights) | AICc (weights) | BIC (weights) |  RMSE | Sigma |    R2 | R2 (adj.) | Tjur's R2 | Log_loss | Score_log | Score_spherical |   PCP | R2 (cond.) | R2 (marg.) |   ICC #> -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- #> m1   |      lm | 156.0 (<.001) |  157.5 (<.001) | 161.9 (<.001) | 2.444 | 2.568 | 0.830 |     0.819 |           |          |           |                 |       |            |            |       #> m2   |     glm |  31.3 (>.999) |   32.2 (>.999) |  35.7 (>.999) | 0.359 | 0.934 |       |           |     0.478 |    0.395 |   -14.903 |           0.095 | 0.743 |            |            |       #> m3   | lmerMod |  74.6 (<.001) |   74.9 (<.001) |  86.7 (<.001) | 0.279 | 0.283 |       |           |           |          |           |                 |       |      0.972 |      0.096 | 0.969"},{"path":"https://easystats.github.io/performance/reference/cronbachs_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Cronbach's Alpha for Items or Scales — cronbachs_alpha","title":"Cronbach's Alpha for Items or Scales — cronbachs_alpha","text":"Compute various measures internal consistencies tests item-scales questionnaires.","code":""},{"path":"https://easystats.github.io/performance/reference/cronbachs_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cronbach's Alpha for Items or Scales — cronbachs_alpha","text":"","code":"cronbachs_alpha(x)"},{"path":"https://easystats.github.io/performance/reference/cronbachs_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cronbach's Alpha for Items or Scales — cronbachs_alpha","text":"x matrix data frame.","code":""},{"path":"https://easystats.github.io/performance/reference/cronbachs_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cronbach's Alpha for Items or Scales — cronbachs_alpha","text":"Cronbach's Alpha value x.","code":""},{"path":"https://easystats.github.io/performance/reference/cronbachs_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cronbach's Alpha for Items or Scales — cronbachs_alpha","text":"Cronbach's Alpha value x. value closer 1 indicates greater internal consistency, usually following rule thumb applied interpret results: α < 0.5 unacceptable, 0.5 < α < 0.6 poor, 0.6 < α < 0.7 questionable, 0.7 < α < 0.8 acceptable, everything > 0.8 good excellent.","code":""},{"path":"https://easystats.github.io/performance/reference/cronbachs_alpha.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cronbach's Alpha for Items or Scales — cronbachs_alpha","text":"Bland, J. M., Altman, D. G. Statistics notes: Cronbach's alpha. BMJ 1997;314:572. 10.1136/bmj.314.7080.572","code":""},{"path":"https://easystats.github.io/performance/reference/cronbachs_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cronbach's Alpha for Items or Scales — cronbachs_alpha","text":"","code":"data(mtcars) x <- mtcars[, c(\"cyl\", \"gear\", \"carb\", \"hp\")] cronbachs_alpha(x) #> [1] 0.09463206"},{"path":"https://easystats.github.io/performance/reference/display.performance_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print tables in different output formats — display.performance_model","title":"Print tables in different output formats — display.performance_model","text":"Prints tables (.e. data frame) different output formats. print_md() alias display(format = \"markdown\").","code":""},{"path":"https://easystats.github.io/performance/reference/display.performance_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print tables in different output formats — display.performance_model","text":"","code":"# S3 method for performance_model display(object, format = \"markdown\", digits = 2, caption = NULL, ...)  # S3 method for performance_model print_md(   x,   digits = 2,   caption = \"Indices of model performance\",   layout = \"horizontal\",   ... )  # S3 method for compare_performance print_md(   x,   digits = 2,   caption = \"Comparison of Model Performance Indices\",   layout = \"horizontal\",   ... )"},{"path":"https://easystats.github.io/performance/reference/display.performance_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print tables in different output formats — display.performance_model","text":"object, x object returned model_performance() compare_performance(). summary. format String, indicating output format. Currently, \"markdown\" supported. digits Number decimal places. caption Table caption string. NULL, table caption printed. ... Currently used. layout Table layout (can either \"horizontal\" \"vertical\").","code":""},{"path":"https://easystats.github.io/performance/reference/display.performance_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print tables in different output formats — display.performance_model","text":"character vector. format = \"markdown\", return value character vector markdown-table format.","code":""},{"path":"https://easystats.github.io/performance/reference/display.performance_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print tables in different output formats — display.performance_model","text":"display() useful table-output functions, usually printed formatted text-table console, formatted pretty table-rendering markdown documents, knitted rmarkdown PDF Word files. See vignette examples.","code":""},{"path":"https://easystats.github.io/performance/reference/display.performance_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print tables in different output formats — display.performance_model","text":"","code":"model <- lm(mpg ~ wt + cyl, data = mtcars) mp <- model_performance(model) display(mp) #>  #>  #> |AIC    |   AICc |    BIC |   R2 | R2 (adj.) | RMSE | Sigma | #> |:------|:------:|:------:|:----:|:---------:|:----:|:-----:| #> |156.01 | 157.49 | 161.87 | 0.83 |      0.82 | 2.44 |  2.57 |"},{"path":"https://easystats.github.io/performance/reference/icc.html","id":null,"dir":"Reference","previous_headings":"","what":"Intraclass Correlation Coefficient (ICC) — icc","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"function calculates intraclass-correlation coefficient (ICC) - sometimes also called variance partition coefficient (VPC) repeatability - mixed effects models. ICC can calculated models supported insight::get_variance(). models fitted brms-package, icc() might fail due large variety models families supported brms-package. cases, alternative ICC variance_decomposition(), based posterior predictive distribution (see 'Details').","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"","code":"icc(   model,   by_group = FALSE,   tolerance = 1e-05,   ci = NULL,   iterations = 100,   ... )  variance_decomposition(model, re_formula = NULL, robust = TRUE, ci = 0.95, ...)"},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"model (Bayesian) mixed effects model. by_group Logical, TRUE, icc() returns variance components random-effects level (multiple levels). See 'Details'. tolerance Tolerance singularity check random effects, decide whether compute random effect variances . Indicates value convergence result accepted. larger tolerance , stricter test . See performance::check_singularity(). ci Confidence resp. credible interval level. icc() r2(), confidence intervals based bootstrapped samples ICC resp. R2 value. See iterations. iterations Number bootstrap-replicates computing confidence intervals ICC R2. ... Arguments passed brms::posterior_predict(). re_formula Formula containing group-level effects considered prediction. NULL (default), include group-level effects. Else, instance nested models, name specific group-level effect calculate variance decomposition group-level. See 'Details' ?brms::posterior_predict. robust Logical, TRUE, median instead mean used calculate central tendency variances.","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"list two values, adjusted ICC unadjusted ICC. variance_decomposition(), list two values, decomposed ICC well credible intervals ICC.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"interpretation","dir":"Reference","previous_headings":"","what":"Interpretation","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"ICC can interpreted \"proportion variance explained grouping structure population\". grouping structure entails measurements organized groups (e.g., test scores school can grouped classroom multiple classrooms classroom administered test) ICC indexes strongly measurements group resemble . index goes 0, grouping conveys information, 1, observations group identical (Gelman Hill, 2007, p. 258). word, ICC - sometimes conceptualized measurement repeatability - \"can also interpreted expected correlation two randomly drawn units group\" (Hox 2010: 15), although definition might apply mixed models complex random effects structures. ICC can help determine whether mixed model even necessary: ICC zero (close zero) means observations within clusters similar observations different clusters, setting random factor might necessary.","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"difference-with-r-","dir":"Reference","previous_headings":"","what":"Difference with R2","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"coefficient determination R2 (can computed r2()) quantifies proportion variance explained statistical model, definition mixed model complex (hence, different methods compute proxy exist). ICC related R2 ratios variance components. precisely, R2 proportion explained variance (full model), ICC proportion explained variance can attributed random effects. simple cases, ICC corresponds difference conditional R2 marginal R2 (see r2_nakagawa()).","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"calculation","dir":"Reference","previous_headings":"","what":"Calculation","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"ICC calculated dividing random effect variance, σ2i, total variance, .e. sum random effect variance residual variance, σ2ε.","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"adjusted-and-unadjusted-icc","dir":"Reference","previous_headings":"","what":"Adjusted and unadjusted ICC","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"icc() calculates adjusted unadjusted ICC, take sources uncertainty (.e. random effects) account. adjusted ICC relates random effects, unadjusted ICC also takes fixed effects variances account, precisely, fixed effects variance added denominator formula calculate ICC (see Nakagawa et al. 2017). Typically, adjusted ICC interest analysis random effects interest. icc() returns meaningful ICC also complex random effects structures, like models random slopes nested design (two levels) applicable models distributions Gaussian. details computation variances, see ?insight::get_variance.","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"icc-for-unconditional-and-conditional-models","dir":"Reference","previous_headings":"","what":"ICC for unconditional and conditional models","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"Usually, ICC calculated null model (\"unconditional model\"). However, according Raudenbush Bryk (2002) Rabe-Hesketh Skrondal (2012) also feasible compute ICC full models covariates (\"conditional models\") compare much, e.g., level-2 variable explains portion variation grouping structure (random intercept).","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"icc-for-specific-group-levels","dir":"Reference","previous_headings":"","what":"ICC for specific group-levels","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"proportion variance specific levels related overall model can computed setting by_group = TRUE. reported ICC variance (random effect) group compared total variance model. mixed models simple random intercept, identical classical (adjusted) ICC.","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"variance-decomposition-for-brms-models","dir":"Reference","previous_headings":"","what":"Variance decomposition for brms-models","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"model class brmsfit, icc() might fail due large variety models families supported brms package. cases, variance_decomposition() alternative ICC measure. function calculates variance decomposition based posterior predictive distribution. case, first, draws posterior predictive distribution conditioned group-level terms (posterior_predict(..., re_formula = NA)) calculated well draws distribution conditioned random effects (default, unless specified else re_formula) taken. , second, variances draws calculated. \"ICC\" ratio two variances. recommended way analyse random-effect-variances non-Gaussian models. possible compare variances across models, also specifying different group-level terms via re_formula-argument. Sometimes, variance posterior predictive distribution large, variance ratio output makes sense, e.g. negative. cases, might help use robust = TRUE.","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"Hox, J. J. (2010). Multilevel analysis: techniques applications (2nd ed). New York: Routledge. Nakagawa, S., Johnson, P. C. D., Schielzeth, H. (2017). coefficient determination R2 intra-class correlation coefficient generalized linear mixed-effects models revisited expanded. Journal Royal Society Interface, 14(134), 20170213. doi:10.1098/rsif.2017.0213 Rabe-Hesketh, S., Skrondal, . (2012). Multilevel longitudinal modeling using Stata (3rd ed). College Station, Tex: Stata Press Publication. Raudenbush, S. W., Bryk, . S. (2002). Hierarchical linear models: applications data analysis methods (2nd ed). Thousand Oaks: Sage Publications.","code":""},{"path":"https://easystats.github.io/performance/reference/icc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Intraclass Correlation Coefficient (ICC) — icc","text":"","code":"if (require(\"lme4\")) {   model <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)   icc(model) } #> # Intraclass Correlation Coefficient #>  #>     Adjusted ICC: 0.910 #>   Unadjusted ICC: 0.311  # ICC for specific group-levels if (require(\"lme4\")) {   data(sleepstudy)   set.seed(12345)   sleepstudy$grp <- sample(1:5, size = 180, replace = TRUE)   sleepstudy$subgrp <- NA   for (i in 1:5) {     filter_group <- sleepstudy$grp == i     sleepstudy$subgrp[filter_group] <-       sample(1:30, size = sum(filter_group), replace = TRUE)   }   model <- lmer(     Reaction ~ Days + (1 | grp / subgrp) + (1 | Subject),     data = sleepstudy   )   icc(model, by_group = TRUE) } #> # ICC by Group #>  #> Group      |   ICC #> ------------------ #> subgrp:grp | 0.017 #> Subject    | 0.589 #> grp        | 0.001"},{"path":"https://easystats.github.io/performance/reference/item_difficulty.html","id":null,"dir":"Reference","previous_headings":"","what":"Difficulty of Questionnaire Items — item_difficulty","title":"Difficulty of Questionnaire Items — item_difficulty","text":"Compute various measures internal consistencies tests item-scales questionnaires.","code":""},{"path":"https://easystats.github.io/performance/reference/item_difficulty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Difficulty of Questionnaire Items — item_difficulty","text":"","code":"item_difficulty(x)"},{"path":"https://easystats.github.io/performance/reference/item_difficulty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Difficulty of Questionnaire Items — item_difficulty","text":"x Depending function, x may matrix returned cor()-function, data frame items (e.g. test questionnaire).","code":""},{"path":"https://easystats.github.io/performance/reference/item_difficulty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Difficulty of Questionnaire Items — item_difficulty","text":"data frame three columns: name(s) item(s), item difficulties item, ideal item difficulty.","code":""},{"path":"https://easystats.github.io/performance/reference/item_difficulty.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Difficulty of Questionnaire Items — item_difficulty","text":"function calculates item difficulty, range 0.2 0.8. Lower values signal difficult items, higher values close one sign easier items. ideal value item difficulty p + (1 - p) / 2, p = 1 / max(x). cases, ideal item difficulty lies 0.5 0.8.","code":""},{"path":"https://easystats.github.io/performance/reference/item_difficulty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Difficulty of Questionnaire Items — item_difficulty","text":"","code":"data(mtcars) x <- mtcars[, c(\"cyl\", \"gear\", \"carb\", \"hp\")] item_difficulty(x) #> # Item Difficulty #>  #>       difficulty  ideal #>    cyl      0.77   0.56 #>   gear      0.74   0.60 #>   carb      0.35   0.56 #>     hp      0.44   0.50"},{"path":"https://easystats.github.io/performance/reference/item_intercor.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean Inter-Item-Correlation — item_intercor","title":"Mean Inter-Item-Correlation — item_intercor","text":"Compute various measures internal consistencies tests item-scales questionnaires.","code":""},{"path":"https://easystats.github.io/performance/reference/item_intercor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean Inter-Item-Correlation — item_intercor","text":"","code":"item_intercor(x, method = c(\"pearson\", \"spearman\", \"kendall\"))"},{"path":"https://easystats.github.io/performance/reference/item_intercor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean Inter-Item-Correlation — item_intercor","text":"x matrix returned cor()-function, data frame items (e.g. test questionnaire). method Correlation computation method. May one \"spearman\" (default), \"pearson\" \"kendall\". may use initial letter .","code":""},{"path":"https://easystats.github.io/performance/reference/item_intercor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean Inter-Item-Correlation — item_intercor","text":"mean inter-item-correlation value x.","code":""},{"path":"https://easystats.github.io/performance/reference/item_intercor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean Inter-Item-Correlation — item_intercor","text":"function calculates mean inter-item-correlation, .e. correlation matrix x computed (unless x already matrix returned cor()-function) mean sum item's correlation values returned. Requires either data frame computed cor()-object.  “Ideally, average inter-item correlation set items .20 .40, suggesting items reasonably homogeneous, contain sufficiently unique variance isomorphic . values lower .20, items may representative content domain. values higher .40, items may capturing small bandwidth construct.” (Piedmont 2014)","code":""},{"path":"https://easystats.github.io/performance/reference/item_intercor.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean Inter-Item-Correlation — item_intercor","text":"Piedmont RL. 2014. Inter-item Correlations. : Michalos AC (eds) Encyclopedia Quality Life Well-Research. Dordrecht: Springer, 3303-3304. doi:10.1007/978-94-007-0753-5_1493","code":""},{"path":"https://easystats.github.io/performance/reference/item_intercor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean Inter-Item-Correlation — item_intercor","text":"","code":"data(mtcars) x <- mtcars[, c(\"cyl\", \"gear\", \"carb\", \"hp\")] item_intercor(x) #> [1] 0.294155"},{"path":"https://easystats.github.io/performance/reference/item_reliability.html","id":null,"dir":"Reference","previous_headings":"","what":"Reliability Test for Items or Scales — item_reliability","title":"Reliability Test for Items or Scales — item_reliability","text":"Compute various measures internal consistencies tests item-scales questionnaires.","code":""},{"path":"https://easystats.github.io/performance/reference/item_reliability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reliability Test for Items or Scales — item_reliability","text":"","code":"item_reliability(x, standardize = FALSE, digits = 3)"},{"path":"https://easystats.github.io/performance/reference/item_reliability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reliability Test for Items or Scales — item_reliability","text":"x matrix data frame. standardize Logical, TRUE, data frame's vectors standardized. Recommended variables different measures / scales. digits Amount digits returned values.","code":""},{"path":"https://easystats.github.io/performance/reference/item_reliability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reliability Test for Items or Scales — item_reliability","text":"data frame corrected item-total correlations (item discrimination, column item_discrimination) Cronbach's Alpha (item deleted, column alpha_if_deleted) item scale, NULL data frame less columns.","code":""},{"path":"https://easystats.github.io/performance/reference/item_reliability.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reliability Test for Items or Scales — item_reliability","text":"function calculates item discriminations (corrected item-total correlations item x remaining items) Cronbach's alpha item, deleted scale. absolute value item discrimination indices 0.1. index 0.1 0.3 considered \"fair\", index 0.3 (-0.3) \"good\". Items low discrimination indices often ambiguously worded examined. Items negative indices examined determine negative value obtained (e.g. reversed answer categories regarding positive negative poles).","code":""},{"path":"https://easystats.github.io/performance/reference/item_reliability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reliability Test for Items or Scales — item_reliability","text":"","code":"data(mtcars) x <- mtcars[, c(\"cyl\", \"gear\", \"carb\", \"hp\")] item_reliability(x) #>   term alpha_if_deleted item_discrimination #> 1  cyl            0.048               0.826 #> 2 gear            0.110              -0.127 #> 3 carb            0.058               0.751 #> 4   hp            0.411               0.881"},{"path":"https://easystats.github.io/performance/reference/item_split_half.html","id":null,"dir":"Reference","previous_headings":"","what":"Split-Half Reliability — item_split_half","title":"Split-Half Reliability — item_split_half","text":"Compute various measures internal consistencies tests item-scales questionnaires.","code":""},{"path":"https://easystats.github.io/performance/reference/item_split_half.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split-Half Reliability — item_split_half","text":"","code":"item_split_half(x, digits = 3)"},{"path":"https://easystats.github.io/performance/reference/item_split_half.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split-Half Reliability — item_split_half","text":"x matrix data frame. digits Amount digits returned values.","code":""},{"path":"https://easystats.github.io/performance/reference/item_split_half.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split-Half Reliability — item_split_half","text":"list two elements: split-half reliability splithalf Spearman-Brown corrected split-half reliability spearmanbrown.","code":""},{"path":"https://easystats.github.io/performance/reference/item_split_half.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Split-Half Reliability — item_split_half","text":"function calculates split-half reliability items x, including Spearman-Brown adjustment. Splitting done selecting odd versus even columns x. value closer 1 indicates greater internal consistency.","code":""},{"path":"https://easystats.github.io/performance/reference/item_split_half.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Split-Half Reliability — item_split_half","text":"Spearman C. 1910. Correlation calculated faulty data. British Journal Psychology (3): 271-295. doi:10.1111/j.2044-8295.1910.tb00206.x Brown W. 1910. experimental results correlation mental abilities. British Journal Psychology (3): 296-322. doi:10.1111/j.2044-8295.1910.tb00207.x","code":""},{"path":"https://easystats.github.io/performance/reference/item_split_half.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split-Half Reliability — item_split_half","text":"","code":"data(mtcars) x <- mtcars[, c(\"cyl\", \"gear\", \"carb\", \"hp\")] item_split_half(x) #> $splithalf #> [1] 0.9070215 #>  #> $spearmanbrown #> [1] 0.9512441 #>"},{"path":"https://easystats.github.io/performance/reference/looic.html","id":null,"dir":"Reference","previous_headings":"","what":"LOO-related Indices for Bayesian regressions. — looic","title":"LOO-related Indices for Bayesian regressions. — looic","text":"Compute LOOIC (leave-one-cross-validation (LOO) information criterion) ELPD (expected log predictive density) Bayesian regressions. LOOIC ELPD, smaller larger values respectively indicative better fit.","code":""},{"path":"https://easystats.github.io/performance/reference/looic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LOO-related Indices for Bayesian regressions. — looic","text":"","code":"looic(model, verbose = TRUE)"},{"path":"https://easystats.github.io/performance/reference/looic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LOO-related Indices for Bayesian regressions. — looic","text":"model Bayesian regression model. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/performance/reference/looic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LOO-related Indices for Bayesian regressions. — looic","text":"list four elements, ELPD, LOOIC standard errors.","code":""},{"path":"https://easystats.github.io/performance/reference/looic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LOO-related Indices for Bayesian regressions. — looic","text":"","code":"if (require(\"rstanarm\")) {   model <- stan_glm(mpg ~ wt + cyl, data = mtcars, chains = 1, iter = 500, refresh = 0)   looic(model) } #> Loading required package: rstanarm #> Loading required package: Rcpp #> This is rstanarm version 2.21.3 #> - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! #> - Default priors may change, so it's safest to specify priors, even if equivalent to the defaults. #> - For execution on a local, multicore CPU with excess RAM we recommend calling #>   options(mc.cores = parallel::detectCores()) #>  #> Attaching package: ‘rstanarm’ #> The following object is masked from ‘package:car’: #>  #>     logit #> The following object is masked from ‘package:psych’: #>  #>     logit #> The following object is masked from ‘package:parameters’: #>  #>     compare_models #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> # LOOIC and ELPD with Standard Error #>  #>   LOOIC: 155.90 [8.79] #>    ELPD: -77.95 [4.39]"},{"path":"https://easystats.github.io/performance/reference/model_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Performance — model_performance","title":"Model Performance — model_performance","text":"See documentation object's class: Frequentist Regressions Instrumental Variables Regressions Mixed models Bayesian models CFA / SEM lavaan models Meta-analysis models","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Performance — model_performance","text":"","code":"model_performance(model, ...)  performance(model, ...)"},{"path":"https://easystats.github.io/performance/reference/model_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Performance — model_performance","text":"model Statistical model. ... Arguments passed methods, resp. compare_performance(), one multiple model objects (also different classes).","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Performance — model_performance","text":"data frame (one row) one column per \"index\" (see metrics).","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Performance — model_performance","text":"model_performance() correctly detects transformed response returns \"corrected\" AIC BIC value original scale. get back original scale, likelihood model multiplied Jacobian/derivative transformation.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/model_performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Performance — model_performance","text":"","code":"model <- lm(mpg ~ wt + cyl, data = mtcars) model_performance(model) #> # Indices of model performance #>  #> AIC     |    AICc |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma #> --------------------------------------------------------------- #> 156.010 | 157.492 | 161.873 | 0.830 |     0.819 | 2.444 | 2.568  model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") model_performance(model) #> # Indices of model performance #>  #> AIC    |   AICc |    BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP #> ----------------------------------------------------------------------------------------------------- #> 31.298 | 32.155 | 35.695 |     0.478 | 0.359 | 0.934 |    0.395 |   -14.903 |           0.095 | 0.743"},{"path":"https://easystats.github.io/performance/reference/model_performance.ivreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance of instrumental variable regression models — model_performance.ivreg","title":"Performance of instrumental variable regression models — model_performance.ivreg","text":"Performance instrumental variable regression models","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.ivreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance of instrumental variable regression models — model_performance.ivreg","text":"","code":"# S3 method for ivreg model_performance(model, metrics = \"all\", verbose = TRUE, ...)"},{"path":"https://easystats.github.io/performance/reference/model_performance.ivreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance of instrumental variable regression models — model_performance.ivreg","text":"model model. metrics Can \"\", \"common\" character vector metrics computed (c(\"AIC\", \"AICc\", \"BIC\", \"R2\", \"RMSE\", \"SIGMA\", \"Sargan\", \"Wu_Hausman\")). \"common\" compute AIC, BIC, R2 RMSE. verbose Toggle warnings. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.ivreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performance of instrumental variable regression models — model_performance.ivreg","text":"model_performance() correctly detects transformed response returns \"corrected\" AIC BIC value original scale. get back original scale, likelihood model multiplied Jacobian/derivative transformation.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Model summary for k-means clustering — model_performance.kmeans","title":"Model summary for k-means clustering — model_performance.kmeans","text":"Model summary k-means clustering","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model summary for k-means clustering — model_performance.kmeans","text":"","code":"# S3 method for kmeans model_performance(model, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/performance/reference/model_performance.kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model summary for k-means clustering — model_performance.kmeans","text":"model Object type kmeans. verbose Toggle warnings. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model summary for k-means clustering — model_performance.kmeans","text":"","code":"# a 2-dimensional example x <- rbind(   matrix(rnorm(100, sd = 0.3), ncol = 2),   matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2) ) colnames(x) <- c(\"x\", \"y\") model <- kmeans(x, 2) model_performance(model) #> # Indices of model performance #>  #> Sum_Squares_Total | Sum_Squares_Within | Sum_Squares_Between | Iterations #> ------------------------------------------------------------------------- #> 71.530            |             16.523 |              55.007 |      1.000"},{"path":"https://easystats.github.io/performance/reference/model_performance.lavaan.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance of lavaan SEM / CFA Models — model_performance.lavaan","title":"Performance of lavaan SEM / CFA Models — model_performance.lavaan","text":"Compute indices model performance SEM CFA models lavaan package.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.lavaan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance of lavaan SEM / CFA Models — model_performance.lavaan","text":"","code":"# S3 method for lavaan model_performance(model, metrics = \"all\", verbose = TRUE, ...)"},{"path":"https://easystats.github.io/performance/reference/model_performance.lavaan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance of lavaan SEM / CFA Models — model_performance.lavaan","text":"model lavaan model. metrics Can \"\" character vector metrics computed (c(\"Chi2\", \"Chi2_df\", \"p_Chi2\", \"Baseline\", \"Baseline_df\", \"p_Baseline\", \"GFI\", \"AGFI\", \"NFI\", \"NNFI\", \"CFI\", \"RMSEA\", \"RMSEA_CI_low\", \"RMSEA_CI_high\", \"p_RMSEA\", \"RMR\", \"SRMR\", \"RFI\", \"PNFI\", \"IFI\", \"RNI\", \"Loglikelihood\", \"AIC\", \"BIC\", \"BIC_adjusted\")). verbose Toggle warnings. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.lavaan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance of lavaan SEM / CFA Models — model_performance.lavaan","text":"data frame (one row) one column per \"index\" (see metrics).","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/model_performance.lavaan.html","id":"indices-of-fit","dir":"Reference","previous_headings":"","what":"Indices of fit","title":"Performance of lavaan SEM / CFA Models — model_performance.lavaan","text":"Chisq: model Chi-squared assesses overall fit discrepancy sample fitted covariance matrices. p-value > .05 (.e., hypothesis perfect fit rejected). However, quite sensitive sample size. GFI/AGFI: (Adjusted) Goodness Fit proportion variance accounted estimated population covariance. Analogous R2. GFI AGFI > .95 > .90, respectively. NFI/NNFI/TLI: (Non) Normed Fit Index. NFI 0.95, indicates model interest improves fit 95\\ null model. NNFI (also called Tucker Lewis index; TLI) preferable smaller samples. > .90 (Byrne, 1994) > .95 (Schumacker Lomax, 2004). CFI: Comparative Fit Index revised form NFI. sensitive sample size (Fan, Thompson, Wang, 1999). Compares fit target model fit independent, null, model. > .90. RMSEA: Root Mean Square Error Approximation parsimony-adjusted index. Values closer 0 represent good fit. < .08 < .05. p-value printed tests hypothesis RMSEA less equal .05 (cutoff sometimes used good fit), thus significant. RMR/SRMR: (Standardized) Root Mean Square Residual represents square-root difference residuals sample covariance matrix hypothesized model. RMR can sometimes hard interpret, better use SRMR. < .08. RFI: Relative Fit Index, also known RHO1, guaranteed vary 0 1. However, RFI close 1 indicates good fit. IFI: Incremental Fit Index (IFI) adjusts Normed Fit Index (NFI) sample size degrees freedom (Bollen's, 1989). 0.90 good fit, index can exceed 1. PNFI: Parsimony-Adjusted Measures Index. commonly agreed-upon cutoff value acceptable model index. > 0.50. See documentation ?lavaan::fitmeasures.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.lavaan.html","id":"what-to-report","dir":"Reference","previous_headings":"","what":"What to report","title":"Performance of lavaan SEM / CFA Models — model_performance.lavaan","text":"Kline (2015) suggests minimum following indices reported: model chi-square, RMSEA, CFI SRMR.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.lavaan.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Performance of lavaan SEM / CFA Models — model_performance.lavaan","text":"Byrne, B. M. (1994). Structural equation modeling EQS EQS/Windows. Thousand Oaks, CA: Sage Publications. Tucker, L. R., Lewis, C. (1973). reliability coefficient maximum likelihood factor analysis. Psychometrika, 38, 1-10. Schumacker, R. E., Lomax, R. G. (2004). beginner's guide structural equation modeling, Second edition. Mahwah, NJ: Lawrence Erlbaum Associates. Fan, X., B. Thompson, L. Wang (1999). Effects sample size, estimation method, model specification structural equation modeling fit indexes. Structural Equation Modeling, 6, 56-83. Kline, R. B. (2015). Principles practice structural equation modeling. Guilford publications.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.lavaan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance of lavaan SEM / CFA Models — model_performance.lavaan","text":"","code":"# Confirmatory Factor Analysis (CFA) --------- if (require(\"lavaan\")) {   structure <- \" visual  =~ x1 + x2 + x3                  textual =~ x4 + x5 + x6                  speed   =~ x7 + x8 + x9 \"   model <- lavaan::cfa(structure, data = HolzingerSwineford1939)   model_performance(model) } #> Loading required package: lavaan #> This is lavaan 0.6-12 #> lavaan is FREE software! Please report any bugs. #>  #> Attaching package: ‘lavaan’ #> The following object is masked from ‘package:psych’: #>  #>     cor2cov #> # Indices of model performance #>  #> Chi2(24) | p (Chi2) | Baseline(36) | p (Baseline) |   GFI |  AGFI |   NFI |  NNFI |   CFI | RMSEA |    RMSEA  CI | p (RMSEA) |   RMR |  SRMR |   RFI |  PNFI |   IFI |   RNI | Loglikelihood |      AIC |      BIC | BIC_adjusted #> --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- #> 85.306   |   < .001 |      918.852 |       < .001 | 0.943 | 0.894 | 0.907 | 0.896 | 0.931 | 0.092 | [0.07, 0.11] |    < .001 | 0.082 | 0.065 | 0.861 | 0.605 | 0.931 | 0.931 |     -3737.745 | 7517.490 | 7595.339 |     7528.739"},{"path":"https://easystats.github.io/performance/reference/model_performance.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance of Regression Models — model_performance.lm","title":"Performance of Regression Models — model_performance.lm","text":"Compute indices model performance regression models.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance of Regression Models — model_performance.lm","text":"","code":"# S3 method for lm model_performance(model, metrics = \"all\", verbose = TRUE, ...)"},{"path":"https://easystats.github.io/performance/reference/model_performance.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance of Regression Models — model_performance.lm","text":"model model. metrics Can \"\", \"common\" character vector metrics computed (one \"AIC\", \"AICc\", \"BIC\", \"R2\", \"R2_adj\", \"RMSE\", \"SIGMA\", \"LOGLOSS\", \"PCP\", \"SCORE\"). \"common\" compute AIC, BIC, R2 RMSE. verbose Toggle warnings. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance of Regression Models — model_performance.lm","text":"data frame (one row) one column per \"index\" (see metrics).","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performance of Regression Models — model_performance.lm","text":"Depending model, following indices computed: AIC: Akaike's Information Criterion, see ?stats::AIC AICc: Second-order (small sample) AIC correction small sample sizes BIC: Bayesian Information Criterion, see ?stats::BIC R2: r-squared value, see r2() R2_adj: adjusted r-squared, see r2() RMSE: root mean squared error, see performance_rmse() SIGMA: residual standard deviation, see insight::get_sigma() LOGLOSS: Log-loss, see performance_logloss() SCORE_LOG: score logarithmic proper scoring rule, see performance_score() SCORE_SPHERICAL: score spherical proper scoring rule, see performance_score() PCP: percentage correct predictions, see performance_pcp() model_performance() correctly detects transformed response returns \"corrected\" AIC BIC value original scale. get back original scale, likelihood model multiplied Jacobian/derivative transformation.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance of Regression Models — model_performance.lm","text":"","code":"model <- lm(mpg ~ wt + cyl, data = mtcars) model_performance(model) #> # Indices of model performance #>  #> AIC     |    AICc |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma #> --------------------------------------------------------------- #> 156.010 | 157.492 | 161.873 | 0.830 |     0.819 | 2.444 | 2.568  model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") model_performance(model) #> # Indices of model performance #>  #> AIC    |   AICc |    BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP #> ----------------------------------------------------------------------------------------------------- #> 31.298 | 32.155 | 35.695 |     0.478 | 0.359 | 0.934 |    0.395 |   -14.903 |           0.095 | 0.743"},{"path":"https://easystats.github.io/performance/reference/model_performance.merMod.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance of Mixed Models — model_performance.merMod","title":"Performance of Mixed Models — model_performance.merMod","text":"Compute indices model performance mixed models.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.merMod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance of Mixed Models — model_performance.merMod","text":"","code":"# S3 method for merMod model_performance(   model,   metrics = \"all\",   estimator = \"REML\",   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/performance/reference/model_performance.merMod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance of Mixed Models — model_performance.merMod","text":"model mixed effects model. metrics Can \"\", \"common\" character vector metrics computed (c(\"AIC\", \"AICc\", \"BIC\", \"R2\", \"ICC\", \"RMSE\", \"SIGMA\", \"LOGLOSS\", \"SCORE\")). \"common\" compute AIC, BIC, R2, ICC RMSE. estimator linear models. Corresponds different estimators standard deviation errors. estimator = \"ML\" (default), scaling done n (biased ML estimator), equivalent using AIC(logLik()). Setting \"REML\" give results AIC(logLik(..., REML = TRUE)). verbose Toggle warnings. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.merMod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance of Mixed Models — model_performance.merMod","text":"data frame (one row) one column per \"index\" (see metrics).","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/model_performance.merMod.html","id":"intraclass-correlation-coefficient-icc-","dir":"Reference","previous_headings":"","what":"Intraclass Correlation Coefficient (ICC)","title":"Performance of Mixed Models — model_performance.merMod","text":"method returns adjusted ICC , typically interest judging variance attributed random effects part model (see also icc()).","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.merMod.html","id":"reml-versus-ml-estimator","dir":"Reference","previous_headings":"","what":"REML versus ML estimator","title":"Performance of Mixed Models — model_performance.merMod","text":"default behaviour model_performance() computing AIC BIC linear mixed model package lme4 AIC() BIC() (.e. estimator = \"REML\"). However, model comparison using compare_performance() sets estimator = \"ML\" default, comparing information criteria based REML fits usually valid (unless models fixed effects). Thus, make sure set correct estimator-value looking fit-indices comparing model fits.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.merMod.html","id":"other-performance-indices","dir":"Reference","previous_headings":"","what":"Other performance indices","title":"Performance of Mixed Models — model_performance.merMod","text":"Furthermore, see 'Details' model_performance.lm() details returned indices.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.merMod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance of Mixed Models — model_performance.merMod","text":"","code":"if (require(\"lme4\")) {   model <- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)   model_performance(model) } #> # Indices of model performance #>  #> AIC    |   AICc |    BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma #> -------------------------------------------------------------------------- #> 77.320 | 77.595 | 89.362 |      0.972 |      0.096 | 0.969 | 0.279 | 0.283"},{"path":"https://easystats.github.io/performance/reference/model_performance.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance of Meta-Analysis Models — model_performance.rma","title":"Performance of Meta-Analysis Models — model_performance.rma","text":"Compute indices model performance meta-analysis model metafor package.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance of Meta-Analysis Models — model_performance.rma","text":"","code":"# S3 method for rma model_performance(   model,   metrics = \"all\",   estimator = \"ML\",   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/performance/reference/model_performance.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance of Meta-Analysis Models — model_performance.rma","text":"model rma object returned metafor::rma(). metrics Can \"\" character vector metrics computed (c(\"AIC\", \"BIC\", \"I2\", \"H2\", \"TAU2\", \"R2\", \"CochransQ\", \"QE\", \"Omnibus\", \"QM\")). estimator linear models. Corresponds different estimators standard deviation errors. estimator = \"ML\" (default), scaling done n (biased ML estimator), equivalent using AIC(logLik()). Setting \"REML\" give results AIC(logLik(..., REML = TRUE)). verbose Toggle warnings. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance of Meta-Analysis Models — model_performance.rma","text":"data frame (one row) one column per \"index\" (see metrics).","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/model_performance.rma.html","id":"indices-of-fit","dir":"Reference","previous_headings":"","what":"Indices of fit","title":"Performance of Meta-Analysis Models — model_performance.rma","text":"AIC Akaike's Information Criterion, see ?stats::AIC BIC Bayesian Information Criterion, see ?stats::BIC I2: random effects model, I2 estimates (percent) much total variability effect size estimates can attributed heterogeneity among true effects. mixed-effects model, I2 estimates much unaccounted variability can attributed residual heterogeneity. H2: random-effects model, H2 estimates ratio total amount variability effect size estimates amount sampling variability. mixed-effects model, H2 estimates ratio unaccounted variability effect size estimates amount sampling variability. TAU2: amount (residual) heterogeneity random mixed effects model. CochransQ (QE): Test (residual) Heterogeneity. Without moderators model, simply Cochran's Q-test. Omnibus (QM): Omnibus test parameters. R2: Pseudo-R2-statistic, indicates amount heterogeneity accounted moderators included fixed-effects model. See documentation ?metafor::fitstats.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance of Meta-Analysis Models — model_performance.rma","text":"","code":"if (require(\"metafor\")) {   data(dat.bcg)   dat <- escalc(measure = \"RR\", ai = tpos, bi = tneg, ci = cpos, di = cneg, data = dat.bcg)   model <- rma(yi, vi, data = dat, method = \"REML\")   model_performance(model) } #> Loading required package: metafor #> Loading required package: metadat #>  #> Loading the 'metafor' package (version 3.8-1). For an #> introduction to the package please type: help(metafor) #>  #> Attaching package: ‘metafor’ #> The following object is masked from ‘package:car’: #>  #>     vif #> # Indices of model performance #>  #> AIC    |    BIC |    I2 |     H2 |  TAU2 | CochransQ | p (CochransQ) | df | Omnibus | p (Omnibus) #> ------------------------------------------------------------------------------------------------- #> 29.376 | 30.345 | 0.922 | 12.856 | 0.313 |   152.233 |        < .001 | 12 |  15.796 |      < .001"},{"path":"https://easystats.github.io/performance/reference/model_performance.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance of Bayesian Models — model_performance.stanreg","title":"Performance of Bayesian Models — model_performance.stanreg","text":"Compute indices model performance (general) linear models.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance of Bayesian Models — model_performance.stanreg","text":"","code":"# S3 method for stanreg model_performance(model, metrics = \"all\", verbose = TRUE, ...)  # S3 method for BFBayesFactor model_performance(   model,   metrics = \"all\",   verbose = TRUE,   average = FALSE,   prior_odds = NULL,   ... )"},{"path":"https://easystats.github.io/performance/reference/model_performance.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance of Bayesian Models — model_performance.stanreg","text":"model Object class stanreg brmsfit. metrics Can \"\", \"common\" character vector metrics computed (c(\"LOOIC\", \"WAIC\", \"R2\", \"R2_adj\", \"RMSE\", \"SIGMA\", \"LOGLOSS\", \"SCORE\")). \"common\" compute LOOIC, WAIC, R2 RMSE. verbose Toggle warnings. ... Arguments passed methods. average Compute model-averaged index? See bayestestR::weighted_posteriors(). prior_odds Optional vector prior odds models compared first model (denominator, BFBayesFactor objects). data.frames, used basis weighting.","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance of Bayesian Models — model_performance.stanreg","text":"data frame (one row) one column per \"index\" (see metrics).","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.stanreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performance of Bayesian Models — model_performance.stanreg","text":"Depending model, following indices computed: ELPD expected log predictive density. Larger ELPD values mean better fit. See looic(). LOOIC leave-one-cross-validation (LOO) information criterion. Lower LOOIC values mean better fit. See looic(). WAIC widely applicable information criterion. Lower WAIC values mean better fit. See ?loo::waic. R2 r-squared value, see r2_bayes(). R2_adjusted LOO-adjusted r-squared, see r2_loo(). RMSE root mean squared error, see performance_rmse(). SIGMA residual standard deviation, see insight::get_sigma(). LOGLOSS Log-loss, see performance_logloss(). SCORE_LOG score logarithmic proper scoring rule, see performance_score(). SCORE_SPHERICAL score spherical proper scoring rule, see performance_score(). PCP percentage correct predictions, see performance_pcp().","code":""},{"path":"https://easystats.github.io/performance/reference/model_performance.stanreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Performance of Bayesian Models — model_performance.stanreg","text":"Gelman, ., Goodrich, B., Gabry, J., Vehtari, . (2018). R-squared Bayesian regression models. American Statistician, American Statistician, 1-6.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/model_performance.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance of Bayesian Models — model_performance.stanreg","text":"","code":"if (FALSE) { if (require(\"rstanarm\") && require(\"rstantools\")) {   model <- stan_glm(mpg ~ wt + cyl, data = mtcars, chains = 1, iter = 500, refresh = 0)   model_performance(model)    model <- stan_glmer(     mpg ~ wt + cyl + (1 | gear),     data = mtcars,     chains = 1,     iter = 500,     refresh = 0   )   model_performance(model) }  if (require(\"BayesFactor\") && require(\"rstantools\")) {   model <- generalTestBF(carb ~ am + mpg, mtcars)    model_performance(model)   model_performance(model[3])    model_performance(model, average = TRUE) } }"},{"path":"https://easystats.github.io/performance/reference/performance_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Accuracy of predictions from model fit — performance_accuracy","title":"Accuracy of predictions from model fit — performance_accuracy","text":"function calculates predictive accuracy linear logistic regression models.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Accuracy of predictions from model fit — performance_accuracy","text":"","code":"performance_accuracy(   model,   method = c(\"cv\", \"boot\"),   k = 5,   n = 1000,   verbose = TRUE )"},{"path":"https://easystats.github.io/performance/reference/performance_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Accuracy of predictions from model fit — performance_accuracy","text":"model linear logistic regression model. mixed-effects model also accepted. method Character string, indicating whether cross-validation (method = \"cv\") bootstrapping (method = \"boot\") used compute accuracy values. k number folds k-fold cross-validation. n Number bootstrap-samples. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Accuracy of predictions from model fit — performance_accuracy","text":"list three values: Accuracy model predictions, .e. proportion accurately predicted values model, standard error, SE, Method used compute accuracy.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_accuracy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Accuracy of predictions from model fit — performance_accuracy","text":"linear models, accuracy correlation coefficient actual predicted value outcome. logistic regression models, accuracy corresponds AUC-value, calculated bayestestR::auc()-function.  accuracy mean value multiple correlation resp. AUC-values, either computed cross-validation non-parametric bootstrapping (see argument method). standard error standard deviation computed correlation resp. AUC-values.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_accuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Accuracy of predictions from model fit — performance_accuracy","text":"","code":"model <- lm(mpg ~ wt + cyl, data = mtcars) performance_accuracy(model) #> # Accuracy of Model Predictions #>  #> Accuracy: 92.35% #>       SE: 4.85%-points #>   Method: Correlation between observed and predicted  model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") performance_accuracy(model) #> # Accuracy of Model Predictions #>  #> Accuracy: 89.44% #>       SE: 19.29%-points #>   Method: Area under Curve"},{"path":"https://easystats.github.io/performance/reference/performance_aicc.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the AIC or second-order AIC — performance_aicc","title":"Compute the AIC or second-order AIC — performance_aicc","text":"Compute AIC second-order Akaike's information criterion (AICc). performance_aic() small wrapper returns AIC, however, models transformed response variable, performance_aic() returns corrected AIC value (see 'Examples'). generic function also works models AIC method (like Tweedie models). performance_aicc() returns second-order (\"small sample\") AIC incorporates correction small sample sizes.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_aicc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the AIC or second-order AIC — performance_aicc","text":"","code":"performance_aicc(x, ...)  performance_aic(x, ...)  # S3 method for default performance_aic(x, estimator = \"ML\", verbose = TRUE, ...)"},{"path":"https://easystats.github.io/performance/reference/performance_aicc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the AIC or second-order AIC — performance_aicc","text":"x model object. ... Currently used. estimator linear models. Corresponds different estimators standard deviation errors. estimator = \"ML\" (default), scaling done n (biased ML estimator), equivalent using AIC(logLik()). Setting \"REML\" give results AIC(logLik(..., REML = TRUE)). verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_aicc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the AIC or second-order AIC — performance_aicc","text":"Numeric, AIC AICc value.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_aicc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the AIC or second-order AIC — performance_aicc","text":"performance_aic() correctly detects transformed response , unlike stats::AIC(), returns \"corrected\" AIC value original scale. get back original scale, likelihood model multiplied Jacobian/derivative transformation.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_aicc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the AIC or second-order AIC — performance_aicc","text":"Akaike, H. (1973) Information theory extension maximum likelihood principle. : Second International Symposium Information Theory, pp. 267-281. Petrov, B.N., Csaki, F., Eds, Akademiai Kiado, Budapest. Hurvich, C. M., Tsai, C.-L. (1991) Bias corrected AIC criterion underfitted regression time series models. Biometrika 78, 499–509.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_aicc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the AIC or second-order AIC — performance_aicc","text":"","code":"m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars) AIC(m) #> [1] 159.1051 performance_aicc(m) #> [1] 162.4651  # correct AIC for models with transformed response variable data(\"mtcars\") mtcars$mpg <- floor(mtcars$mpg) model <- lm(log(mpg) ~ factor(cyl), mtcars)  # wrong AIC, not corrected for log-transformation AIC(model) #> [1] -19.67061  # performance_aic() correctly detects transformed response and # returns corrected AIC performance_aic(model) #> [1] 168.2152"},{"path":"https://easystats.github.io/performance/reference/performance_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validated model performance — performance_cv","title":"Cross-validated model performance — performance_cv","text":"function cross-validates regression models user-supplied new sample using holdout (train-test), k-fold, leave-one-cross-validation.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validated model performance — performance_cv","text":"","code":"performance_cv(   model,   data = NULL,   method = c(\"holdout\", \"k_fold\", \"loo\"),   metrics = \"all\",   prop = 0.3,   k = 5,   stack = TRUE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/performance/reference/performance_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validated model performance — performance_cv","text":"model regression model. data Optional. data frame containing variables model used cross-validation sample. method Character string, indicating cross-validation method use: whether holdout (\"holdout\", aka train-test), k-fold (\"k_fold\"), leave-one-(\"loo\"). data supplied, argument ignored. metrics Can \"\", \"common\" character vector metrics computed (c(\"ELPD\", \"Deviance\", \"MSE\", \"RMSE\", \"R2\")). \"common\" compute R2 RMSE. prop method = \"holdout\", proportion sample hold test sample? k method = \"k_fold\", number folds use. stack Logical. method = \"k_fold\", performance computed stacking residuals holdout fold calculating metric stacked data (TRUE, default) performance computed calculating metrics within holdout fold averaging performance across fold (FALSE)? verbose Toggle warnings. ... used.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validated model performance — performance_cv","text":"data frame columns metric requested, well k method = \"holdout\" Method used cross-validation. method = \"holdout\" stack = TRUE, standard error (standard deviation across holdout folds) metric also included.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validated model performance — performance_cv","text":"","code":"model <- lm(mpg ~ wt + cyl, data = mtcars) performance_cv(model) #> # Cross-validation performance (30% holdout method) #>  #> MSE | RMSE |   R2 #> ----------------- #> 7.6 |  2.8 | 0.63"},{"path":"https://easystats.github.io/performance/reference/performance_hosmer.html","id":null,"dir":"Reference","previous_headings":"","what":"Hosmer-Lemeshow goodness-of-fit test — performance_hosmer","title":"Hosmer-Lemeshow goodness-of-fit test — performance_hosmer","text":"Check model quality logistic regression models.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_hosmer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hosmer-Lemeshow goodness-of-fit test — performance_hosmer","text":"","code":"performance_hosmer(model, n_bins = 10)"},{"path":"https://easystats.github.io/performance/reference/performance_hosmer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hosmer-Lemeshow goodness-of-fit test — performance_hosmer","text":"model glm-object binomial-family. n_bins Numeric, number bins divide data.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_hosmer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hosmer-Lemeshow goodness-of-fit test — performance_hosmer","text":"object class hoslem_test following values: chisq, Hosmer-Lemeshow chi-squared statistic; df, degrees freedom p.value p-value goodness--fit test.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_hosmer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hosmer-Lemeshow goodness-of-fit test — performance_hosmer","text":"well-fitting model shows significant difference model observed data, .e. reported p-value greater 0.05.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_hosmer.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hosmer-Lemeshow goodness-of-fit test — performance_hosmer","text":"Hosmer, D. W., Lemeshow, S. (2000). Applied Logistic Regression. Hoboken, NJ, USA: John Wiley Sons, Inc. doi:10.1002/0471722146","code":""},{"path":"https://easystats.github.io/performance/reference/performance_hosmer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hosmer-Lemeshow goodness-of-fit test — performance_hosmer","text":"","code":"model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") performance_hosmer(model) #> # Hosmer-Lemeshow Goodness-of-Fit Test #>  #>   Chi-squared: 5.137 #>            df: 8     #>       p-value: 0.743 #>  #> Summary: model seems to fit well."},{"path":"https://easystats.github.io/performance/reference/performance_logloss.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Loss — performance_logloss","title":"Log Loss — performance_logloss","text":"Compute log loss models binary outcome.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_logloss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Loss — performance_logloss","text":"","code":"performance_logloss(model, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/performance/reference/performance_logloss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Loss — performance_logloss","text":"model Model binary outcome. verbose Toggle warnings. ... Currently used.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_logloss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Loss — performance_logloss","text":"Numeric, log loss model.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_logloss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Loss — performance_logloss","text":"Logistic regression models predict probability outcome \"success\" \"failure\" (1 0 etc.). performance_logloss() evaluates good bad predicted probabilities . High values indicate bad predictions, low values indicate good predictions. lower log-loss, better model predicts outcome.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/performance_logloss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Loss — performance_logloss","text":"","code":"data(mtcars) m <- glm(formula = vs ~ hp + wt, family = binomial, data = mtcars) performance_logloss(m) #> [1] 0.2517054"},{"path":"https://easystats.github.io/performance/reference/performance_mae.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean Absolute Error of Models — performance_mae","title":"Mean Absolute Error of Models — performance_mae","text":"Compute mean absolute error models.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean Absolute Error of Models — performance_mae","text":"","code":"performance_mae(model, ...)  mae(model, ...)"},{"path":"https://easystats.github.io/performance/reference/performance_mae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean Absolute Error of Models — performance_mae","text":"model model. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_mae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean Absolute Error of Models — performance_mae","text":"Numeric, mean absolute error model.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_mae.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean Absolute Error of Models — performance_mae","text":"","code":"data(mtcars) m <- lm(mpg ~ hp + gear, data = mtcars) performance_mae(m) #> [1] 2.545822"},{"path":"https://easystats.github.io/performance/reference/performance_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean Square Error of Linear Models — performance_mse","title":"Mean Square Error of Linear Models — performance_mse","text":"Compute mean square error linear models.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean Square Error of Linear Models — performance_mse","text":"","code":"performance_mse(model, ...)  mse(model, ...)"},{"path":"https://easystats.github.io/performance/reference/performance_mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean Square Error of Linear Models — performance_mse","text":"model model. ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean Square Error of Linear Models — performance_mse","text":"Numeric, mean square error model.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_mse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean Square Error of Linear Models — performance_mse","text":"mean square error mean sum squared residuals, .e. measures average squares errors. Less technically speaking, mean square error can considered variance residuals, .e. variation outcome model explain. Lower values (closer zero) indicate better fit.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_mse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean Square Error of Linear Models — performance_mse","text":"","code":"data(mtcars) m <- lm(mpg ~ hp + gear, data = mtcars) performance_mse(m) #> [1] 8.752858"},{"path":"https://easystats.github.io/performance/reference/performance_pcp.html","id":null,"dir":"Reference","previous_headings":"","what":"Percentage of Correct Predictions — performance_pcp","title":"Percentage of Correct Predictions — performance_pcp","text":"Percentage correct predictions (PCP) models binary outcome.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_pcp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Percentage of Correct Predictions — performance_pcp","text":"","code":"performance_pcp(model, ci = 0.95, method = \"Herron\", verbose = TRUE)"},{"path":"https://easystats.github.io/performance/reference/performance_pcp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Percentage of Correct Predictions — performance_pcp","text":"model Model binary outcome. ci level confidence interval. method Name method calculate PCP (see 'Details'). Default \"Herron\". May abbreviated. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_pcp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Percentage of Correct Predictions — performance_pcp","text":"list several elements: percentage correct predictions full null model, confidence intervals, well chi-squared p-value Likelihood-Ratio-Test full null model.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_pcp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Percentage of Correct Predictions — performance_pcp","text":"method = \"Gelman-Hill\" (\"gelman_hill\") computes PCP based proposal Gelman Hill 2017, 99, defined proportion cases deterministic prediction wrong, .e. proportion predicted probability 0.5, although y=0 (vice versa) (see also Herron 1999, 90). method = \"Herron\" (\"herron\") computes modified version PCP (Herron 1999, 90-92), sum predicted probabilities, y=1, plus sum 1 - predicted probabilities, y=0, divided number observations. approach said accurate. PCP ranges 0 1, values closer 1 mean model predicts outcome better models PCP closer 0. general, PCP 0.5 (.e. 50\\ Furthermore, PCP full model considerably null model's PCP. likelihood-ratio test indicates whether model significantly better fit null-model (cases, p < 0.05).","code":""},{"path":"https://easystats.github.io/performance/reference/performance_pcp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Percentage of Correct Predictions — performance_pcp","text":"Herron, M. (1999). Postestimation Uncertainty Limited Dependent Variable Models. Political Analysis, 8, 83–98. Gelman, ., Hill, J. (2007). Data analysis using regression multilevel/hierarchical models. Cambridge; New York: Cambridge University Press, 99.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_pcp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Percentage of Correct Predictions — performance_pcp","text":"","code":"data(mtcars) m <- glm(formula = vs ~ hp + wt, family = binomial, data = mtcars) performance_pcp(m) #> # Percentage of Correct Predictions from Logistic Regression Model #>  #>   Full model: 83.75% [70.96% - 96.53%] #>   Null model: 50.78% [33.46% - 68.10%] #>  #> # Likelihood-Ratio-Test #>  #>   Chi-squared: 27.751 #>   df:  2.000 #>   p-value:  0.000 #>  performance_pcp(m, method = \"Gelman-Hill\") #> # Percentage of Correct Predictions from Logistic Regression Model #>  #>   Full model: 87.50% [76.04% - 98.96%] #>   Null model: 56.25% [39.06% - 73.44%] #>  #> # Likelihood-Ratio-Test #>  #>   Chi-squared: 27.751 #>   df:  2.000 #>   p-value:  0.000 #>"},{"path":"https://easystats.github.io/performance/reference/performance_rmse.html","id":null,"dir":"Reference","previous_headings":"","what":"Root Mean Squared Error — performance_rmse","title":"Root Mean Squared Error — performance_rmse","text":"Compute root mean squared error (mixed effects) models, including Bayesian regression models.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_rmse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Root Mean Squared Error — performance_rmse","text":"","code":"performance_rmse(model, normalized = FALSE, verbose = TRUE)  rmse(model, normalized = FALSE, verbose = TRUE)"},{"path":"https://easystats.github.io/performance/reference/performance_rmse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Root Mean Squared Error — performance_rmse","text":"model model. normalized Logical, use TRUE normalized rmse returned. verbose Toggle warnings.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_rmse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Root Mean Squared Error — performance_rmse","text":"Numeric, root mean squared error.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_rmse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Root Mean Squared Error — performance_rmse","text":"RMSE square root variance residuals indicates absolute fit model data (difference observed data model's predicted values). can interpreted standard deviation unexplained variance, units response variable. Lower values indicate better model fit. normalized RMSE proportion RMSE related range response variable. Hence, lower values indicate less residual variance.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_rmse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Root Mean Squared Error — performance_rmse","text":"","code":"if (require(\"nlme\")) {   m <- lme(distance ~ age, data = Orthodont)    # RMSE   performance_rmse(m, normalized = FALSE)    # normalized RMSE   performance_rmse(m, normalized = TRUE) } #> Loading required package: nlme #>  #> Attaching package: ‘nlme’ #> The following object is masked from ‘package:lme4’: #>  #>     lmList #> [1] 0.07242178"},{"path":"https://easystats.github.io/performance/reference/performance_roc.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple ROC curve — performance_roc","title":"Simple ROC curve — performance_roc","text":"function calculates simple ROC curves x/y coordinates based response predictions binomial model.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_roc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple ROC curve — performance_roc","text":"","code":"performance_roc(x, ..., predictions, new_data)"},{"path":"https://easystats.github.io/performance/reference/performance_roc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple ROC curve — performance_roc","text":"x numeric vector, representing outcome (0/1), model binomial outcome. ... One models binomial outcome. case, new_data ignored. predictions x numeric, numeric vector length x, representing actual predicted values. new_data x model, data frame passed predict() newdata-argument. NULL, ROC full model calculated.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_roc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple ROC curve — performance_roc","text":"data frame three columns, x/y-coordinate pairs ROC curve (Sensitivity Specificity), column model name.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_roc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simple ROC curve — performance_roc","text":"also plot()-method implemented see-package.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_roc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simple ROC curve — performance_roc","text":"","code":"library(bayestestR) data(iris)  set.seed(123) iris$y <- rbinom(nrow(iris), size = 1, .3) folds <- sample(nrow(iris), size = nrow(iris) / 8, replace = FALSE) test_data <- iris[folds, ] train_data <- iris[-folds, ]  model <- glm(y ~ Sepal.Length + Sepal.Width, data = train_data, family = \"binomial\") as.data.frame(performance_roc(model, new_data = test_data)) #>    Sensitivity Specificity   Model #> 1    0.0000000  0.00000000 Model 1 #> 2    0.1428571  0.00000000 Model 1 #> 3    0.1428571  0.09090909 Model 1 #> 4    0.1428571  0.18181818 Model 1 #> 5    0.1428571  0.27272727 Model 1 #> 6    0.1428571  0.36363636 Model 1 #> 7    0.2857143  0.36363636 Model 1 #> 8    0.2857143  0.45454545 Model 1 #> 9    0.2857143  0.54545455 Model 1 #> 10   0.2857143  0.63636364 Model 1 #> 11   0.2857143  0.72727273 Model 1 #> 12   0.4285714  0.72727273 Model 1 #> 13   0.5714286  0.72727273 Model 1 #> 14   0.5714286  0.81818182 Model 1 #> 15   0.7142857  0.81818182 Model 1 #> 16   0.8571429  0.81818182 Model 1 #> 17   0.8571429  0.90909091 Model 1 #> 18   1.0000000  0.90909091 Model 1 #> 19   1.0000000  1.00000000 Model 1 #> 20   1.0000000  1.00000000 Model 1  roc <- performance_roc(model, new_data = test_data) area_under_curve(roc$Specificity, roc$Sensitivity) #> [1] 0.3766234  m1 <- glm(y ~ Sepal.Length + Sepal.Width, data = iris, family = \"binomial\") m2 <- glm(y ~ Sepal.Length + Petal.Width, data = iris, family = \"binomial\") m3 <- glm(y ~ Sepal.Length + Species, data = iris, family = \"binomial\") performance_roc(m1, m2, m3) #> # Area under Curve #>  #>   m1: 54.80% #>   m2: 53.41% #>   m3: 53.58%  # if you have `see` package installed, you can also plot comparison of # ROC curves for different models if (require(\"see\")) plot(performance_roc(m1, m2, m3))"},{"path":"https://easystats.github.io/performance/reference/performance_rse.html","id":null,"dir":"Reference","previous_headings":"","what":"Residual Standard Error for Linear Models — performance_rse","title":"Residual Standard Error for Linear Models — performance_rse","text":"Compute residual standard error linear models.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_rse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residual Standard Error for Linear Models — performance_rse","text":"","code":"performance_rse(model)"},{"path":"https://easystats.github.io/performance/reference/performance_rse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residual Standard Error for Linear Models — performance_rse","text":"model model.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_rse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residual Standard Error for Linear Models — performance_rse","text":"Numeric, residual standard error model.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_rse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Residual Standard Error for Linear Models — performance_rse","text":"residual standard error square root residual sum squares divided residual degrees freedom.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_rse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Residual Standard Error for Linear Models — performance_rse","text":"","code":"data(mtcars) m <- lm(mpg ~ hp + gear, data = mtcars) performance_rse(m) #> [1] 3.107785"},{"path":"https://easystats.github.io/performance/reference/performance_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Proper Scoring Rules — performance_score","title":"Proper Scoring Rules — performance_score","text":"Calculates logarithmic, quadratic/Brier spherical score model binary count outcome.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proper Scoring Rules — performance_score","text":"","code":"performance_score(model, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/performance/reference/performance_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proper Scoring Rules — performance_score","text":"model Model binary count outcome. verbose Toggle warnings. ... Arguments functions, usually used internally.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proper Scoring Rules — performance_score","text":"list three elements, logarithmic, quadratic/Brier spherical score.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_score.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Proper Scoring Rules — performance_score","text":"Proper scoring rules can used evaluate quality model predictions model fit. performance_score() calculates logarithmic, quadratic/Brier spherical scoring rules. spherical rule takes values interval [0, 1], values closer 1 indicating accurate model, logarithmic rule interval [-Inf, 0], values closer 0 indicating accurate model. stan_lmer() stan_glmer() models, predicted values based posterior_predict(), instead predict(). Thus, results may differ expected non-Bayesian counterparts lme4.","code":""},{"path":"https://easystats.github.io/performance/reference/performance_score.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Proper Scoring Rules — performance_score","text":"Code partially based GLMMadaptive::scoring_rules().","code":""},{"path":"https://easystats.github.io/performance/reference/performance_score.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Proper Scoring Rules — performance_score","text":"Carvalho, . (2016). overview applications proper scoring rules. Decision Analysis 13, 223–242. doi:10.1287/deca.2016.0337","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/performance_score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Proper Scoring Rules — performance_score","text":"","code":"## Dobson (1990) Page 93: Randomized Controlled Trial : counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) outcome <- gl(3, 1, 9) treatment <- gl(3, 3) model <- glm(counts ~ outcome + treatment, family = poisson())  performance_score(model) #> # Proper Scoring Rules #>  #> logarithmic: -2.5979 #>   quadratic:  0.2095 #>   spherical:  0.3238 if (FALSE) { if (require(\"glmmTMB\")) {   data(Salamanders)   model <- glmmTMB(     count ~ spp + mined + (1 | site),     zi = ~ spp + mined,     family = nbinom2(),     data = Salamanders   )    performance_score(model) } }"},{"path":"https://easystats.github.io/performance/reference/r2.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the model's R2 — r2","title":"Compute the model's R2 — r2","text":"Calculate R2, also known coefficient determination, value different model objects. Depending model, R2, pseudo-R2, marginal / adjusted R2 values returned.","code":""},{"path":"https://easystats.github.io/performance/reference/r2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the model's R2 — r2","text":"","code":"r2(model, ...)  # S3 method for default r2(model, ci = NULL, verbose = TRUE, ...)  # S3 method for merMod r2(model, ci = NULL, tolerance = 1e-05, ...)"},{"path":"https://easystats.github.io/performance/reference/r2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the model's R2 — r2","text":"model statistical model. ... Arguments passed related r2-methods. ci Confidence interval level, scalar. NULL (default), confidence intervals R2 calculated. verbose Logical. details R2 CI methods given (TRUE) (FALSE)? tolerance Tolerance singularity check random effects, decide whether compute random effect variances conditional r-squared . Indicates value convergence result accepted. r2_nakagawa() returns warning, stating random effect variances computed (thus, conditional r-squared NA), decrease tolerance-level. See also check_singularity().","code":""},{"path":"https://easystats.github.io/performance/reference/r2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the model's R2 — r2","text":"Returns list containing values related appropriate R2 given model (NULL R2 extracted). See list : Logistic models: Tjur's R2 General linear models: Nagelkerke's R2 Multinomial Logit: McFadden's R2 Models zero-inflation: R2 zero-inflated models Mixed models: Nakagawa's R2 Bayesian models: R2 bayes","code":""},{"path":"https://easystats.github.io/performance/reference/r2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the model's R2 — r2","text":"r2()-method defined given model class, r2() tries return \"generic\" r-quared value, calculated following: 1-sum((y-y_hat)^2)/sum((y-y_bar)^2))","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/r2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the model's R2 — r2","text":"","code":"# Pseudo r-quared for GLM model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") r2(model) #> # R2 for Logistic Regression #>   Tjur's R2: 0.478  # r-squared including confidence intervals model <- lm(mpg ~ wt + hp, data = mtcars) r2(model, ci = 0.95) #>        R2: 0.827 [0.654, 0.906] #>   adj. R2: 0.815 [0.632, 0.899]  if (require(\"lme4\")) {   model <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)   r2(model) } #> # R2 for Mixed Models #>  #>   Conditional R2: 0.969 #>      Marginal R2: 0.658"},{"path":"https://easystats.github.io/performance/reference/r2_bayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian R2 — r2_bayes","title":"Bayesian R2 — r2_bayes","text":"Compute R2 Bayesian models. mixed models (including random part), additionally computes R2 related fixed effects (marginal R2). r2_bayes() returns single R2 value, r2_posterior() returns posterior sample Bayesian R2 values.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_bayes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian R2 — r2_bayes","text":"","code":"r2_bayes(model, robust = TRUE, ci = 0.95, verbose = TRUE, ...)  r2_posterior(model, ...)  # S3 method for brmsfit r2_posterior(model, verbose = TRUE, ...)  # S3 method for stanreg r2_posterior(model, verbose = TRUE, ...)  # S3 method for BFBayesFactor r2_posterior(model, average = FALSE, prior_odds = NULL, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/performance/reference/r2_bayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian R2 — r2_bayes","text":"model Bayesian regression model (brms, rstanarm, BayesFactor, etc). robust Logical, TRUE, median instead mean used calculate central tendency variances. ci Value vector probability CI (0 1) estimated. verbose Toggle warnings. ... Arguments passed r2_posterior(). average Compute model-averaged index? See bayestestR::weighted_posteriors(). prior_odds Optional vector prior odds models compared first model (denominator, BFBayesFactor objects). data.frames, used basis weighting.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_bayes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian R2 — r2_bayes","text":"list Bayesian R2 value. mixed models, list Bayesian R2 value marginal Bayesian R2 value. standard errors credible intervals R2 values saved attributes.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_bayes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian R2 — r2_bayes","text":"r2_bayes() returns \"unadjusted\" R2 value. See r2_loo() calculate LOO-adjusted R2, comes conceptually closer adjusted R2 measure. mixed models, conditional marginal R2 returned. marginal R2 considers variance fixed effects, conditional R2 takes fixed random effects account. r2_posterior() actual workhorse r2_bayes() returns posterior sample Bayesian R2 values.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_bayes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian R2 — r2_bayes","text":"Gelman, ., Goodrich, B., Gabry, J., Vehtari, . (2018). R-squared Bayesian regression models. American Statistician, 1–6. doi:10.1080/00031305.2018.1549100","code":""},{"path":"https://easystats.github.io/performance/reference/r2_bayes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian R2 — r2_bayes","text":"","code":"library(performance) if (require(\"rstanarm\") && require(\"rstantools\")) {   model <- stan_glm(mpg ~ wt + cyl, data = mtcars, chains = 1, iter = 500, refresh = 0)   r2_bayes(model)    model <- stan_lmer(     Petal.Length ~ Petal.Width + (1 | Species),     data = iris,     chains = 1,     iter = 500,     refresh = 0   )   r2_bayes(model) } #> Loading required package: rstantools #> This is rstantools version 2.2.0 #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: The largest R-hat is 1.07, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> # Bayesian R2 with Compatibility Interval #>  #>   Conditional R2: 0.953 (95% CI [0.941, 0.961]) #>      Marginal R2: 0.821 (95% CI [0.702, 0.891])  if (require(\"BayesFactor\")) {   BFM <- generalTestBF(mpg ~ qsec + gear, data = mtcars, progress = FALSE)   FM <- lmBF(mpg ~ qsec + gear, data = mtcars)    r2_bayes(FM)   r2_bayes(BFM[3])   r2_bayes(BFM, average = TRUE) # across all models    # with random effects:   mtcars$gear <- factor(mtcars$gear)   model <- lmBF(     mpg ~ hp + cyl + gear + gear:wt,     mtcars,     progress = FALSE,     whichRandom = c(\"gear\", \"gear:wt\")   )    r2_bayes(model) } #> Loading required package: BayesFactor #> Loading required package: coda #> ************ #> Welcome to BayesFactor 0.9.12-4.4. If you have questions, please contact Richard Morey (richarddmorey@gmail.com). #>  #> Type BFManual() to open the manual. #> ************ #> # Bayesian R2 with Compatibility Interval #>  #>   Conditional R2: 0.367 (95% CI [0.260, 0.633]) #>      Marginal R2: 0.209 (95% CI [2.871e-05, 0.500])  if (FALSE) { if (require(\"brms\")) {   model <- brms::brm(mpg ~ wt + cyl, data = mtcars)   r2_bayes(model)    model <- brms::brm(Petal.Length ~ Petal.Width + (1 | Species), data = iris)   r2_bayes(model) } }"},{"path":"https://easystats.github.io/performance/reference/r2_coxsnell.html","id":null,"dir":"Reference","previous_headings":"","what":"Cox & Snell's R2 — r2_coxsnell","title":"Cox & Snell's R2 — r2_coxsnell","text":"Calculates pseudo-R2 value based proposal Cox & Snell (1989).","code":""},{"path":"https://easystats.github.io/performance/reference/r2_coxsnell.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cox & Snell's R2 — r2_coxsnell","text":"","code":"r2_coxsnell(model, ...)"},{"path":"https://easystats.github.io/performance/reference/r2_coxsnell.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cox & Snell's R2 — r2_coxsnell","text":"model Model binary outcome. ... Currently used.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_coxsnell.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cox & Snell's R2 — r2_coxsnell","text":"named vector R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_coxsnell.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cox & Snell's R2 — r2_coxsnell","text":"index proposed Cox Snell (1989, pp. 208-9) , apparently independently, Magee (1990); suggested earlier binary response models Maddala (1983). However, index achieves maximum less 1 discrete models (.e. models whose likelihood product probabilities) maximum 1, instead densities, can become infinite (Nagelkerke, 1991).","code":""},{"path":"https://easystats.github.io/performance/reference/r2_coxsnell.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cox & Snell's R2 — r2_coxsnell","text":"Cox, D. R., Snell, E. J. (1989). Analysis binary data (Vol. 32). Monographs Statistics Applied Probability. Magee, L. (1990). R 2 measures based Wald likelihood ratio joint significance tests. American Statistician, 44(3), 250-253. Maddala, G. S. (1986). Limited-dependent qualitative variables econometrics (. 3). Cambridge university press. Nagelkerke, N. J. (1991). note general definition coefficient determination. Biometrika, 78(3), 691-692.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_coxsnell.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cox & Snell's R2 — r2_coxsnell","text":"","code":"model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") r2_coxsnell(model) #> Cox & Snell's R2  #>        0.4401407"},{"path":"https://easystats.github.io/performance/reference/r2_efron.html","id":null,"dir":"Reference","previous_headings":"","what":"Efron's R2 — r2_efron","title":"Efron's R2 — r2_efron","text":"Calculates Efron's pseudo R2.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_efron.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Efron's R2 — r2_efron","text":"","code":"r2_efron(model)"},{"path":"https://easystats.github.io/performance/reference/r2_efron.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Efron's R2 — r2_efron","text":"model Generalized linear model.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_efron.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Efron's R2 — r2_efron","text":"R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_efron.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Efron's R2 — r2_efron","text":"Efron's R2 calculated taking sum squared model residuals, divided total variability dependent variable. R2 equals squared correlation predicted values actual values, however, note model residuals generalized linear models generally comparable OLS.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_efron.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Efron's R2 — r2_efron","text":"Efron, B. (1978). Regression ANOVA zero-one data: Measures residual variation. Journal American Statistical Association, 73, 113-121.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_efron.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Efron's R2 — r2_efron","text":"","code":"## Dobson (1990) Page 93: Randomized Controlled Trial: counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) # outcome <- gl(3, 1, 9) treatment <- gl(3, 3) model <- glm(counts ~ outcome + treatment, family = poisson())  r2_efron(model) #> [1] 0.5265152"},{"path":"https://easystats.github.io/performance/reference/r2_kullback.html","id":null,"dir":"Reference","previous_headings":"","what":"Kullback-Leibler R2 — r2_kullback","title":"Kullback-Leibler R2 — r2_kullback","text":"Calculates Kullback-Leibler-divergence-based R2 generalized linear models.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_kullback.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kullback-Leibler R2 — r2_kullback","text":"","code":"r2_kullback(model, adjust = TRUE)"},{"path":"https://easystats.github.io/performance/reference/r2_kullback.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kullback-Leibler R2 — r2_kullback","text":"model generalized linear model. adjust Logical, TRUE (default), adjusted R2 value returned.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_kullback.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kullback-Leibler R2 — r2_kullback","text":"named vector R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_kullback.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kullback-Leibler R2 — r2_kullback","text":"Cameron, . C. Windmeijer, . G. (1997) R-squared measure goodness fit common nonlinear regression models. Journal Econometrics, 77: 329-342.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_kullback.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kullback-Leibler R2 — r2_kullback","text":"","code":"model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") r2_kullback(model) #> Kullback-Leibler R2  #>           0.3834362"},{"path":"https://easystats.github.io/performance/reference/r2_loo.html","id":null,"dir":"Reference","previous_headings":"","what":"LOO-adjusted R2 — r2_loo","title":"LOO-adjusted R2 — r2_loo","text":"Compute LOO-adjusted R2.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LOO-adjusted R2 — r2_loo","text":"","code":"r2_loo(model, robust = TRUE, ci = 0.95, verbose = TRUE, ...)  r2_loo_posterior(model, ...)  # S3 method for brmsfit r2_loo_posterior(model, verbose = TRUE, ...)  # S3 method for stanreg r2_loo_posterior(model, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/performance/reference/r2_loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LOO-adjusted R2 — r2_loo","text":"model Bayesian regression model (brms, rstanarm, BayesFactor, etc). robust Logical, TRUE, median instead mean used calculate central tendency variances. ci Value vector probability CI (0 1) estimated. verbose Toggle warnings. ... Arguments passed r2_posterior().","code":""},{"path":"https://easystats.github.io/performance/reference/r2_loo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LOO-adjusted R2 — r2_loo","text":"list Bayesian R2 value. mixed models, list Bayesian R2 value marginal Bayesian R2 value. standard errors credible intervals R2 values saved attributes. list LOO-adjusted R2 value. standard errors credible intervals R2 values saved attributes.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_loo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"LOO-adjusted R2 — r2_loo","text":"r2_loo() returns \"adjusted\" R2 value computed using leave-one--adjusted posterior distribution. conceptually similar adjusted/unbiased R2 estimate classical regression modeling. See r2_bayes() \"unadjusted\" R2.  Mixed models currently fully supported. r2_loo_posterior() actual workhorse r2_loo() returns posterior sample LOO-adjusted Bayesian R2 values.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_loo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LOO-adjusted R2 — r2_loo","text":"","code":"if (require(\"rstanarm\")) {   model <- stan_glm(mpg ~ wt + cyl, data = mtcars, chains = 1, iter = 500, refresh = 0)   r2_loo(model) } #> Warning: The largest R-hat is 1.05, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details. #> # LOO-adjusted R2 with Compatibility Interval #>  #>   Conditional R2: 0.794 (95% CI [0.696, 0.876])"},{"path":"https://easystats.github.io/performance/reference/r2_mcfadden.html","id":null,"dir":"Reference","previous_headings":"","what":"McFadden's R2 — r2_mcfadden","title":"McFadden's R2 — r2_mcfadden","text":"Calculates McFadden's pseudo R2.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_mcfadden.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"McFadden's R2 — r2_mcfadden","text":"","code":"r2_mcfadden(model, ...)"},{"path":"https://easystats.github.io/performance/reference/r2_mcfadden.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"McFadden's R2 — r2_mcfadden","text":"model Generalized linear multinomial logit (mlogit) model. ... Currently used.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_mcfadden.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"McFadden's R2 — r2_mcfadden","text":"models, list McFadden's R2 adjusted McFadden's R2 value. models, McFadden's R2 available.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_mcfadden.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"McFadden's R2 — r2_mcfadden","text":"McFadden, D. (1987). Regression-based specification tests multinomial logit model. Journal econometrics, 34(1-2), 63-82. McFadden, D. (1973). Conditional logit analysis qualitative choice behavior.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_mcfadden.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"McFadden's R2 — r2_mcfadden","text":"","code":"if (require(\"mlogit\")) {   data(\"Fishing\", package = \"mlogit\")   Fish <- mlogit.data(Fishing, varying = c(2:9), shape = \"wide\", choice = \"mode\")    model <- mlogit(mode ~ price + catch, data = Fish)   r2_mcfadden(model) } #> Loading required package: mlogit #> Loading required package: dfidx #>  #> Attaching package: ‘dfidx’ #> The following objects are masked from ‘package:poorman’: #>  #>     %>%, arrange, filter, mutate, pull, select, slice, transmute #> The following object is masked from ‘package:stats’: #>  #>     filter #> McFadden's R2  #>       0.17823"},{"path":"https://easystats.github.io/performance/reference/r2_mckelvey.html","id":null,"dir":"Reference","previous_headings":"","what":"McKelvey & Zavoinas R2 — r2_mckelvey","title":"McKelvey & Zavoinas R2 — r2_mckelvey","text":"Calculates McKelvey Zavoinas pseudo R2.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_mckelvey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"McKelvey & Zavoinas R2 — r2_mckelvey","text":"","code":"r2_mckelvey(model)"},{"path":"https://easystats.github.io/performance/reference/r2_mckelvey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"McKelvey & Zavoinas R2 — r2_mckelvey","text":"model Generalized linear model.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_mckelvey.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"McKelvey & Zavoinas R2 — r2_mckelvey","text":"R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_mckelvey.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"McKelvey & Zavoinas R2 — r2_mckelvey","text":"McKelvey Zavoinas R2 based explained variance, variance predicted response divided sum variance predicted response residual variance. binomial models, residual variance either pi^2/3 logit-link 1 probit-link. poisson-models, residual variance based log-normal approximation, similar distribution-specific variance described ?insight::get_variance.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_mckelvey.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"McKelvey & Zavoinas R2 — r2_mckelvey","text":"McKelvey, R., Zavoina, W. (1975), \"Statistical Model Analysis Ordinal Level Dependent Variables\", Journal Mathematical Sociology 4, S. 103–120.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_mckelvey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"McKelvey & Zavoinas R2 — r2_mckelvey","text":"","code":"## Dobson (1990) Page 93: Randomized Controlled Trial: counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) # outcome <- gl(3, 1, 9) treatment <- gl(3, 3) model <- glm(counts ~ outcome + treatment, family = poisson())  r2_mckelvey(model) #> McKelvey's R2  #>     0.3776292"},{"path":"https://easystats.github.io/performance/reference/r2_nagelkerke.html","id":null,"dir":"Reference","previous_headings":"","what":"Nagelkerke's R2 — r2_nagelkerke","title":"Nagelkerke's R2 — r2_nagelkerke","text":"Calculate Nagelkerke's pseudo-R2.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_nagelkerke.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nagelkerke's R2 — r2_nagelkerke","text":"","code":"r2_nagelkerke(model, ...)"},{"path":"https://easystats.github.io/performance/reference/r2_nagelkerke.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nagelkerke's R2 — r2_nagelkerke","text":"model generalized linear model, including cumulative links resp. multinomial models. ... Currently used.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_nagelkerke.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nagelkerke's R2 — r2_nagelkerke","text":"named vector R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_nagelkerke.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Nagelkerke's R2 — r2_nagelkerke","text":"Nagelkerke, N. J. (1991). note general definition coefficient determination. Biometrika, 78(3), 691-692.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_nagelkerke.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nagelkerke's R2 — r2_nagelkerke","text":"","code":"model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") r2_nagelkerke(model) #> Nagelkerke's R2  #>       0.5899593"},{"path":"https://easystats.github.io/performance/reference/r2_nakagawa.html","id":null,"dir":"Reference","previous_headings":"","what":"Nakagawa's R2 for mixed models — r2_nakagawa","title":"Nakagawa's R2 for mixed models — r2_nakagawa","text":"Compute marginal conditional r-squared value mixed effects models complex random effects structures.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_nakagawa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nakagawa's R2 for mixed models — r2_nakagawa","text":"","code":"r2_nakagawa(   model,   by_group = FALSE,   tolerance = 1e-05,   ci = NULL,   iterations = 100,   ... )"},{"path":"https://easystats.github.io/performance/reference/r2_nakagawa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nakagawa's R2 for mixed models — r2_nakagawa","text":"model mixed effects model. by_group Logical, TRUE, returns explained variance different levels (multiple levels). essentially similar variance reduction approach Hox (2010), pp. 69-78. tolerance Tolerance singularity check random effects, decide whether compute random effect variances conditional r-squared . Indicates value convergence result accepted. r2_nakagawa() returns warning, stating random effect variances computed (thus, conditional r-squared NA), decrease tolerance-level. See also check_singularity(). ci Confidence resp. credible interval level. icc() r2(), confidence intervals based bootstrapped samples ICC resp. R2 value. See iterations. iterations Number bootstrap-replicates computing confidence intervals ICC R2. ... Arguments passed brms::posterior_predict().","code":""},{"path":"https://easystats.github.io/performance/reference/r2_nakagawa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nakagawa's R2 for mixed models — r2_nakagawa","text":"list conditional marginal R2 values.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_nakagawa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Nakagawa's R2 for mixed models — r2_nakagawa","text":"Marginal conditional r-squared values mixed models calculated based Nakagawa et al. (2017). details computation variances, see ?insight::get_variance. random effect variances actually mean random effect variances, thus r-squared value also appropriate mixed models random slopes nested random effects (see Johnson, 2014). Conditional R2: takes fixed random effects account. Marginal R2: considers variance fixed effects. contribution random effects can deduced subtracting marginal R2 conditional R2 computing icc().","code":""},{"path":"https://easystats.github.io/performance/reference/r2_nakagawa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Nakagawa's R2 for mixed models — r2_nakagawa","text":"Hox, J. J. (2010). Multilevel analysis: techniques applications (2nd ed). New York: Routledge. Johnson, P. C. D. (2014). Extension Nakagawa Schielzeth’s R2 GLMM random slopes models. Methods Ecology Evolution, 5(9), 944–946. doi:10.1111/2041-210X.12225 Nakagawa, S., Schielzeth, H. (2013). general simple method obtaining R2 generalized linear mixed-effects models. Methods Ecology Evolution, 4(2), 133–142. doi:10.1111/j.2041-210x.2012.00261.x Nakagawa, S., Johnson, P. C. D., Schielzeth, H. (2017). coefficient determination R2 intra-class correlation coefficient generalized linear mixed-effects models revisited expanded. Journal Royal Society Interface, 14(134), 20170213. doi:10.1098/rsif.2017.0213","code":""},{"path":"https://easystats.github.io/performance/reference/r2_nakagawa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nakagawa's R2 for mixed models — r2_nakagawa","text":"","code":"if (require(\"lme4\")) {   model <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)   r2_nakagawa(model)   r2_nakagawa(model, by_group = TRUE) } #> # Explained Variance by Level #>  #> Level   |     R2 #> ---------------- #> Level 1 |  0.569 #> Species | -0.853 #>"},{"path":"https://easystats.github.io/performance/reference/r2_somers.html","id":null,"dir":"Reference","previous_headings":"","what":"Somers' Dxy rank correlation for binary outcomes — r2_somers","title":"Somers' Dxy rank correlation for binary outcomes — r2_somers","text":"Calculates Somers' Dxy rank correlation logistic regression models.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_somers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Somers' Dxy rank correlation for binary outcomes — r2_somers","text":"","code":"r2_somers(model)"},{"path":"https://easystats.github.io/performance/reference/r2_somers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Somers' Dxy rank correlation for binary outcomes — r2_somers","text":"model logistic regression model.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_somers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Somers' Dxy rank correlation for binary outcomes — r2_somers","text":"named vector R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_somers.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Somers' Dxy rank correlation for binary outcomes — r2_somers","text":"Somers, R. H. (1962). new asymmetric measure association ordinal variables. American Sociological Review. 27 (6).","code":""},{"path":"https://easystats.github.io/performance/reference/r2_somers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Somers' Dxy rank correlation for binary outcomes — r2_somers","text":"","code":"if (FALSE) { if (require(\"correlation\")) {   model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\")   r2_somers(model) } }"},{"path":"https://easystats.github.io/performance/reference/r2_tjur.html","id":null,"dir":"Reference","previous_headings":"","what":"Tjur's R2 - coefficient of determination (D) — r2_tjur","title":"Tjur's R2 - coefficient of determination (D) — r2_tjur","text":"method calculates Coefficient Discrimination D (also known Tjur's R2; Tjur, 2009) generalized linear (mixed) models binary outcomes. alternative pseudo-R2 values like Nagelkerke's R2 Cox-Snell R2. Coefficient Discrimination D can read like (pseudo-)R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_tjur.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tjur's R2 - coefficient of determination (D) — r2_tjur","text":"","code":"r2_tjur(model, ...)"},{"path":"https://easystats.github.io/performance/reference/r2_tjur.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tjur's R2 - coefficient of determination (D) — r2_tjur","text":"model Binomial Model. ... Arguments functions, usually used internally.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_tjur.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tjur's R2 - coefficient of determination (D) — r2_tjur","text":"named vector R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_tjur.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tjur's R2 - coefficient of determination (D) — r2_tjur","text":"Tjur, T. (2009). Coefficients determination logistic regression models - new proposal: coefficient discrimination. American Statistician, 63(4), 366-372.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_tjur.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tjur's R2 - coefficient of determination (D) — r2_tjur","text":"","code":"model <- glm(vs ~ wt + mpg, data = mtcars, family = \"binomial\") r2_tjur(model) #> Tjur's R2  #> 0.4776926"},{"path":"https://easystats.github.io/performance/reference/r2_xu.html","id":null,"dir":"Reference","previous_headings":"","what":"Xu' R2 (Omega-squared) — r2_xu","title":"Xu' R2 (Omega-squared) — r2_xu","text":"Calculates Xu' Omega-squared value, simple R2 equivalent linear mixed models.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_xu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Xu' R2 (Omega-squared) — r2_xu","text":"","code":"r2_xu(model)"},{"path":"https://easystats.github.io/performance/reference/r2_xu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Xu' R2 (Omega-squared) — r2_xu","text":"model linear (mixed) model.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_xu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Xu' R2 (Omega-squared) — r2_xu","text":"R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_xu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Xu' R2 (Omega-squared) — r2_xu","text":"r2_xu() crude measure explained variance linear (mixed) effects models, originally denoted Ω2.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_xu.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Xu' R2 (Omega-squared) — r2_xu","text":"Xu, R. (2003). Measuring explained variation linear mixed effects models. Statistics Medicine, 22(22), 3527–3541. doi:10.1002/sim.1572","code":""},{"path":"https://easystats.github.io/performance/reference/r2_xu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Xu' R2 (Omega-squared) — r2_xu","text":"","code":"model <- lm(Sepal.Length ~ Petal.Length + Species, data = iris) r2_xu(model) #>   Xu's R2  #> 0.8367238"},{"path":"https://easystats.github.io/performance/reference/r2_zeroinflated.html","id":null,"dir":"Reference","previous_headings":"","what":"R2 for models with zero-inflation — r2_zeroinflated","title":"R2 for models with zero-inflation — r2_zeroinflated","text":"Calculates R2 models zero-inflation component, including mixed effects models.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_zeroinflated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"R2 for models with zero-inflation — r2_zeroinflated","text":"","code":"r2_zeroinflated(model, method = c(\"default\", \"correlation\"))"},{"path":"https://easystats.github.io/performance/reference/r2_zeroinflated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"R2 for models with zero-inflation — r2_zeroinflated","text":"model model. method Indicates method calculate R2. See 'Details'. May abbreviated.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_zeroinflated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"R2 for models with zero-inflation — r2_zeroinflated","text":"default-method, list R2 adjusted R2 values. method = \"correlation\", named numeric vector correlation-based R2 value.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_zeroinflated.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"R2 for models with zero-inflation — r2_zeroinflated","text":"default-method calculates R2 value based residual variance divided total variance. method = \"correlation\", R2 correlation-based measure, rather crude. simply computes squared correlation model's actual predicted response.","code":""},{"path":"https://easystats.github.io/performance/reference/r2_zeroinflated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"R2 for models with zero-inflation — r2_zeroinflated","text":"","code":"# \\donttest{ if (require(\"pscl\")) {   data(bioChemists)   model <- zeroinfl(     art ~ fem + mar + kid5 + ment | kid5 + phd,     data = bioChemists   )    r2_zeroinflated(model) } #> Loading required package: pscl #> Classes and Methods for R developed in the #> Political Science Computational Laboratory #> Department of Political Science #> Stanford University #> Simon Jackman #> hurdle and zeroinfl functions by Achim Zeileis #> # R2 for Zero-Inflated and Hurdle Regression #>        R2: 0.180 #>   adj. R2: 0.175 # }"},{"path":"https://easystats.github.io/performance/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. insight display, print_html, print_md","code":""},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if models are different — test_bf","title":"Test if models are different — test_bf","text":"Testing whether models \"different\" terms accuracy explanatory power delicate often complex procedure, many limitations prerequisites. Moreover, many tests exist, coming interpretation, set strengths weaknesses. test_performance() function runs relevant appropriate tests based type input (instance, whether models nested ). However, still requires user understand tests order prevent misinterpretation. See Details section information regarding different tests interpretation.","code":""},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if models are different — test_bf","text":"","code":"test_bf(...)  # S3 method for default test_bf(..., reference = 1, text_length = NULL)  test_likelihoodratio(..., estimator = \"ML\")  test_lrt(..., estimator = \"ML\")  test_performance(..., reference = 1)  test_vuong(...)  test_wald(...)"},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if models are different — test_bf","text":"... Multiple model objects. reference applies models non-nested, determines model taken reference, models tested. text_length Numeric, length (number chars) output lines. test_bf() describes models formulas, can lead overly long lines output. text_length fixes length lines specified limit. estimator Applied comparing regression models using test_likelihoodratio(). Corresponds different estimators standard deviation errors. Defaults \"OLS\" linear models, \"ML\" models (including mixed models), \"REML\" linear mixed models fixed effects. See 'Details'.","code":""},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if models are different — test_bf","text":"data frame containing relevant indices.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":"nested-vs-non-nested-models","dir":"Reference","previous_headings":"","what":"Nested vs. Non-nested Models","title":"Test if models are different — test_bf","text":"Model's \"nesting\" important concept models comparison. Indeed, many tests make sense models \"nested\", .e., predictors nested. means predictors model contained within predictors larger model (sometimes referred encompassing model). instance, model1 (y ~ x1 + x2) \"nested\" within model2 (y ~ x1 + x2 + x3). Usually, people list nested models, instance m1 (y ~ 1), m2 (y ~ x1), m3 (y ~ x1 + x2), m4 (y ~ x1 + x2 + x3), conventional \"ordered\" smallest largest, user reverse order largest smallest. test shows whether parsimonious model, whether adding predictor, results significant difference model's performance. case, models usually compared sequentially: m2 tested m1, m3 m2, m4 m3, etc. Two models considered \"non-nested\" predictors different. instance, model1 (y ~ x1 + x2) model2 (y ~ x3 + x4). case non-nested models, models usually compared reference model (default, first list). Nesting detected via insight::is_nested_models() function. Note , apart nesting, order tests valid, requirements often fulfilled. instance, outcome variables (response) must . meaningfully test whether apples significantly different oranges!","code":""},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":"estimator-of-the-standard-deviation","dir":"Reference","previous_headings":"","what":"Estimator of the standard deviation","title":"Test if models are different — test_bf","text":"estimator relevant comparing regression models using test_likelihoodratio(). estimator = \"OLS\", uses method anova(..., test = \"LRT\") implemented base R, .e., scaling n-k (unbiased OLS estimator) using estimator alternative hypothesis. estimator = \"ML\", instance used lrtest(...) package lmtest, scaling done n (biased ML estimator) estimator null hypothesis. moderately large samples, differences negligible, possible OLS perform slightly better small samples Gaussian errors. estimator = \"REML\", LRT based REML-fit log-likelihoods models. Note types estimators available model classes.","code":""},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":"reml-versus-ml-estimator","dir":"Reference","previous_headings":"","what":"REML versus ML estimator","title":"Test if models are different — test_bf","text":"estimator = \"ML\", default linear mixed models (unless share fixed effects), values information criteria (AIC, AICc) based ML-estimator, default behaviour AIC() may different (particular linear mixed models lme4, sets REML = TRUE). default test_likelihoodratio() intentional, comparing information criteria based REML fits requires fixed effects models, often case. Thus, anova.merMod() automatically refits models REML performing LRT, test_likelihoodratio() checks comparison based REML fits indeed valid, , uses REML default (else, ML default). Set estimator argument explicitely override default behaviour.","code":""},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":"tests-description","dir":"Reference","previous_headings":"","what":"Tests Description","title":"Test if models are different — test_bf","text":"Bayes factor Model Comparison - test_bf(): models fit data, returned BF shows Bayes Factor (see bayestestR::bayesfactor_models()) model reference model (depends whether models nested ). Check vignette details. Wald's F-Test - test_wald(): Wald test rough approximation Likelihood Ratio Test. However, applicable LRT: can often run Wald test situations test can run. Importantly, test makes statistical sense models nested. Note: test also available base R anova() function. returns F-value column statistic associated p-value. Likelihood Ratio Test (LRT) - test_likelihoodratio(): LRT tests model better (likely) explanation data. Likelihood-Ratio-Test (LRT) gives usually somewhat close results (equivalent) Wald test , similarly, makes sense nested models. However, maximum likelihood tests make stronger assumptions method moments tests like F-test, turn efficient. Agresti (1990) suggests use LRT instead Wald test small sample sizes (30) parameters large. Note: regression models, similar anova(..., test=\"LRT\") (models) lmtest::lrtest(...), depending estimator argument. lavaan models (SEM, CFA), function calls lavaan::lavTestLRT(). models transformed response variables (like log(x) sqrt(x)), logLik() returns wrong log-likelihood. However, test_likelihoodratio() calls insight::get_loglikelihood() check_response=TRUE, returns corrected log-likelihood value models transformed response variables. Furthermore, since LRT accepts nested models (.e. models differ fixed effects), computed log-likelihood always based ML estimator, REML fits. Vuong's Test - test_vuong(): Vuong's (1989) test can used nested non-nested models, actually consists two tests. Test Distinguishability (Omega2 column associated p-value) indicates whether models can possibly distinguished basis observed data. p-value significant, means models distinguishable. Robust Likelihood Test (LR column associated p-value) indicates whether model fits better reference model. models nested, test works robust LRT. code function adapted nonnest2 package, credit go authors.","code":""},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test if models are different — test_bf","text":"Vuong, Q. H. (1989). Likelihood ratio tests model selection non-nested hypotheses. Econometrica, 57, 307-333. Merkle, E. C., , D., & Preacher, K. (2016). Testing non-nested structural equation models. Psychological Methods, 21, 151-163.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/reference/test_performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if models are different — test_bf","text":"","code":"# Nested Models # ------------- m1 <- lm(Sepal.Length ~ Petal.Width, data = iris) m2 <- lm(Sepal.Length ~ Petal.Width + Species, data = iris) m3 <- lm(Sepal.Length ~ Petal.Width * Species, data = iris)  test_performance(m1, m2, m3) #> Name | Model |    BF |   Omega2 | p (Omega2) |   LR | p (LR) #> ------------------------------------------------------------ #> m1   |    lm |       |          |            |      |        #> m2   |    lm | 0.007 | 9.54e-04 |      0.935 | 0.15 |  0.919 #> m3   |    lm | 0.037 |     0.02 |      0.081 | 3.41 |  0.099 #> Models were detected as nested and are compared in sequential order.  test_bf(m1, m2, m3) #> Bayes Factors for Model Comparison #>  #>      Model                       BF #> [m2] Petal.Width + Species    0.007 #> [m3] Petal.Width * Species 2.64e-04 #>  #> * Against Denominator: [m1] Petal.Width #> *   Bayes Factor Type: BIC approximation test_wald(m1, m2, m3) # Equivalent to anova(m1, m2, m3) #> Name | Model |  df | df_diff |    F |     p #> ------------------------------------------- #> m1   |    lm | 148 |         |      |       #> m2   |    lm | 146 |    2.00 | 0.08 | 0.927 #> m3   |    lm | 144 |    2.00 | 1.66 | 0.195 #> Models were detected as nested and are compared in sequential order.  # Equivalent to lmtest::lrtest(m1, m2, m3) test_likelihoodratio(m1, m2, m3, estimator = \"ML\") #> # Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator) #>  #> Name | Model | df | df_diff | Chi2 |     p #> ------------------------------------------ #> m1   |    lm |  3 |         |      |       #> m2   |    lm |  5 |       2 | 0.15 | 0.926 #> m3   |    lm |  7 |       2 | 3.41 | 0.182  # Equivalent to anova(m1, m2, m3, test='LRT') test_likelihoodratio(m1, m2, m3, estimator = \"OLS\") #> # Likelihood-Ratio-Test (LRT) for Model Comparison (OLS-estimator) #>  #> Name | Model | df | df_diff | Chi2 |     p #> ------------------------------------------ #> m1   |    lm |  3 |         |      |       #> m2   |    lm |  5 |       2 | 0.15 | 0.927 #> m3   |    lm |  7 |       2 | 3.31 | 0.191  if (require(\"CompQuadForm\")) {   test_vuong(m1, m2, m3) # nonnest2::vuongtest(m1, m2, nested=TRUE)    # Non-nested Models   # -----------------   m1 <- lm(Sepal.Length ~ Petal.Width, data = iris)   m2 <- lm(Sepal.Length ~ Petal.Length, data = iris)   m3 <- lm(Sepal.Length ~ Species, data = iris)    test_performance(m1, m2, m3)   test_bf(m1, m2, m3)   test_vuong(m1, m2, m3) # nonnest2::vuongtest(m1, m2) } #> Loading required package: CompQuadForm #> Name | Model | Omega2 | p (Omega2) |    LR | p (LR) #> --------------------------------------------------- #> m1   |    lm |        |            |       |        #> m2   |    lm |   0.19 |     < .001 | -4.57 | < .001 #> m3   |    lm |   0.12 |     < .001 |  2.51 | 0.006  #> Each model is compared to m1.  # Tweak the output # ---------------- test_performance(m1, m2, m3, include_formula = TRUE) #> Name |                           Model |       BF | Omega2 | p (Omega2) |    LR | p (LR) #> ---------------------------------------------------------------------------------------- #> m1   |  lm(Sepal.Length ~ Petal.Width) |          |        |            |       |        #> m2   | lm(Sepal.Length ~ Petal.Length) | 2.90e+10 |   0.19 |     < .001 | -4.57 | < .001 #> m3   |      lm(Sepal.Length ~ Species) | 2.00e-06 |   0.12 |     < .001 |  2.51 | 0.006  #> Each model is compared to m1.   # SEM / CFA (lavaan objects) # -------------------------- # Lavaan Models if (require(\"lavaan\")) {   structure <- \" visual  =~ x1 + x2 + x3                  textual =~ x4 + x5 + x6                  speed   =~ x7 + x8 + x9                    visual ~~ textual + speed \"   m1 <- lavaan::cfa(structure, data = HolzingerSwineford1939)    structure <- \" visual  =~ x1 + x2 + x3                  textual =~ x4 + x5 + x6                  speed   =~ x7 + x8 + x9                    visual ~~ 0 * textual + speed \"   m2 <- lavaan::cfa(structure, data = HolzingerSwineford1939)    structure <- \" visual  =~ x1 + x2 + x3                  textual =~ x4 + x5 + x6                  speed   =~ x7 + x8 + x9                    visual ~~ 0 * textual + 0 * speed \"   m3 <- lavaan::cfa(structure, data = HolzingerSwineford1939)    test_likelihoodratio(m1, m2, m3)    # Different Model Types   # ---------------------   if (require(\"lme4\") && require(\"mgcv\")) {     m1 <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)     m2 <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)     m3 <- gam(Sepal.Length ~ s(Petal.Length, by = Species) + Species, data = iris)      test_performance(m1, m2, m3)   } } #> Loading required package: mgcv #> This is mgcv 1.8-41. For overview type 'help(\"mgcv-package\")'. #> Name |   Model |       BF #> ------------------------- #> m1   |      lm |          #> m2   | lmerMod | 3.78e-04 #> m3   |     gam |    0.012 #> Each model is compared to m1."},{"path":[]},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-10-1","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.10.1","text":"Minor improvements documentation.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-10-1","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.10.1","text":"icc() r2_nakagawa() get ci iterations arguments, compute confidence intervals ICC resp. R2, based bootstrapped sampling. r2() gets ci, compute (analytical) confidence intervals R2. check_predictions() accepts bw argument (smoothing bandwidth), passed plot() methods density-estimation. default smoothing bandwidth bw changed \"nrd0\" \"nrd\", seems produce better fitting plots non-gaussian models. model underlying check_distribution() now also trained detect cauchy, half-cauchy inverse-gamma distributions. model_performance() now allows include ICC Bayesian models.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-10-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.10.1","text":"verbose didn’t work r2_bayes() BFBayesFactor objects. Fixed issues check_model() models convergence issues lead NA values residuals. Fixed bug check_outliers whereby passing multiple elements threshold list generated error (#496). test_wald() now warns user inappropriate F test calls test_likelihoodratio() binomial models.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-0100","dir":"Changelog","previous_headings":"","what":"performance 0.10.0","title":"performance 0.10.0","text":"CRAN release: 2022-10-03","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"breaking-change-0-10-0","dir":"Changelog","previous_headings":"","what":"Breaking Change","title":"performance 0.10.0","text":"minimum needed R version bumped 3.6. alias performance_lrt() removed. Use test_lrt() resp. test_likelihoodratio().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-functions-0-10-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"performance 0.10.0","text":"Following functions moved package parameters performance: check_sphericity_bartlett(), check_kmo(), check_factorstructure() check_clusterstructure().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-10-0","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.10.0","text":"check_normality(), check_homogeneity() check_symmetry() now works htest objects. Print method check_outliers() changed significantly: now states methods, thresholds, variables used, reports outliers per variable (univariate methods) well observation flagged several variables/methods. Includes new optional ID argument add along row number output (@rempsyc #443). check_outliers() now uses conventional outlier thresholds. IQR confidence interval methods now gain improved distance scores continuous instead discrete.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-10-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"performance 0.10.0","text":"Fixed wrong z-score values using vector instead data frame check_outliers() (#476). Fixed cronbachs_alpha() objects parameters::principal_component().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-092","dir":"Changelog","previous_headings":"","what":"performance 0.9.2","title":"performance 0.9.2","text":"CRAN release: 2022-08-10","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-9-2","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.9.2","text":"print() methods model_performance() compare_performance() get layout argument, can \"horizontal\" (default) \"vertical\", switch layout printed table. Improved speed performance check_model() performance_*() functions. Improved support models class geeglm.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-9-2","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.9.2","text":"check_model() gains show_dots argument, show hide data points. particular useful models many observations, generating plot slow.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-9-2","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"performance 0.9.2","text":"Fixes wrong column names model_performance() output kmeans objects (#453)","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-091","dir":"Changelog","previous_headings":"","what":"performance 0.9.1","title":"performance 0.9.1","text":"CRAN release: 2022-06-20","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"breaking-0-9-1","dir":"Changelog","previous_headings":"","what":"Breaking","title":"performance 0.9.1","text":"formerly “conditional” ICC icc() now named “unadjusted” ICC.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-functions-0-9-1","dir":"Changelog","previous_headings":"","what":"New functions","title":"performance 0.9.1","text":"performance_cv() cross-validated model performance.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"support-for-new-models-0-9-1","dir":"Changelog","previous_headings":"","what":"Support for new models","title":"performance 0.9.1","text":"Added support models package estimator.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-9-1","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.9.1","text":"check_overdispersion() gets plot() method. check_outliers() now also works models classes gls lme. consequence, check_model() longer fail models. check_collinearity() now includes confidence intervals VIFs tolerance values. model_performance() now also includes within-subject R2 measures, applicable. Improved handling random effects check_normality() (.e. argument effects = \"random\").","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-9-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.9.1","text":"check_predictions() work GLMs matrix-response. check_predictions() work logistic regression models (.e. models binary response) package glmmTMB item_split_half() work input data frame matrix contained two columns. Fixed wrong computation BIC model_performance() models transformed response values. Fixed issues check_model() GLMs matrix-response.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-090","dir":"Changelog","previous_headings":"","what":"performance 0.9.0","title":"performance 0.9.0","text":"CRAN release: 2022-03-30","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-functions-0-9-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"performance 0.9.0","text":"check_concurvity(), returns GAM concurvity measures (comparable collinearity checks).","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/news/index.html","id":"check-functions-0-9-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Check functions","title":"performance 0.9.0","text":"check_predictions(), check_collinearity() check_outliers() now support (mixed) regression models BayesFactor. check_zeroinflation() now also works lme4::glmer.nb() models. check_collinearity() better supports GAM models.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"test-functions-0-9-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Test functions","title":"performance 0.9.0","text":"test_performance() now calls test_lrt() test_wald() instead test_vuong() package CompQuadForm missing. test_performance() test_lrt() now compute corrected log-likelihood models transformed response variables (log- sqrt-transformations) passed functions.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"model-performance-functions-0-9-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Model performance functions","title":"performance 0.9.0","text":"performance_aic() now corrects AIC value models transformed response variables. also means comparing models using compare_performance() allows comparisons AIC values models without transformed response variables. Also, model_performance() now corrects AIC BIC values models transformed response variables.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"plotting-and-printing-0-9-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Plotting and printing","title":"performance 0.9.0","text":"print() method binned_residuals() now prints short summary results (longer generates plot). plot() method added generate plots. plot() output check_model() revised: binomial models, constant variance plot omitted, binned residuals plot included. density-plot showed normality residuals replaced posterior predictive check plot.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-9-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.9.0","text":"model_performance() models lme4 report AICc requested. r2_nakagawa() messed order group levels by_group TRUE.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-080","dir":"Changelog","previous_headings":"","what":"performance 0.8.0","title":"performance 0.8.0","text":"CRAN release: 2021-10-01","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"breaking-changes-0-8-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"performance 0.8.0","text":"ci-level r2() Bayesian models now defaults 0.95, line latest changes bayestestR package. S3-method dispatch pp_check() revised, avoid problems bayesplot package, generic located.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-8-0","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.8.0","text":"Minor revisions wording messages check-functions. posterior_predictive_check() check_predictions() added aliases pp_check().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-functions-0-8-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"performance 0.8.0","text":"check_multimodal() check_heterogeneity_bias(). functions removed parameters packages future.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-8-0","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.8.0","text":"r2() linear models can now compute confidence intervals, via ci argument.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-8-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.8.0","text":"Fixed issues check_model() Bayesian models. Fixed issue pp_check() models transformed response variables, now predictions observed response values (transformed) scale.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-073","dir":"Changelog","previous_headings":"","what":"performance 0.7.3","title":"performance 0.7.3","text":"CRAN release: 2021-07-21","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-7-3","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.7.3","text":"check_outliers() new ci (hdi, eti) method filter based Confidence/Credible intervals. compare_performance() now also accepts list model objects. performance_roc() now also works binomial models classes glm. Several functions, like icc() r2_nakagawa(), now .data.frame() method. check_collinearity() now correctly handles objects forthcoming afex update.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-072","dir":"Changelog","previous_headings":"","what":"performance 0.7.2","title":"performance 0.7.2","text":"CRAN release: 2021-05-17","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-functions-0-7-2","dir":"Changelog","previous_headings":"","what":"New functions","title":"performance 0.7.2","text":"performance_mae() calculate mean absolute error.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-7-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.7.2","text":"Fixed issue \"data length differs size matrix\" warnings examples forthcoming R 4.2. Fixed issue check_normality() models sample size larger 5.000 observations. Fixed issue check_model() glmmTMB models. Fixed issue check_collinearity() glmmTMB models zero-inflation, zero-inflated model intercept-model.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-071","dir":"Changelog","previous_headings":"","what":"performance 0.7.1","title":"performance 0.7.1","text":"CRAN release: 2021-04-09","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-supported-models-0-7-1","dir":"Changelog","previous_headings":"","what":"New supported models","title":"performance 0.7.1","text":"Add support model_fit (tidymodels). model_performance supports kmeans models.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-7-1","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.7.1","text":"Give informative warning r2_bayes() BFBayesFactor objects can’t calculated. Several check_*() functions now return informative messages invalid model types input. r2() supports mhurdle (mhurdle) models. Added print() methods classes r2(). performance_roc() performance_accuracy() functions unfortunately spelling mistakes output columns: Sensitivity called Sensivity Specificity called Specifity. think understandable mistakes :-)","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/news/index.html","id":"check_model-0-7-1","dir":"Changelog","previous_headings":"Changes to functions","what":"check_model()","title":"performance 0.7.1","text":"check_model() gains arguments, customize plot appearance. Added option detrend QQ/PP plots check_model().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"model_performance-0-7-1","dir":"Changelog","previous_headings":"Changes to functions","what":"model_performance()","title":"performance 0.7.1","text":"metrics argument model_performance() compare_performance() gains \"AICc\" option, also compute 2nd order AIC. \"R2_adj\" now explicit option metrics argument model_performance() compare_performance().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"other-functions-0-7-1","dir":"Changelog","previous_headings":"Changes to functions","what":"Other functions","title":"performance 0.7.1","text":"default-method r2() now tries compute r-squared models specific r2()-method yet, using following formula: 1-sum((y-y_hat)^2)/sum((y-y_bar)^2)) column name Parameter check_collinearity() now appropriately named Term.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-7-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.7.1","text":"test_likelihoodratio() now correctly sorts models identical fixed effects part, different model parts (like zero-inflation). Fixed incorrect computation models inverse-Gaussian families, Gaussian families fitted glm(). Fixed issue performance_roc() models outcome 0/1 coded. Fixed issue performance_accuracy() logistic regression models method = \"boot\". cronbachs_alpha() work matrix-objects, stated docs. now .","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-070","dir":"Changelog","previous_headings":"","what":"performance 0.7.0","title":"performance 0.7.0","text":"CRAN release: 2021-02-03","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-7-0","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.7.0","text":"Roll-back R dependency R >= 3.4.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"breaking-changes-0-7-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"performance 0.7.0","text":"compare_performance() doesn’t return models’ Bayes Factors, now returned test_performance() test_bf().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-functions-to-test-or-compare-models-0-7-0","dir":"Changelog","previous_headings":"","what":"New functions to test or compare models","title":"performance 0.7.0","text":"test_vuong(), compare models using Vuong’s (1989) Test. test_bf(), compare models using Bayes factors. test_likelihoodratio() alias performance_lrt(). test_wald(), rough approximation LRT. test_performance(), run relevant appropriate tests based input.","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance_lrt-0-7-0","dir":"Changelog","previous_headings":"Changes to functions","what":"performance_lrt()","title":"performance 0.7.0","text":"performance_lrt() get alias test_likelihoodratio(). return AIC/BIC now (related LRT per se can easily obtained functions). Now contains column difference degrees freedom models. Fixed column names consistency.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"model_performance-0-7-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_performance()","title":"performance 0.7.0","text":"Added diagnostics models class ivreg.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"other-functions-0-7-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Other functions","title":"performance 0.7.0","text":"Revised computation performance_mse(), ensure ’s always based response residuals. performance_aic() now robust.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-7-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.7.0","text":"Fixed issue icc() variance_decomposition() multivariate response models, model parts contained random effects. Fixed issue compare_performance() duplicated rows. check_collinearity() longer breaks models rank deficient model matrix, gives warning instead. Fixed issue check_homogeneity() method = \"auto\", wrongly tested response variable, residuals. Fixed issue check_homogeneity() edge cases predictor non-syntactic names.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-061","dir":"Changelog","previous_headings":"","what":"performance 0.6.1","title":"performance 0.6.1","text":"CRAN release: 2020-12-09","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-6-1","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.6.1","text":"check_collinearity() gains verbose argument, toggle warnings messages.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-6-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.6.1","text":"Fixed examples, now using suggested packages conditionally.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-060","dir":"Changelog","previous_headings":"","what":"performance 0.6.0","title":"performance 0.6.0","text":"CRAN release: 2020-12-01","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-6-0","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.6.0","text":"model_performance() now supports margins, gamlss, stanmvreg semLme.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-functions-0-6-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"performance 0.6.0","text":"r2_somers(), compute Somers’ Dxy rank-correlation R2-measure logistic regression models. display(), print output package-functions different formats. print_md() alias display(format = \"markdown\").","code":""},{"path":[]},{"path":"https://easystats.github.io/performance/news/index.html","id":"model_performance-0-6-0","dir":"Changelog","previous_headings":"Changes to functions","what":"model_performance()","title":"performance 0.6.0","text":"model_performance() now robust doesn’t fail index computed. Instead, returns indices possible calculate. model_performance() gains default-method catches model objects previously supported. model object also supported default-method, warning given. model_performance() metafor-models now includes degrees freedom Cochran’s Q.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"other-functions-0-6-0","dir":"Changelog","previous_headings":"Changes to functions","what":"Other functions","title":"performance 0.6.0","text":"performance_mse() performance_rmse() now always try return (R)MSE response scale. performance_accuracy() now accepts types linear logistic regression models, even class lm glm. performance_roc() now accepts types logistic regression models, even class glm. r2() mixed models r2_nakagawa() gain tolerance-argument, set tolerance level singularity checks computing random effect variances conditional r-squared.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-6-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.6.0","text":"Fixed issue icc() introduced last update make lme-models fail. Fixed issue performance_roc() models factors response.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-051","dir":"Changelog","previous_headings":"","what":"performance 0.5.1","title":"performance 0.5.1","text":"CRAN release: 2020-10-29","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"breaking-changes-0-5-1","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"performance 0.5.1","text":"Column names model_performance() compare_performance() changed line easystats naming convention: LOGLOSS now Log_loss, SCORE_LOG Score_log SCORE_SPHERICAL now Score_spherical.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-functions-0-5-1","dir":"Changelog","previous_headings":"","what":"New functions","title":"performance 0.5.1","text":"r2_posterior() Bayesian models obtain posterior distributions R-squared.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-5-1","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.5.1","text":"r2_bayes() works Bayesian models BayesFactor ( #143 ). model_performance() works Bayesian models BayesFactor ( #150 ). model_performance() now also includes residual standard deviation. Improved formatting Bayes factors compare_performance(). compare_performance() rank = TRUE doesn’t use BF values BIC present, prevent “double-dipping” BIC values (#144). method argument check_homogeneity() gains \"levene\" option, use Levene’s Test homogeneity.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-5-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.5.1","text":"Fix bug compare_performance() ... arguments function calls regression objects, instead direct function calls.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-050","dir":"Changelog","previous_headings":"","what":"performance 0.5.0","title":"performance 0.5.0","text":"CRAN release: 2020-09-12","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-5-0","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.5.0","text":"r2() icc() support semLME models (package smicd). check_heteroscedasticity() now also work zero-inflated mixed models glmmTMB GLMMadpative. check_outliers() now returns logical vector. Original numerical vector still accessible via .numeric().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"new-functions-0-5-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"performance 0.5.0","text":"pp_check() compute posterior predictive checks frequentist models.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.5.0","text":"Fixed issue incorrect labeling groups icc() by_group =   TRUE. Fixed issue check_heteroscedasticity() mixed models sigma calculated straightforward way. Fixed issues check_zeroinflation() MASS::glm.nb(). Fixed CRAN check issues.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-048","dir":"Changelog","previous_headings":"","what":"performance 0.4.8","title":"performance 0.4.8","text":"CRAN release: 2020-07-27","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-4-8","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.4.8","text":"Removed suggested packages removed CRAN.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-4-8","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.4.8","text":"icc() now also computes “classical” ICC brmsfit models. former way calculating “ICC” brmsfit models now available new function called variance_decomposition().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-4-8","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.4.8","text":"Fix issue new version bigutilsr check_outliers(). Fix issue model order performance_lrt().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-047","dir":"Changelog","previous_headings":"","what":"performance 0.4.7","title":"performance 0.4.7","text":"CRAN release: 2020-06-14","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-4-7","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.4.7","text":"Support models package mfx.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-4-7","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.4.7","text":"model_performance.rma() now includes results heterogeneity test meta-analysis objects. check_normality() now also works mixed models (limitation studentized residuals used). check_normality() gets effects-argument mixed models, check random effects normality.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-4-7","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.4.7","text":"Fixed issue performance_accuracy() binomial models response variable non-numeric factor levels. Fixed issues performance_roc(), printed 1 - AUC instead AUC.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-046","dir":"Changelog","previous_headings":"","what":"performance 0.4.6","title":"performance 0.4.6","text":"CRAN release: 2020-05-03","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-4-6","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.4.6","text":"Minor revisions model_performance() meet changes mlogit package. Support bayesx models.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-4-6","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.4.6","text":"icc() gains by_group argument, compute ICCs per different group factors mixed models multiple levels cross-classified design. r2_nakagawa() gains by_group argument, compute explained variance different levels (following variance-reduction approach Hox 2010). performance_lrt() now works lavaan objects.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-4-6","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.4.6","text":"Fix issues functions models logical dependent variable. Fix bug check_itemscale(), caused multiple computations skewness statistics. Fix issues r2() gam models.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"performance-045","dir":"Changelog","previous_headings":"","what":"performance 0.4.5","title":"performance 0.4.5","text":"CRAN release: 2020-03-28","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"general-0-4-5","dir":"Changelog","previous_headings":"","what":"General","title":"performance 0.4.5","text":"model_performance() r2() now support rma-objects package metafor, mlm bife models.","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"changes-to-functions-0-4-5","dir":"Changelog","previous_headings":"","what":"Changes to functions","title":"performance 0.4.5","text":"compare_performance() gets bayesfactor argument, include exclude Bayes factor model comparisons output. Added r2.aov().","code":""},{"path":"https://easystats.github.io/performance/news/index.html","id":"bug-fixes-0-4-5","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"performance 0.4.5","text":"Fixed issue performance_aic() models package survey, returned three different AIC values. Now AIC value returned. Fixed issue check_collinearity() glmmTMB models zero-inflated formula one predictor. Fixed issue check_model() lme models. Fixed issue check_distribution() brmsfit models. Fixed issue check_heteroscedasticity() aov objects. Fixed issues lmrob glmrob objects.","code":""}]
