---
title: "R-squared (R2)"
output: 
  rmarkdown::html_vignette:
    toc: true
    fig_width: 10.08
    fig_height: 6
tags: [r, performance, r2]
vignette: >
  \usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{R-squared (R2)}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
library(knitr)
options(knitr.kable.NA = "")
knitr::opts_chunk$set(
  comment = ">",
  message = FALSE,
  warning = FALSE,
  out.width = "100%",
  dpi = 450
)
options(digits = 2)

set.seed(333)
library(rstanarm)
```

# What is the R2?

The **coefficient of determination**, denoted $R^2$ and pronounced "R squared",
is the proportion of the variance in the dependent variable (the response) that
is *explained* (i.e., predicted) by the independent variable(s) (i.e., the
predictor(s)).

It is an "absolute" index of *goodness-of-fit*, ranging from 0 to 1, and can be used for model performance assessment or models comparison.

# Different types of R2

As models become more complex, the computation of an $R^2$ becomes increasingly
less straightforward.

Currently, depending on the context of the regression model object, one can
choose from the following measures supported in `performance`:

- Bayesian $R^2$
- Cox & Snell's $R^2$
- Efron's $R^2$
- Kullback-Leibler $R^2$
- LOO-adjusted $R^2$
- McFadden's $R^2$
- McKelvey & Zavoinas $R^2$
- Nagelkerke's $R^2$
- Nakagawa's $R^2$ for mixed models
- Somers' $D_{xy}$ rank correlation for binary outcomes
- Tjur's $R^2$ - coefficient of determination (D)
- Xu' $R^2$ (Omega-squared)
- $R^2$ for models with zero-inflation

```{r , echo=FALSE, include=FALSE, eval=FALSE}
# DONT INCLUDE FOR NOW AS IT's NOT COMPLETE
d <- data.frame(
  "Model_class" = c("lm", "glm"),
  "r2_simple" = c("X", NA),
  "r2_Tjur" = c(NA, "X")
)
knitr::kable(d)
```

*TO BE COMPLETED.*

# R2 for GLMs

In the context of a generalized linear model, $R^2$ doesn't measure the
percentage of *"explained variance"*, as this concept doesn't apply. However,
the $R^2$s that have been adapted for GLMs have retained the name of "R2",
mostly because of the similar properties (the range, the sensitivity, and the
interpretation).

```{r}
utils::data(anorexia, package = "MASS")
library(performance)

# defining a generalized linear model
model <- glm(Postwt ~ Prewt + Treat + offset(Prewt),
                family = gaussian, data = anorexia)

r2(model)
```

Note that `r2` functions only return the $R^2$ values. We would encourage users
to instead always use the `compare_performance` function to get a more
comprehensive set of indices of model fit.

```{r}
model_performance(model)
```

# R2 for Mixed Models

## Marginal vs. Conditional R2

For mixed models, `performance` will return two different $R^2$s:
- the conditional $R^2$ 
- marginal $R^2$ 

The marginal $R^2$ considers only the variance of the **fixed effects**, while
the conditional $R^2$ takes *both* the **fixed and random effects** into
account.

```{r}
library(lme4)

# defining a linear mixed-effects model
model <- lmer(Petal.Length ~ Petal.Width + (1 | Species), data = iris)

r2(model)
```

But, in the current vignette, we would like to exclusively focus on this family
of functions and will only talk about this measure.

# R2 for Bayesian Models

```{r}
library(rstanarm)

# defining a Bayesian generalized linear model
model <- stan_glm(mpg ~ wt + cyl, data = mtcars, refresh = 0)

r2(model)
```

As discussed above, for mixed-effects models, there will be two components associated with $R^2$.

```{r}
# defining a Bayesian linear mixed-effects model
model <- stan_lmer(Petal.Length ~ Petal.Width + (1 | Species), data = iris, refresh = 0)

r2(model)
```

If you want to know more about these indices, you can check out details and
references in the functions that compute them
[**here**](https://easystats.github.io/performance/reference/index.html#section-r-functions).

# Interpretation

If you want to know about how to *interpret* these $R^2$ values, see [`effectsize`](https://easystats.github.io/effectsize/reference/interpret_r2.html).